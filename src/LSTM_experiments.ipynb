{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Benchmarking LSTMs\n",
    "\n",
    "This notebook contains experiments on 3 different sequence tasks:\n",
    "* __Sequence Labelling__\n",
    "    * A many-to-one, _Sentiment Analysis_ task on the IMDb dataset available with _torchtext_.\n",
    "* __Sequence to Sequence - Same__\n",
    "    * A many-to-many-same, _Predict missing word_ task on the Facebook bAbi dataset.\n",
    "* __Sequence to Sequence - Different__\n",
    "    * A many-to-one-different, _NTM toy_ task.\n",
    "    \n",
    "For each of the tasks, we will run our implementation of vanilla LSTM. <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchtext.datasets import IMDB\n",
    "from torchtext import data\n",
    "from torchtext.vocab import GloVe\n",
    "\n",
    "import random\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, f1_score, classification_report\n",
    "\n",
    "from IPython.display import Image\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "seed = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1: Sequence Labelling\n",
    "\n",
    "All code pertaining to this task will have a pre-/post-fix **SeqLabel**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embedding dimension/dimension for LSTM cell inputs\n",
    "embed_dim = 300\n",
    "# Number of hidden nodes\n",
    "hidden_dim = 256\n",
    "# Number of output nodes\n",
    "output_dim = 1\n",
    "# Number of LSTMs cells to be stacked\n",
    "layers = 1\n",
    "# Boolean value for bidirectioanl or not\n",
    "bidirectional = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 8\n",
    "# Percentage of training data\n",
    "split_ratio = 0.8\n",
    "learning_rate = 0.001\n",
    "epochs = 1 #200"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading and preparing IMDb data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data size:    20000\n",
      "Validation data size:  5000\n",
      "Test data size:        25000\n"
     ]
    }
   ],
   "source": [
    "from imdb import IMDB_dataset\n",
    "\n",
    "imdb = IMDB_dataset(split_ratio, seed)\n",
    "imdb.load(verbose = True)\n",
    "imdb.build_vocab(embed_dim)\n",
    "train_loader, valid_loader, test_loader = imdb.create_data_loader(batch_size, \n",
    "                                                                  device)\n",
    "vocab_len = len(imdb.TEXT.vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Our implementation\n",
    "\n",
    "from seq_label import LSTM_SeqLabel, SeqLabel\n",
    "\n",
    "# Initializing model\n",
    "model = LSTM_SeqLabel(vocab_len, embed_dim, hidden_dim, output_dim, \n",
    "                       imdb.pretrained_weights, layers, bidirectional)\n",
    "model.to(device)\n",
    "\n",
    "# Initializing optimizer and loss\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "loss_criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "# Initializing task\n",
    "task = SeqLabel(model, optimizer, loss_criterion, device)\n",
    "\n",
    "# Training\n",
    "freq = 5    # epoch interval to calculate F1 score and save models\n",
    "out_dir = \"results/seq_label/\"\n",
    "# out_dir = \"/content/drive/My Drive/colab/seq_label/\"\n",
    "model, stats = task.train(epochs, train_loader, valid_loader, freq, out_dir)\n",
    "\n",
    "print(\"=\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing\n",
    "f1_test = task.evaluate_sentiment(test_loader, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and Test - PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PyTorch implementation\n",
    "\n",
    "from seq_label import SentimentNetworkBaseline\n",
    "\n",
    "# Initializing model\n",
    "model = SentimentNetworkBaseline(vocab_len, embed_dim, hidden_dim, output_dim, \n",
    "                       imdb.pretrained_weights, layers, bidirectional)\n",
    "model.to(device)\n",
    "\n",
    "# Initializing optimizer and loss\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "loss_criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "# Initializing task\n",
    "task = SeqLabel(model, optimizer, loss_criterion, device)\n",
    "\n",
    "# Training\n",
    "freq = 5    # epoch interval to calculate F1 score and save models\n",
    "out_dir = \"results/seq_label/pytorch/\"\n",
    "# out_dir = \"/content/drive/My Drive/colab/seq_label/\"\n",
    "model, stats = task.train(epochs, train_loader, valid_loader, freq, out_dir)\n",
    "\n",
    "print(\"=\" * 50)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
