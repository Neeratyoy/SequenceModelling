{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Benchmarking LSTMs\n",
    "\n",
    "This notebook contains experiments on 3 different sequence tasks:\n",
    "* __Sequence Labelling__\n",
    "    * A many-to-one, _Sentiment Analysis_ task on the IMDb dataset available with _torchtext_.\n",
    "* __Sequence to Sequence - Same__\n",
    "    * A many-to-many-same, _Predict missing word_ task on the Facebook bAbi dataset.\n",
    "* __Sequence to Sequence - Different__\n",
    "    * A many-to-one-different, _NTM toy_ task.\n",
    "    \n",
    "For each of the tasks, we will run our implementation of vanilla LSTM. <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchtext.datasets import IMDB\n",
    "from torchtext import data\n",
    "from torchtext.vocab import GloVe\n",
    "\n",
    "import random\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix, f1_score, classification_report\n",
    "\n",
    "from IPython.display import Image\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "seed = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1: Sequence Labelling\n",
    "\n",
    "All code pertaining to this task will have a pre-/post-fix **SeqLabel**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embedding dimension/dimension for LSTM cell inputs\n",
    "embed_dim = 300\n",
    "# Number of hidden nodes\n",
    "hidden_dim = 256\n",
    "# Number of output nodes\n",
    "output_dim = 1\n",
    "# Number of LSTMs cells to be stacked\n",
    "layers = 1\n",
    "# Boolean value for bidirectioanl or not\n",
    "bidirectional = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 8\n",
    "# Percentage of training data\n",
    "split_ratio = 0.8\n",
    "learning_rate = 0.001\n",
    "epochs = 1 #200"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading and preparing IMDb data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data size:    20000\n",
      "Validation data size:  5000\n",
      "Test data size:        25000\n"
     ]
    }
   ],
   "source": [
    "from imdb import IMDB_dataset\n",
    "\n",
    "imdb = IMDB_dataset(split_ratio, seed)\n",
    "imdb.load(verbose = True)\n",
    "imdb.build_vocab(embed_dim)\n",
    "train_loader, valid_loader, test_loader = imdb.create_data_loader(batch_size, \n",
    "                                                                  device)\n",
    "vocab_len = len(imdb.TEXT.vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from seq_label import *\n",
    "\n",
    "# Initializing model\n",
    "model = LSTM_SeqLabel(vocab_len, embed_dim, hidden_dim, output_dim, \n",
    "                       imdb.pretrained_weights, layers, bidirectional)\n",
    "model.to(device)\n",
    "\n",
    "# Initializing optimizer and loss\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "loss_criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "# Initializing task\n",
    "task = SeqLabel(model, optimizer, loss_criterion, device)\n",
    "\n",
    "# Training\n",
    "freq = 5    # epoch interval to calculate F1 score and save models\n",
    "out_dir = \"results/seq_label/\"\n",
    "# out_dir = \"drive/My Drive/colab/seq_label/\"\n",
    "model, stats = task.train(epochs, train_loader, valid_loader, freq, out_dir)\n",
    "\n",
    "print(\"=\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing\n",
    "f1_test = task.evaluate_sentiment(test_loader, verbose=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
