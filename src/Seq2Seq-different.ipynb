{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Seq2Seq-different-toy.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [
        "6BLdqZYbVuDE"
      ],
      "toc_visible": true
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "UlO122p0VuBN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "import os\n",
        "import json\n",
        "import time\n",
        "import random\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix, f1_score, classification_report\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
        "\n",
        "from IPython.display import Image\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "SEED = 1\n",
        "random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6cDKfMiQZKOw",
        "colab_type": "text"
      },
      "source": [
        "### Common parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cAjXMJbDVuBf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 32\n",
        "# Percentage of training data\n",
        "learning_rate = 0.001"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U6Ew_zshVuBo",
        "colab_type": "text"
      },
      "source": [
        "## n-copy task dataset\n",
        "\n",
        "The entire dataset comprises of the binary representation of all numbers uptil a range defined. The binary sequence from left to right (most significant to least significant) is the input. The target is just the reverse sequence."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GpBOzxKjVuBr",
        "colab_type": "code",
        "outputId": "98f0e588-c2d3-4ccf-9007-d0ee0165b43d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "from seq_seq_different import create_ncopy_task\n",
        "\n",
        "START = torch.tensor([1,1]).to(device)\n",
        "train_loader, test_loader, valid_loader = create_ncopy_task(sequence_length=15, \n",
        "                                                            n_copy=10,\n",
        "                                                            batch_size=batch_size,\n",
        "                                                            start_token=1,\n",
        "                                                            train_test_ratio=0.9, \n",
        "                                                            train_valid_ratio=0.8,\n",
        "                                                            verbose=True)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([16, 9000, 2]) torch.Size([151, 9000, 2])\n",
            "torch.Size([16, 1000, 2]) torch.Size([151, 1000, 2])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WzcP0iOtZDxS",
        "colab_type": "text"
      },
      "source": [
        "# LSTM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3lO9RngFZFNm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Input dim\n",
        "input_dim = 2\n",
        "# Number of hidden nodes\n",
        "hidden_dim = 32\n",
        "# Number of output nodes\n",
        "output_dim = 2\n",
        "# Number of LSTMs cells to be stacked\n",
        "layers = 1\n",
        "# Boolean value for bidirectioanl or not\n",
        "bidirectional = True\n",
        "# Boolean value to use LayerNorm or not\n",
        "layernorm = True"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FMsw_1kAVuB8",
        "colab_type": "text"
      },
      "source": [
        "## Our implementation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xbHxGL4dVuB-",
        "colab_type": "code",
        "outputId": "5c407790-1f24-4fa5-90b1-6448ae750566",
        "colab": {}
      },
      "source": [
        "from seq_seq_different import LSTMSeq2SeqDifferent\n",
        "\n",
        "our = LSTMSeq2SeqDifferent(input_dim, hidden_dim, output_dim, bidirectional=bidirectional, \n",
        "                           layers=layers, layernorm=layernorm).to(device)\n",
        "\n",
        "print(\"Our implementation\\n{}\".format(\"=\" * len(\"Our implementation\")))\n",
        "print(\"# of parameters: {}\".format(our.count_parameters()))\n",
        "for name, param in our.named_parameters():\n",
        "    print(\"{:<40}: {}\".format(name, param.shape))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Our implementation\n",
            "==================\n",
            "# of parameters: 27522\n",
            "encoder.model.0.weights                 : torch.Size([34, 128])\n",
            "encoder.model.0.bias                    : torch.Size([128])\n",
            "encoder.model.0.ln_gates.weight         : torch.Size([128])\n",
            "encoder.model.0.ln_gates.bias           : torch.Size([128])\n",
            "encoder.model.0.ln_candidate.weight     : torch.Size([32])\n",
            "encoder.model.0.ln_candidate.bias       : torch.Size([32])\n",
            "encoder.model_rev.0.weights             : torch.Size([34, 128])\n",
            "encoder.model_rev.0.bias                : torch.Size([128])\n",
            "encoder.model_rev.0.ln_gates.weight     : torch.Size([128])\n",
            "encoder.model_rev.0.ln_gates.bias       : torch.Size([128])\n",
            "encoder.model_rev.0.ln_candidate.weight : torch.Size([32])\n",
            "encoder.model_rev.0.ln_candidate.bias   : torch.Size([32])\n",
            "decoder.model.0.weights                 : torch.Size([66, 256])\n",
            "decoder.model.0.bias                    : torch.Size([256])\n",
            "decoder.model.0.ln_gates.weight         : torch.Size([256])\n",
            "decoder.model.0.ln_gates.bias           : torch.Size([256])\n",
            "decoder.model.0.ln_candidate.weight     : torch.Size([64])\n",
            "decoder.model.0.ln_candidate.bias       : torch.Size([64])\n",
            "fc.weight                               : torch.Size([2, 64])\n",
            "fc.bias                                 : torch.Size([2])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-gS3tg9nVuCE",
        "colab_type": "code",
        "outputId": "806befc4-5f7d-4f89-b025-d850f583afc0",
        "colab": {}
      },
      "source": [
        "from seq_seq_different import Seq2SeqDifferent\n",
        "\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(our.parameters(), lr=learning_rate)\n",
        "out_dir = 'dump/Seq2SeqDifferent/'\n",
        "\n",
        "task_our = Seq2SeqDifferent(model=our, optimizer=optimizer, loss_fn=loss_fn, device=device)\n",
        "\n",
        "our, our_stats = task_our.train(100, train_loader, valid_loader, teacher_forcing=0.5, freq=5,\n",
        "                                out_dir=out_dir)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Beginning training model with 27522 parameters\n",
            "Files will be saved in: dump/Seq2SeqDifferent/\n",
            "\n",
            "Epoch #1: Batch 225/225 -- Loss = 0.6515399217605591; Time taken: 0.46451616287231445s\n",
            "Epoch #1: Average loss is 0.6728919953770107\n",
            "Epoch #1: Train F1 is 0.6622557885971484\n",
            "Epoch #1: Validation F1 is 0.6617258883248732\n",
            "Time taken for epoch: 151.5590431690216s\n",
            "\n",
            "Epoch #2: Batch 225/225 -- Loss = 0.6431607007980347; Time taken: 0.4668121337890625ss\n",
            "Epoch #2: Average loss is 0.6349373835987515\n",
            "Time taken for epoch: 105.04991316795349s\n",
            "\n",
            "Epoch #3: Batch 225/225 -- Loss = 0.7124704122543335; Time taken: 0.46477770805358887s\n",
            "Epoch #3: Average loss is 0.6731014895439148\n",
            "Time taken for epoch: 105.01866436004639s\n",
            "\n",
            "Epoch #4: Batch 225/225 -- Loss = 0.6943488717079163; Time taken: 0.467041015625s303ss\n",
            "Epoch #4: Average loss is 0.700743449529012\n",
            "Time taken for epoch: 105.2679283618927s\n",
            "\n",
            "Epoch #5: Batch 225/225 -- Loss = 0.6926679015159607; Time taken: 0.4675862789154053ss\n",
            "Epoch #5: Average loss is 0.6936100673675537\n",
            "Epoch #5: Train F1 is 0.577996718553605\n",
            "Epoch #5: Validation F1 is 0.5771955013926241\n",
            "Time taken for epoch: 151.1312825679779s\n",
            "\n",
            "Epoch #6: Batch 225/225 -- Loss = 0.6927188038825989; Time taken: 0.4650914669036865ss\n",
            "Epoch #6: Average loss is 0.6931213593482971\n",
            "Time taken for epoch: 104.83272457122803s\n",
            "\n",
            "Epoch #7: Batch 225/225 -- Loss = 0.6926925182342529; Time taken: 0.4643218517303467ss\n",
            "Epoch #7: Average loss is 0.6930781239933438\n",
            "Time taken for epoch: 104.73882842063904s\n",
            "\n",
            "Epoch #8: Batch 225/225 -- Loss = 0.6926618814468384; Time taken: 0.4645824432373047ss\n",
            "Epoch #8: Average loss is 0.6930628546079\n",
            "Time taken for epoch: 104.84167718887329s\n",
            "\n",
            "Epoch #9: Batch 225/225 -- Loss = 0.6927075982093811; Time taken: 0.4677774906158447ss\n",
            "Epoch #9: Average loss is 0.6930552347501119\n",
            "Time taken for epoch: 105.46779608726501s\n",
            "\n",
            "Epoch #10: Batch 225/225 -- Loss = 0.692692756652832; Time taken: 0.46494531631469727ss\n",
            "Epoch #10: Average loss is 0.6930447665850321\n",
            "Epoch #10: Train F1 is 0.6640573366380941\n",
            "Epoch #10: Validation F1 is 0.664184257373785\n",
            "Time taken for epoch: 151.48030281066895s\n",
            "\n",
            "Epoch #11: Batch 225/225 -- Loss = 0.6927105784416199; Time taken: 0.46501946449279785s\n",
            "Epoch #11: Average loss is 0.6930208508173624\n",
            "Time taken for epoch: 104.57618999481201s\n",
            "\n",
            "Epoch #12: Batch 225/225 -- Loss = 0.6926689147949219; Time taken: 0.47908568382263184s\n",
            "Epoch #12: Average loss is 0.6929961933030022\n",
            "Time taken for epoch: 105.32506036758423s\n",
            "\n",
            "Epoch #13: Batch 225/225 -- Loss = 0.6926791071891785; Time taken: 0.4682903289794922ss\n",
            "Epoch #13: Average loss is 0.6929654333326551\n",
            "Time taken for epoch: 105.39294910430908s\n",
            "\n",
            "Epoch #14: Batch 225/225 -- Loss = 0.6925128102302551; Time taken: 0.46306490898132324s\n",
            "Epoch #14: Average loss is 0.6928956172201368\n",
            "Time taken for epoch: 105.56298637390137s\n",
            "\n",
            "Epoch #15: Batch 225/225 -- Loss = 0.6924218535423279; Time taken: 0.4657254219055176ss\n",
            "Epoch #15: Average loss is 0.6928060266706678\n",
            "Epoch #15: Train F1 is 0.6669758748831874\n",
            "Epoch #15: Validation F1 is 0.6675863930480682\n",
            "Time taken for epoch: 150.79322957992554s\n",
            "\n",
            "Epoch #16: Batch 225/225 -- Loss = 0.6921194195747375; Time taken: 0.4783146381378174ss\n",
            "Epoch #16: Average loss is 0.6926307312647502\n",
            "Time taken for epoch: 105.16428971290588s\n",
            "\n",
            "Epoch #17: Batch 225/225 -- Loss = 0.6917997598648071; Time taken: 0.46674585342407227s\n",
            "Epoch #17: Average loss is 0.6923314518398709\n",
            "Time taken for epoch: 105.35246777534485s\n",
            "\n",
            "Epoch #18: Batch 225/225 -- Loss = 0.691544771194458; Time taken: 0.46956586837768555ss\n",
            "Epoch #18: Average loss is 0.6918968383471171\n",
            "Time taken for epoch: 105.62143659591675s\n",
            "\n",
            "Epoch #19: Batch 225/225 -- Loss = 0.6911785006523132; Time taken: 0.4649062156677246ss\n",
            "Epoch #19: Average loss is 0.6914837015999689\n",
            "Time taken for epoch: 105.17839574813843s\n",
            "\n",
            "Epoch #20: Batch 225/225 -- Loss = 0.6910504698753357; Time taken: 0.46570587158203125s\n",
            "Epoch #20: Average loss is 0.691199439631568\n",
            "Epoch #20: Train F1 is 0.6645900460454265\n",
            "Epoch #20: Validation F1 is 0.6652687626774848\n",
            "Time taken for epoch: 150.53537917137146s\n",
            "\n",
            "Epoch #21: Batch 225/225 -- Loss = 0.6908079385757446; Time taken: 0.4660513401031494ss\n",
            "Epoch #21: Average loss is 0.6909969573550754\n",
            "Time taken for epoch: 104.89425253868103s\n",
            "\n",
            "Epoch #22: Batch 225/225 -- Loss = 0.6905733942985535; Time taken: 0.46428680419921875s\n",
            "Epoch #22: Average loss is 0.6907493609852261\n",
            "Time taken for epoch: 105.6089437007904s\n",
            "\n",
            "Epoch #23: Batch 225/225 -- Loss = 0.6905878782272339; Time taken: 0.4679253101348877ss\n",
            "Epoch #23: Average loss is 0.6906502170032925\n",
            "Time taken for epoch: 104.92649674415588s\n",
            "\n",
            "Epoch #24: Batch 225/225 -- Loss = 0.6904723048210144; Time taken: 0.4700610637664795ss\n",
            "Epoch #24: Average loss is 0.6905621194839477\n",
            "Time taken for epoch: 104.82347130775452s\n",
            "\n",
            "Epoch #25: Batch 225/225 -- Loss = 0.690384030342102; Time taken: 0.46527624130249023ss\n",
            "Epoch #25: Average loss is 0.6904931248558892\n",
            "Epoch #25: Train F1 is 0.66420393922141\n",
            "Epoch #25: Validation F1 is 0.6650274305608421\n",
            "Time taken for epoch: 150.44285321235657s\n",
            "\n",
            "Epoch #26: Batch 225/225 -- Loss = 0.6904294490814209; Time taken: 0.4625365734100342ss\n",
            "Epoch #26: Average loss is 0.6904295253753662\n",
            "Time taken for epoch: 105.20646691322327s\n",
            "\n",
            "Epoch #27: Batch 225/225 -- Loss = 0.6902856230735779; Time taken: 0.46321892738342285s\n",
            "Epoch #27: Average loss is 0.6903870466020372\n",
            "Time taken for epoch: 104.791428565979s\n",
            "\n",
            "Epoch #28: Batch 225/225 -- Loss = 0.6903323531150818; Time taken: 0.46848607063293457s\n",
            "Epoch #28: Average loss is 0.69034395509296\n",
            "Time taken for epoch: 105.44341135025024s\n",
            "\n",
            "Epoch #29: Batch 225/225 -- Loss = 0.6903844475746155; Time taken: 0.466411828994751s4s\n",
            "Epoch #29: Average loss is 0.6902984468142191\n",
            "Time taken for epoch: 105.58343529701233s\n",
            "\n",
            "Epoch #30: Batch 225/225 -- Loss = 0.6902866363525391; Time taken: 0.4666714668273926ss\n",
            "Epoch #30: Average loss is 0.6902573985523648\n",
            "Epoch #30: Train F1 is 0.6642871568710886\n",
            "Epoch #30: Validation F1 is 0.6649312786339027\n",
            "Time taken for epoch: 151.44044995307922s\n",
            "\n",
            "Epoch #31: Batch 225/225 -- Loss = 0.6902880668640137; Time taken: 0.46201348304748535s\n",
            "Epoch #31: Average loss is 0.6902206818262736\n",
            "Time taken for epoch: 104.89292550086975s\n",
            "\n",
            "Epoch #32: Batch 225/225 -- Loss = 0.6900972723960876; Time taken: 0.4685940742492676ss\n",
            "Epoch #32: Average loss is 0.690176035563151\n",
            "Time taken for epoch: 105.20794153213501s\n",
            "\n",
            "Epoch #33: Batch 225/225 -- Loss = 0.690087616443634; Time taken: 0.4695141315460205s6s\n",
            "Epoch #33: Average loss is 0.690124044948154\n",
            "Time taken for epoch: 105.41707229614258s\n",
            "\n",
            "Epoch #34: Batch 225/225 -- Loss = 0.6900395154953003; Time taken: 0.46471333503723145s\n",
            "Epoch #34: Average loss is 0.6900664620929294\n",
            "Time taken for epoch: 105.0949912071228s\n",
            "\n",
            "Epoch #35: Batch 225/225 -- Loss = 0.6902871131896973; Time taken: 0.46417665481567383s\n",
            "Epoch #35: Average loss is 0.6901360352834066\n",
            "Epoch #35: Train F1 is 0.665205350541954\n",
            "Epoch #35: Validation F1 is 0.6658962051821543\n",
            "Time taken for epoch: 150.84759712219238s\n",
            "\n",
            "Epoch #36: Batch 225/225 -- Loss = 0.689985990524292; Time taken: 0.4647200107574463sss\n",
            "Epoch #36: Average loss is 0.6899450850486756\n",
            "Time taken for epoch: 105.02213406562805s\n",
            "\n",
            "Epoch #37: Batch 225/225 -- Loss = 0.6898815631866455; Time taken: 0.46886229515075684s\n",
            "Epoch #37: Average loss is 0.6898142494095696\n",
            "Time taken for epoch: 104.98600006103516s\n",
            "\n",
            "Epoch #38: Batch 225/225 -- Loss = 0.6897584795951843; Time taken: 0.46989011764526367s\n",
            "Epoch #38: Average loss is 0.6896895901362101\n",
            "Time taken for epoch: 105.03108882904053s\n",
            "\n",
            "Epoch #39: Batch 225/225 -- Loss = 0.691318690776825; Time taken: 0.4641237258911133sss\n",
            "Epoch #39: Average loss is 0.6904734357198079\n",
            "Time taken for epoch: 105.29162764549255s\n",
            "\n",
            "Epoch #40: Batch 225/225 -- Loss = 0.6898118853569031; Time taken: 0.46531248092651367s\n",
            "Epoch #40: Average loss is 0.6906933008299934\n",
            "Epoch #40: Train F1 is 0.6184773893838024\n",
            "Epoch #40: Validation F1 is 0.6185451338181923\n",
            "Time taken for epoch: 150.50295281410217s\n",
            "\n",
            "Epoch #41: Batch 225/225 -- Loss = 0.6897261142730713; Time taken: 0.46204209327697754s\n",
            "Epoch #41: Average loss is 0.6899549889564515\n",
            "Time taken for epoch: 105.23043847084045s\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch #42: Batch 225/225 -- Loss = 0.6894994378089905; Time taken: 0.4621548652648926ss\n",
            "Epoch #42: Average loss is 0.6898356726434496\n",
            "Time taken for epoch: 104.34105157852173s\n",
            "\n",
            "Epoch #43: Batch 225/225 -- Loss = 0.6893659234046936; Time taken: 0.4636201858520508ss\n",
            "Epoch #43: Average loss is 0.6896446858512031\n",
            "Time taken for epoch: 104.68857765197754s\n",
            "\n",
            "Epoch #44: Batch 225/225 -- Loss = 0.6895579695701599; Time taken: 0.4610002040863037ss\n",
            "Epoch #44: Average loss is 0.6893148276540968\n",
            "Time taken for epoch: 104.22538471221924s\n",
            "\n",
            "Epoch #45: Batch 225/225 -- Loss = 0.6925036907196045; Time taken: 0.4599723815917969ss\n",
            "Epoch #45: Average loss is 0.6939699705441793\n",
            "Epoch #45: Train F1 is 0.49872868926129016\n",
            "Epoch #45: Validation F1 is 0.49807234845377735\n",
            "Time taken for epoch: 149.02803015708923s\n",
            "\n",
            "Epoch #46: Batch 225/225 -- Loss = 0.6919465661048889; Time taken: 0.46613383293151855s\n",
            "Epoch #46: Average loss is 0.692905150519477\n",
            "Time taken for epoch: 104.63224649429321s\n",
            "\n",
            "Epoch #47: Batch 225/225 -- Loss = 0.6916026473045349; Time taken: 0.4642946720123291ss\n",
            "Epoch #47: Average loss is 0.6923395318455167\n",
            "Time taken for epoch: 104.84204411506653s\n",
            "\n",
            "Epoch #48: Batch 225/225 -- Loss = 0.6912805438041687; Time taken: 0.46587228775024414s\n",
            "Epoch #48: Average loss is 0.6917057585716248\n",
            "Time taken for epoch: 104.76711177825928s\n",
            "\n",
            "Epoch #49: Batch 225/225 -- Loss = 0.6907029151916504; Time taken: 0.46748781204223633s\n",
            "Epoch #49: Average loss is 0.6909912000762092\n",
            "Time taken for epoch: 105.0103394985199s\n",
            "\n",
            "Epoch #50: Batch 225/225 -- Loss = 0.6904445290565491; Time taken: 0.46663475036621094s\n",
            "Epoch #50: Average loss is 0.6903933355543348\n",
            "Epoch #50: Train F1 is 0.6554211271616494\n",
            "Epoch #50: Validation F1 is 0.6558898523808165\n",
            "Time taken for epoch: 151.12843346595764s\n",
            "\n",
            "Epoch #51: Batch 225/225 -- Loss = 0.6900554299354553; Time taken: 0.4646456241607666ss\n",
            "Epoch #51: Average loss is 0.6899805474281311\n",
            "Time taken for epoch: 104.86107468605042s\n",
            "\n",
            "Epoch #52: Batch 225/225 -- Loss = 0.6898332834243774; Time taken: 0.4682753086090088ss\n",
            "Epoch #52: Average loss is 0.689626940091451\n",
            "Time taken for epoch: 104.82090592384338s\n",
            "\n",
            "Epoch #53: Batch 225/225 -- Loss = 0.6897191405296326; Time taken: 0.4640951156616211ss\n",
            "Epoch #53: Average loss is 0.6893322809537252\n",
            "Time taken for epoch: 105.18443369865417s\n",
            "\n",
            "Epoch #54: Batch 225/225 -- Loss = 0.6893068552017212; Time taken: 0.46466946601867676s\n",
            "Epoch #54: Average loss is 0.6890559877289666\n",
            "Time taken for epoch: 104.99127054214478s\n",
            "\n",
            "Epoch #55: Batch 225/225 -- Loss = 0.6890702247619629; Time taken: 0.46369004249572754s\n",
            "Epoch #55: Average loss is 0.6887605346573724\n",
            "Epoch #55: Train F1 is 0.15226978949157868\n",
            "Epoch #55: Validation F1 is 0.15320102432778487\n",
            "Time taken for epoch: 150.3860318660736s\n",
            "\n",
            "Epoch #56: Batch 225/225 -- Loss = 0.6887401938438416; Time taken: 0.46333885192871094s\n",
            "Epoch #56: Average loss is 0.6884073898527358\n",
            "Time taken for epoch: 104.71069526672363s\n",
            "\n",
            "Epoch #57: Batch 225/225 -- Loss = 0.6881496906280518; Time taken: 0.46571898460388184s\n",
            "Epoch #57: Average loss is 0.6878676623768276\n",
            "Time taken for epoch: 104.48166584968567s\n",
            "\n",
            "Epoch #58: Batch 225/225 -- Loss = 0.6633833050727844; Time taken: 0.4683191776275635ss\n",
            "Epoch #58: Average loss is 0.6790785932540894\n",
            "Time taken for epoch: 104.96861553192139s\n",
            "\n",
            "Epoch #59: Batch 225/225 -- Loss = 0.6444721817970276; Time taken: 0.4692556858062744ss\n",
            "Epoch #59: Average loss is 0.6420825497309367\n",
            "Time taken for epoch: 105.23157978057861s\n",
            "\n",
            "Epoch #60: Batch 225/225 -- Loss = 0.6281300187110901; Time taken: 0.46393799781799316s\n",
            "Epoch #60: Average loss is 0.6248228205574884\n",
            "Epoch #60: Train F1 is 0.634323196715825\n",
            "Epoch #60: Validation F1 is 0.6352246073453875\n",
            "Time taken for epoch: 150.35997557640076s\n",
            "\n",
            "Epoch #61: Batch 225/225 -- Loss = 0.6185809969902039; Time taken: 0.4700775146484375ss\n",
            "Epoch #61: Average loss is 0.6117236404948765\n",
            "Time taken for epoch: 104.88832116127014s\n",
            "\n",
            "Epoch #62: Batch 225/225 -- Loss = 0.6014317870140076; Time taken: 0.46616244316101074s\n",
            "Epoch #62: Average loss is 0.5931301185819837\n",
            "Time taken for epoch: 105.41203665733337s\n",
            "\n",
            "Epoch #63: Batch 225/225 -- Loss = 0.6027643084526062; Time taken: 0.46376895904541016s\n",
            "Epoch #63: Average loss is 0.581434372001224\n",
            "Time taken for epoch: 105.02760148048401s\n",
            "\n",
            "Epoch #64: Batch 225/225 -- Loss = 0.580885648727417; Time taken: 0.46853160858154297ss\n",
            "Epoch #64: Average loss is 0.5759558457798428\n",
            "Time taken for epoch: 105.51651000976562s\n",
            "\n",
            "Epoch #65: Batch 225/225 -- Loss = 0.5823310017585754; Time taken: 0.4671471118927002ss\n",
            "Epoch #65: Average loss is 0.5691176737679375\n",
            "Epoch #65: Train F1 is 0.6547813534159713\n",
            "Epoch #65: Validation F1 is 0.654314546782536\n",
            "Time taken for epoch: 150.9079053401947s\n",
            "\n",
            "Epoch #66: Batch 225/225 -- Loss = 0.5763446688652039; Time taken: 0.4650604724884033ss\n",
            "Epoch #66: Average loss is 0.5614991452958848\n",
            "Time taken for epoch: 105.17600297927856s\n",
            "\n",
            "Epoch #67: Batch 225/225 -- Loss = 0.5752940773963928; Time taken: 0.46692347526550293s\n",
            "Epoch #67: Average loss is 0.5560378154118856\n",
            "Time taken for epoch: 105.15611815452576s\n",
            "\n",
            "Epoch #68: Batch 225/225 -- Loss = 0.5712268352508545; Time taken: 0.46617650985717773s\n",
            "Epoch #68: Average loss is 0.5498913229836357\n",
            "Time taken for epoch: 105.18051409721375s\n",
            "\n",
            "Epoch #69: Batch 225/225 -- Loss = 0.5605584979057312; Time taken: 0.46783900260925293s\n",
            "Epoch #69: Average loss is 0.5422179076406691\n",
            "Time taken for epoch: 104.94268536567688s\n",
            "\n",
            "Epoch #70: Batch 225/225 -- Loss = 0.5423962473869324; Time taken: 0.46682286262512207s\n",
            "Epoch #70: Average loss is 0.5304799136850569\n",
            "Epoch #70: Train F1 is 0.7554032227318924\n",
            "Epoch #70: Validation F1 is 0.7523864794684643\n",
            "Time taken for epoch: 150.9677770137787s\n",
            "\n",
            "Epoch #71: Batch 225/225 -- Loss = 0.5336849689483643; Time taken: 0.46539974212646484ss\n",
            "Epoch #71: Average loss is 0.5208807741271125\n",
            "Time taken for epoch: 105.29351162910461s\n",
            "\n",
            "Epoch #72: Batch 225/225 -- Loss = 0.5273744463920593; Time taken: 0.4673776626586914sss\n",
            "Epoch #72: Average loss is 0.5146916757689582\n",
            "Time taken for epoch: 105.44602918624878s\n",
            "\n",
            "Epoch #73: Batch 225/225 -- Loss = 0.5287824273109436; Time taken: 0.4674875736236572sss\n",
            "Epoch #73: Average loss is 0.5101448161072201\n",
            "Time taken for epoch: 105.54955554008484s\n",
            "\n",
            "Epoch #74: Batch 225/225 -- Loss = 0.5154213905334473; Time taken: 0.4649178981781006sss\n",
            "Epoch #74: Average loss is 0.505014328956604\n",
            "Time taken for epoch: 105.24238228797913s\n",
            "\n",
            "Epoch #75: Batch 225/225 -- Loss = 0.5172033905982971; Time taken: 0.46778297424316406ss\n",
            "Epoch #75: Average loss is 0.500878769689136\n",
            "Epoch #75: Train F1 is 0.7498154403704616\n",
            "Epoch #75: Validation F1 is 0.7475955541489026\n",
            "Time taken for epoch: 151.24242997169495s\n",
            "\n",
            "Epoch #76: Batch 225/225 -- Loss = 0.5130929350852966; Time taken: 0.4680781364440918sss\n",
            "Epoch #76: Average loss is 0.49658230397436354\n",
            "Time taken for epoch: 105.10980725288391s\n",
            "\n",
            "Epoch #77: Batch 225/225 -- Loss = 0.5163106918334961; Time taken: 0.4684000015258789s3s\n",
            "Epoch #77: Average loss is 0.4959005320072174\n",
            "Time taken for epoch: 105.21774554252625s\n",
            "\n",
            "Epoch #78: Batch 225/225 -- Loss = 0.5004646182060242; Time taken: 0.4649472236633301sss\n",
            "Epoch #78: Average loss is 0.492313080628713\n",
            "Time taken for epoch: 105.27934408187866s\n",
            "\n",
            "Epoch #79: Batch 225/225 -- Loss = 0.4954985976219177; Time taken: 0.4628274440765381s5s\n",
            "Epoch #79: Average loss is 0.49431112766265867\n",
            "Time taken for epoch: 104.91068887710571s\n",
            "\n",
            "Epoch #80: Batch 225/225 -- Loss = 0.5056886672973633; Time taken: 0.46289825439453125ss\n",
            "Epoch #80: Average loss is 0.4893539869785309\n",
            "Epoch #80: Train F1 is 0.7533622460451449\n",
            "Epoch #80: Validation F1 is 0.7470195134990644\n",
            "Time taken for epoch: 150.41813802719116s\n",
            "\n",
            "Epoch #81: Batch 225/225 -- Loss = 0.4989384412765503; Time taken: 0.47243642807006836ss\n",
            "Epoch #81: Average loss is 0.4853454401757982\n",
            "Time taken for epoch: 104.50051498413086s\n",
            "\n",
            "Epoch #82: Batch 225/225 -- Loss = 0.4964796006679535; Time taken: 0.47089648246765137ss\n",
            "Epoch #82: Average loss is 0.48112186736530727\n",
            "Time taken for epoch: 105.25160050392151s\n",
            "\n",
            "Epoch #83: Batch 225/225 -- Loss = 0.48525920510292053; Time taken: 0.46404576301574707s\n",
            "Epoch #83: Average loss is 0.47912939071655275\n",
            "Time taken for epoch: 104.73568344116211s\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch #84: Batch 225/225 -- Loss = 0.4790632724761963; Time taken: 0.4677715301513672sss\n",
            "Epoch #84: Average loss is 0.4759788786040412\n",
            "Time taken for epoch: 104.92479109764099s\n",
            "\n",
            "Epoch #85: Batch 225/225 -- Loss = 0.479187935590744; Time taken: 0.46527838706970215s5s\n",
            "Epoch #85: Average loss is 0.4694828885131412\n",
            "Epoch #85: Train F1 is 0.7648113245609485\n",
            "Epoch #85: Validation F1 is 0.7649052688213366\n",
            "Time taken for epoch: 150.63849139213562s\n",
            "\n",
            "Epoch #86: Batch 225/225 -- Loss = 0.46712952852249146; Time taken: 0.466156005859375sss\n",
            "Epoch #86: Average loss is 0.4627353122499254\n",
            "Time taken for epoch: 104.97752237319946s\n",
            "\n",
            "Epoch #87: Batch 225/225 -- Loss = 0.4699142575263977; Time taken: 0.4685678482055664s5s\n",
            "Epoch #87: Average loss is 0.4608118250634935\n",
            "Time taken for epoch: 104.68876719474792s\n",
            "\n",
            "Epoch #88: Batch 225/225 -- Loss = 0.45312535762786865; Time taken: 0.46821117401123047s\n",
            "Epoch #88: Average loss is 0.44908561759524873\n",
            "Time taken for epoch: 105.1835949420929s\n",
            "\n",
            "Epoch #89: Batch 225/225 -- Loss = 0.4103626608848572; Time taken: 0.4646008014678955s4s\n",
            "Epoch #89: Average loss is 0.4275063170327081\n",
            "Time taken for epoch: 105.02135682106018s\n",
            "\n",
            "Epoch #90: Batch 225/225 -- Loss = 0.3694479167461395; Time taken: 0.46805787086486816ss\n",
            "Epoch #90: Average loss is 0.39098927643564013\n",
            "Epoch #90: Train F1 is 0.8392707653315925\n",
            "Epoch #90: Validation F1 is 0.8312196173372182\n",
            "Time taken for epoch: 151.1626808643341s\n",
            "\n",
            "Epoch #91: Batch 225/225 -- Loss = 0.3287338614463806; Time taken: 0.465822696685791s65s\n",
            "Epoch #91: Average loss is 0.3523436509238349\n",
            "Time taken for epoch: 105.21570658683777s\n",
            "\n",
            "Epoch #92: Batch 225/225 -- Loss = 0.3208593428134918; Time taken: 0.46928834915161133ss\n",
            "Epoch #92: Average loss is 0.3328424988852607\n",
            "Time taken for epoch: 105.73688292503357s\n",
            "\n",
            "Epoch #93: Batch 225/225 -- Loss = 0.313985675573349; Time taken: 0.4695277214050293s26s\n",
            "Epoch #93: Average loss is 0.32041181617312964\n",
            "Time taken for epoch: 104.57606768608093s\n",
            "\n",
            "Epoch #94: Batch 225/225 -- Loss = 0.313561350107193; Time taken: 0.46577024459838867sss\n",
            "Epoch #94: Average loss is 0.3164064207341936\n",
            "Time taken for epoch: 104.9417667388916s\n",
            "\n",
            "Epoch #95: Batch 225/225 -- Loss = 0.31929561495780945; Time taken: 0.4648454189300537ss\n",
            "Epoch #95: Average loss is 0.31546936525238883\n",
            "Epoch #95: Train F1 is 0.9881740928326802\n",
            "Epoch #95: Validation F1 is 0.9870672041526314\n",
            "Time taken for epoch: 150.86673498153687s\n",
            "\n",
            "Epoch #96: Batch 225/225 -- Loss = 0.3134442865848541; Time taken: 0.4635148048400879s5s\n",
            "Epoch #96: Average loss is 0.31415807949172125\n",
            "Time taken for epoch: 105.04091191291809s\n",
            "\n",
            "Epoch #97: Batch 225/225 -- Loss = 0.31334543228149414; Time taken: 0.462526798248291s7s\n",
            "Epoch #97: Average loss is 0.3138144490453932\n",
            "Time taken for epoch: 104.145516872406s\n",
            "\n",
            "Epoch #98: Batch 225/225 -- Loss = 0.31332656741142273; Time taken: 0.46761059761047363s\n",
            "Epoch #98: Average loss is 0.3134520876407623\n",
            "Time taken for epoch: 105.14106774330139s\n",
            "\n",
            "Epoch #99: Batch 225/225 -- Loss = 0.3133378028869629; Time taken: 0.470780611038208ssss\n",
            "Epoch #99: Average loss is 0.3134538147184584\n",
            "Time taken for epoch: 105.36271977424622s\n",
            "\n",
            "Epoch #100: Batch 225/225 -- Loss = 0.31352174282073975; Time taken: 0.463925838470459sss\n",
            "Epoch #100: Average loss is 0.315895912249883\n",
            "Epoch #100: Train F1 is 0.9821438809271495\n",
            "Epoch #100: Validation F1 is 0.9807208345805479\n",
            "Time taken for epoch: 150.6002552509308s\n",
            "\n",
            "Training completed in 11466.569862604141s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pd7tfdR8VuCM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# task_our.model.load(\"dump/Seq2SeqDifferent/model_epoch_45.pkl\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4wYI327A6bmZ",
        "colab_type": "text"
      },
      "source": [
        "### Evaluate"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WT_r1NWGVuCQ",
        "colab_type": "code",
        "outputId": "8c59332c-5391-4cc0-c4c1-56396edc4776",
        "colab": {}
      },
      "source": [
        "our_f1 = task_our.evaluate(test_loader, True)\n",
        "print(our_f1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Confusion Matrix: \n",
            " [[74232  1098]\n",
            " [ 1538 73132]]\n",
            "\n",
            "Classification Report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.99      0.98     75330\n",
            "           1       0.99      0.98      0.98     74670\n",
            "\n",
            "   micro avg       0.98      0.98      0.98    150000\n",
            "   macro avg       0.98      0.98      0.98    150000\n",
            "weighted avg       0.98      0.98      0.98    150000\n",
            "\n",
            "(0.9822968435191404, 0.33045421727001667)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3IZ6Qb5cVuCW",
        "colab_type": "code",
        "outputId": "bba75d31-c23b-4e29-b9a4-52f618c91c83",
        "colab": {}
      },
      "source": [
        "for x, y in test_loader:\n",
        "    x = x.to(device)\n",
        "    y = y.to(device)\n",
        "    break\n",
        "print(x.shape, y.shape)\n",
        "h = torch.zeros(2 * layers, x.shape[1], our.hidden_dim).to(device)\n",
        "c = torch.zeros(2 * layers, x.shape[1], our.hidden_dim).to(device)\n",
        "o = our(x, y, h, c, 0)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([15, 32, 2]) torch.Size([150, 32, 2])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j04DyOaFVuCb",
        "colab_type": "code",
        "outputId": "6c75ac35-78ca-4183-9a1e-099409b54476",
        "colab": {}
      },
      "source": [
        "z1 = torch.transpose(torch.argmax(y[-50:],2), 1, 0).detach().cpu().long().numpy()\n",
        "z2 = torch.transpose(o[-50:,:,1], 1, 0).detach().cpu().numpy()\n",
        "z2 = np.round(z2).astype(int)\n",
        "# print(z1[0,:10])\n",
        "# print(z2[0,:10])\n",
        "# print(np.bitwise_xor(z1[0, :10], z2[0, :10]))\n",
        "\n",
        "from matplotlib.colors import ListedColormap\n",
        "# plt.matshow(np.bitwise_xor(z1, z2), cmap=cmap)\n",
        "cmap1 = ListedColormap(['w', 'blue'])\n",
        "img1 = plt.imshow(np.bitwise_xor(z1, z2), cmap=cmap1, alpha=0.5)\n",
        "cmap2 = ListedColormap(['w', 'orange'])\n",
        "img2 = plt.imshow(z1, cmap=cmap2, alpha=0.7)\n",
        "plt.tick_params(labelsize=0, left=False, bottom=False)\n",
        "plt.savefig(os.path.join(out_dir, 'test.png'), transparent = True, \n",
        "            bbox_inches = 'tight', pad_inches = 0, dpi=300)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kPpvxbDZVuCg",
        "colab_type": "text"
      },
      "source": [
        "### Test with longer output"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i0QKLgalVuCh",
        "colab_type": "code",
        "outputId": "bf0ca6a7-ce7f-4047-b8e9-cdd4fd20b2f4",
        "colab": {}
      },
      "source": [
        "long_output_train_loader, \\\n",
        "long_output_test_loader, \\\n",
        "long_output_val_loader = create_ncopy_task(sequence_length=15, \n",
        "                                           n_copy=20,\n",
        "                                           batch_size=batch_size, \n",
        "                                           train_test_ratio=0.9, \n",
        "                                           train_valid_ratio=0.8)\n",
        "\n",
        "\n",
        "our_f1 = task_our.evaluate(long_output_test_loader, True)\n",
        "print(our_f1)\n",
        "\n",
        "for x, y in long_output_test_loader:\n",
        "    x = x.to(device)\n",
        "    y = y.to(device)\n",
        "    break\n",
        "\n",
        "h = torch.zeros(2 * layers, x.shape[1], our.hidden_dim).to(device)\n",
        "c = torch.zeros(2 * layers, x.shape[1], our.hidden_dim).to(device)\n",
        "o = our(x, y, h, c, 0)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([15, 9000, 2]) torch.Size([300, 9000, 2])\n",
            "torch.Size([15, 1000, 2]) torch.Size([300, 1000, 2])\n",
            "Confusion Matrix: \n",
            " [[145069   2431]\n",
            " [  3511 148989]]\n",
            "\n",
            "Classification Report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.98      0.98    147500\n",
            "           1       0.98      0.98      0.98    152500\n",
            "\n",
            "   micro avg       0.98      0.98      0.98    300000\n",
            "   macro avg       0.98      0.98      0.98    300000\n",
            "weighted avg       0.98      0.98      0.98    300000\n",
            "\n",
            "(0.980448802316399, 0.33337528817355633)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3XrhRuLGVuCp",
        "colab_type": "code",
        "outputId": "d6aa53ee-2855-49ba-ce57-bd6124810a54",
        "colab": {}
      },
      "source": [
        "z1 = torch.transpose(torch.argmax(y,2), 1, 0).detach().cpu().long().numpy()\n",
        "z1[:,0] = 1\n",
        "z2 = torch.transpose(o[:,:,1], 1, 0).detach().cpu().numpy()\n",
        "z2 = np.round(z2).astype(int)\n",
        "# print(z1[0,:10])\n",
        "# print(z2[0,:10])\n",
        "# print(np.bitwise_xor(z1[0, :10], z2[0, :10]))\n",
        "\n",
        "from matplotlib.colors import ListedColormap\n",
        "# plt.matshow(np.bitwise_xor(z1, z2), cmap=cmap)\n",
        "cmap1 = ListedColormap(['w', 'blue'])\n",
        "img1 = plt.imshow(np.bitwise_xor(z1, z2), cmap=cmap1, alpha=0.7)\n",
        "cmap2 = ListedColormap(['w', 'orange'])\n",
        "img2 = plt.imshow(z1, cmap=cmap2, alpha=0.7)\n",
        "plt.tick_params(labelsize=0, left=False, bottom=False)\n",
        "plt.savefig(os.path.join(out_dir, 'longer_output.png'), transparent = True, \n",
        "            bbox_inches = 'tight', pad_inches = 0, dpi=300)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Txk2b5piVuCw",
        "colab_type": "text"
      },
      "source": [
        "### Test with longer input"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YmAOaGUoVuCx",
        "colab_type": "code",
        "outputId": "ac8b2c8c-9faf-4035-ce67-3fdafb0d89d3",
        "colab": {}
      },
      "source": [
        "long_input_train_loader, \\\n",
        "long_input_test_loader, \\\n",
        "long_input_val_loader = create_ncopy_task(sequence_length=25, \n",
        "                                           n_copy=10,\n",
        "                                           batch_size=batch_size, \n",
        "                                           train_test_ratio=0.9, \n",
        "                                           train_valid_ratio=0.8)\n",
        "\n",
        "\n",
        "our_f1 = task_our.evaluate(long_input_test_loader, True)\n",
        "print(our_f1)\n",
        "\n",
        "for x, y in long_input_test_loader:\n",
        "    x = x.to(device)\n",
        "    y = y.to(device)\n",
        "    break\n",
        "\n",
        "h = torch.zeros(2 * layers, x.shape[1], our.hidden_dim).to(device)\n",
        "c = torch.zeros(2 * layers, x.shape[1], our.hidden_dim).to(device))\n",
        "o = our(x, y, h, c, 0)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([25, 9000, 2]) torch.Size([250, 9000, 2])\n",
            "torch.Size([25, 1000, 2]) torch.Size([250, 1000, 2])\n",
            "Confusion Matrix: \n",
            " [[75581 50739]\n",
            " [53135 70545]]\n",
            "\n",
            "Classification Report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.59      0.60      0.59    126320\n",
            "           1       0.58      0.57      0.58    123680\n",
            "\n",
            "   micro avg       0.58      0.58      0.58    250000\n",
            "   macro avg       0.58      0.58      0.58    250000\n",
            "weighted avg       0.58      0.58      0.58    250000\n",
            "\n",
            "(0.5759621821982005, 0.727789830416441)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S-tmlAiaVuC-",
        "colab_type": "code",
        "outputId": "cb4191f0-1de2-4cdf-a478-c492e1cd6097",
        "colab": {}
      },
      "source": [
        "z1 = torch.transpose(torch.argmax(y,2), 1, 0).detach().cpu().long().numpy()\n",
        "z1[:,0] = 1\n",
        "z2 = torch.transpose(o[:,:,1], 1, 0).detach().cpu().numpy()\n",
        "z2 = np.round(z2).astype(int)\n",
        "# print(z1[0,:10])\n",
        "# print(z2[0,:10])\n",
        "# print(np.bitwise_xor(z1[0, :10], z2[0, :10]))\n",
        "\n",
        "from matplotlib.colors import ListedColormap\n",
        "# plt.matshow(np.bitwise_xor(z1, z2), cmap=cmap)\n",
        "cmap1 = ListedColormap(['w', 'blue'])\n",
        "img1 = plt.imshow(np.bitwise_xor(z1, z2), cmap=cmap1, alpha=0.7)\n",
        "cmap2 = ListedColormap(['w', 'orange'])\n",
        "img2 = plt.imshow(z1, cmap=cmap2, alpha=0.7)\n",
        "plt.tick_params(labelsize=0, left=False, bottom=False)\n",
        "plt.savefig(os.path.join(out_dir, 'longer_input.png'), transparent = True, \n",
        "            bbox_inches = 'tight', pad_inches = 0, dpi=300)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6BLdqZYbVuDE",
        "colab_type": "text"
      },
      "source": [
        "## PyTorch implementation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jGdc9oKCVuDG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# class PyTorchBaseline(nn.Module):\n",
        "#     \"\"\" LSTM Class for Sequence Labelling (many-to-many-different)\n",
        "\n",
        "#     The class creates the LSTM architecture as specified by the parameters.\n",
        "#     A fully connected layer is added to reduce the last hidden state to output_dim.\n",
        "\n",
        "#     Parameters\n",
        "#     ==========\n",
        "#     vocab_len: int from imdb dataset\n",
        "#     embed_dim: dimensions of the embeddings\n",
        "#     hidden_dim: number of hidden nodes required\n",
        "#     output_dim: numer of output nodes required (1 for sentiment analysis)\n",
        "#     pretrained_vec: weights from imdb object\n",
        "#     layers: number of LSTM cells to be stacked for depth\n",
        "#     bidirectional: boolean\n",
        "#     layernorm: boolean\n",
        "\n",
        "#     \"\"\"\n",
        "#     def __init__(self, input_dim, hidden_dim, output_dim, layers=1,\n",
        "#                  bidirectional=False, layernorm=False):\n",
        "#         super().__init__()\n",
        "\n",
        "#         self.input_dim = input_dim\n",
        "#         self.output_dim = output_dim\n",
        "#         self.hidden_dim = hidden_dim\n",
        "#         self.layers = layers\n",
        "#         self.bidirectional = bidirectional\n",
        "#         self.layernorm = layernorm\n",
        "\n",
        "#         self.encoder = nn.LSTM(input_size=input_dim, hidden_size=hidden_dim, num_layers=layers,\n",
        "#                          bidirectional=bidirectional) #, layernorm=layernorm)\n",
        "#         if self.bidirectional:\n",
        "#             self.decoder = nn.LSTM(input_size=output_dim, hidden_size=2 * hidden_dim, num_layers=layers,\n",
        "#                                 bidirectional=False) #, layernorm=layernorm)\n",
        "#             self.fc = nn.Linear(2 * hidden_dim, output_dim)\n",
        "#         else:\n",
        "#             self.decoder = nn.LSTM(input_size=output_dim, hidden_size=hidden_dim, num_layers=layers,\n",
        "#                                 bidirectional=False) #, layernorm=layernorm)\n",
        "#             self.fc = nn.Linear(hidden_dim, output_dim)\n",
        "#         self.softmax = nn.Softmax(dim=2)\n",
        "\n",
        "#     def forward(self, x, target, hidden_state, cell_state, teacher_forcing=0.5):\n",
        "#         device = 'cpu'\n",
        "#         if x.is_cuda:\n",
        "#             device = 'cuda'\n",
        "#         # encoding\n",
        "#         _, (hidden_state, cell_state) = self.encoder(x, (hidden_state, cell_state))\n",
        "#         batch_size = x.shape[1]\n",
        "#         timesteps = target.shape[0]\n",
        "#         x = torch.zeros(1, batch_size, self.output_dim).to(device)\n",
        "#         output = torch.tensor([]).to(device)\n",
        "#         if self.bidirectional:\n",
        "#             # concatenating hidden states from two directions\n",
        "#             hidden_state = torch.cat((hidden_state[:self.layers,:,:], \n",
        "#                                       hidden_state[self.layers:,:,:]), dim=2)\n",
        "#             cell_state = torch.cat((cell_state[:self.layers,:,:], \n",
        "#                                     cell_state[self.layers:,:,:]), dim=2)\n",
        "#         # decoding\n",
        "#         for t in range(timesteps):           \n",
        "#             x, (hidden_state, cell_state) = self.decoder(x, (hidden_state, cell_state))\n",
        "#             x = self.softmax(self.fc(x))\n",
        "#             output = torch.cat((output, x), dim=0)\n",
        "#             choice = random.random() \n",
        "#             if choice < teacher_forcing:\n",
        "#                 x = target[t].float().to(device)\n",
        "#                 x = x.unsqueeze(0)\n",
        "#             else:\n",
        "#                 # converting x to a one-hot encoding\n",
        "#                 x = torch.zeros(x.shape).to(device).scatter_(2, torch.argmax(x, -1, keepdim=True), 1)\n",
        "#         return output\n",
        "\n",
        "#     def save(self, file_path='./model.pkl'):\n",
        "#         torch.save(self.state_dict(), file_path)\n",
        "\n",
        "#     def load(self, file_path):\n",
        "#         self.load_state_dict(torch.load(file_path))\n",
        "\n",
        "#     def count_parameters(self):\n",
        "#         tot_sum = sum(p.numel() for p in self.encoder.parameters() if p.requires_grad)\n",
        "#         tot_sum += sum(p.numel() for p in self.decoder.parameters() if p.requires_grad)\n",
        "#         tot_sum += sum(p.numel() for p in self.fc.parameters() if p.requires_grad)\n",
        "#         return tot_sum\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "byoiVYQgVuDM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# pytorch = PyTorchBaseline(input_dim, hidden_dim, output_dim, layers, bidirectional).to(device)\n",
        "# print(pytorch.count_parameters())\n",
        "# loss_fn = nn.CrossEntropyLoss()\n",
        "# optimizer = torch.optim.Adam(pytorch.parameters(), lr=learning_rate)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "dzB2lX4FVuDQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# train_x = train_x.to(device)\n",
        "# train_y = train_y.to(device)\n",
        "# test_x = test_x.to(device)\n",
        "# test_y = test_y.to(device)\n",
        "\n",
        "# pytorch = train(pytorch, train_x, train_y, test_x, test_y, epochs=30, loss_fn=loss_fn, optimizer=optimizer, teacher_forcing=0.5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dh4Ui3WEZXzL",
        "colab_type": "text"
      },
      "source": [
        "# Transfomer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "ea582e8d-002f-40cf-bd82-2adc819a1057",
        "id": "i2z92eD3Zgmb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "from seq_seq_different import TransformerSeq2SeqDifferent\n",
        "\n",
        "pad = torch.tensor([0,0]).float()\n",
        "# create model\n",
        "# 13k\n",
        "model = TransformerSeq2SeqDifferent(in_dim=2, out_dim=2, N=1, heads=6, model_dim=16, key_dim=4, value_dim=4, ff_dim=128,\n",
        "                                          batch_first=False)\n",
        "# 5k\n",
        "# model = TransformerSeq2SeqDifferent(in_dim=2, out_dim=2, N=1, heads=8, model_dim=8, key_dim=4, value_dim=4, ff_dim=64,\n",
        "#                                           batch_first=False)\n",
        "\n",
        "model = model.to(device)\n",
        "\n",
        "print(model.count_parameters())"
      ],
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "13642\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "85a3f89d-006e-441b-f8f9-793bf9ece8aa",
        "id": "1lwjklLCZgmo",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from seq_seq_different import Seq2SeqDifferent\n",
        "from transformer import NoamOpt\n",
        "\n",
        "out_dir = 'results/Seq2SeqDifferent/transformer'\n",
        "\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "# optimizer = NoamOpt(model.model_dim, 1, 2000,\n",
        "#         torch.optim.Adam(model.parameters(), lr=0, betas=(0.9, 0.98), eps=1e-9))\n",
        "\n",
        "task_transformer = Seq2SeqDifferent(model=model, optimizer=optimizer, loss_fn=loss_fn, \n",
        "                                    start_token=START, device=device)\n",
        "\n",
        "transformer, transformer_stats = task_transformer.train(100, train_loader, valid_loader, freq=5,\n",
        "                                out_dir=out_dir, train_eval=False)"
      ],
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Beginning training model with 13642 parameters\n",
            "Files will be saved in: results/Seq2SeqDifferent/transformer\n",
            "\n",
            "\n",
            "Epoch #1: Average loss is 0.675191134346856\n",
            "."
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/content/seq_seq_different.py:271: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  tgt = torch.tensor(start_token).view(1,1,-1).repeat(src.shape[0],1,1).float()\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "........................................................\n",
            "Epoch #1: Validation F1 is 0.622458736955889\n",
            "Time taken for epoch: 18.662318229675293s\n",
            "\n",
            "\n",
            "Epoch #2: Average loss is 0.656914102766249\n",
            "Time taken for epoch: 2.519498109817505s\n",
            "\n",
            "\n",
            "Epoch #3: Average loss is 0.6348500561714172\n",
            "Time taken for epoch: 2.5584819316864014s\n",
            "\n",
            "\n",
            "Epoch #4: Average loss is 0.5717124072710673\n",
            "Time taken for epoch: 2.537940263748169s\n",
            "\n",
            "\n",
            "Epoch #5: Average loss is 0.5168354116545784\n",
            ".........................................................\n",
            "Epoch #5: Validation F1 is 0.7046093855737682\n",
            "Time taken for epoch: 37.00726819038391s\n",
            "\n",
            "\n",
            "Epoch #6: Average loss is 0.4419614297813839\n",
            "Time taken for epoch: 6.025539875030518s\n",
            "\n",
            "\n",
            "Epoch #7: Average loss is 0.3567193830013275\n",
            "Time taken for epoch: 6.119030952453613s\n",
            "\n",
            "\n",
            "Epoch #8: Average loss is 0.28266781515545314\n",
            "Time taken for epoch: 6.075300931930542s\n",
            "\n",
            "\n",
            "Epoch #9: Average loss is 0.22876333826118045\n",
            "Time taken for epoch: 6.03158974647522s\n",
            "\n",
            "\n",
            "Epoch #10: Average loss is 0.19032639298174117\n",
            ".........................................................\n",
            "Epoch #10: Validation F1 is 0.9510703930143942\n",
            "Time taken for epoch: 54.07170343399048s\n",
            "\n",
            "\n",
            "Epoch #11: Average loss is 0.16332026210096148\n",
            "Time taken for epoch: 6.108050107955933s\n",
            "\n",
            "\n",
            "Epoch #12: Average loss is 0.14362924426794052\n",
            "Time taken for epoch: 6.096493244171143s\n",
            "\n",
            "\n",
            "Epoch #13: Average loss is 0.12739049918121761\n",
            "Time taken for epoch: 6.139577865600586s\n",
            "\n",
            "\n",
            "Epoch #14: Average loss is 0.11415081133445104\n",
            "Time taken for epoch: 6.154162168502808s\n",
            "\n",
            "\n",
            "Epoch #15: Average loss is 0.09987793899244732\n",
            ".........................................................\n",
            "Epoch #15: Validation F1 is 0.9840933586055673\n",
            "Time taken for epoch: 55.234869718551636s\n",
            "\n",
            "\n",
            "Epoch #16: Average loss is 0.0882979546321763\n",
            "Time taken for epoch: 4.686507940292358s\n",
            "\n",
            "\n",
            "Epoch #17: Average loss is 0.07769435750113593\n",
            "Time taken for epoch: 6.004354476928711s\n",
            "\n",
            "\n",
            "Epoch #18: Average loss is 0.06946792468428611\n",
            "Time taken for epoch: 6.134239912033081s\n",
            "\n",
            "\n",
            "Epoch #19: Average loss is 0.061094064199262194\n",
            "Time taken for epoch: 6.1323018074035645s\n",
            "\n",
            "\n",
            "Epoch #20: Average loss is 0.054018906205892565\n",
            ".........................................................\n",
            "Epoch #20: Validation F1 is 0.9970456424152337\n",
            "Time taken for epoch: 55.95450234413147s\n",
            "\n",
            "\n",
            "Epoch #21: Average loss is 0.0476233137316174\n",
            "Time taken for epoch: 6.171801328659058s\n",
            "\n",
            "\n",
            "Epoch #22: Average loss is 0.04261924761864874\n",
            "Time taken for epoch: 5.315441370010376s\n",
            "\n",
            "\n",
            "Epoch #23: Average loss is 0.03897883226474126\n",
            "Time taken for epoch: 4.715900897979736s\n",
            "\n",
            "\n",
            "Epoch #24: Average loss is 0.03529114333291849\n",
            "Time taken for epoch: 4.969578504562378s\n",
            "\n",
            "\n",
            "Epoch #25: Average loss is 0.03224861956304974\n",
            ".........................................................\n",
            "Epoch #25: Validation F1 is 0.9989774748073503\n",
            "Time taken for epoch: 55.96921396255493s\n",
            "\n",
            "\n",
            "Epoch #26: Average loss is 0.029879297705160245\n",
            "Time taken for epoch: 6.181001663208008s\n",
            "\n",
            "\n",
            "Epoch #27: Average loss is 0.02742233435312907\n",
            "Time taken for epoch: 6.19900369644165s\n",
            "\n",
            "\n",
            "Epoch #28: Average loss is 0.025373620200488303\n",
            "Time taken for epoch: 6.168270111083984s\n",
            "\n",
            "\n",
            "Epoch #29: Average loss is 0.023239456183380552\n",
            "Time taken for epoch: 6.159321069717407s\n",
            "\n",
            "\n",
            "Epoch #30: Average loss is 0.021607062559988763\n",
            ".........................................................\n",
            "Epoch #30: Validation F1 is 0.9999518791203503\n",
            "Time taken for epoch: 53.12984371185303s\n",
            "\n",
            "\n",
            "Epoch #31: Average loss is 0.020705206361081866\n",
            "Time taken for epoch: 6.179837942123413s\n",
            "\n",
            "\n",
            "Epoch #32: Average loss is 0.019278672225773334\n",
            "Time taken for epoch: 6.156224489212036s\n",
            "\n",
            "\n",
            "Epoch #33: Average loss is 0.018325349841680792\n",
            "Time taken for epoch: 6.131032943725586s\n",
            "\n",
            "\n",
            "Epoch #34: Average loss is 0.017437896467745306\n",
            "Time taken for epoch: 6.124472618103027s\n",
            "\n",
            "\n",
            "Epoch #35: Average loss is 0.016097763288352225\n",
            ".........................................................\n",
            "Epoch #35: Validation F1 is 0.9999481807750675\n",
            "Time taken for epoch: 54.020549058914185s\n",
            "\n",
            "\n",
            "Epoch #36: Average loss is 0.01567739062425163\n",
            "Time taken for epoch: 6.157331228256226s\n",
            "\n",
            "\n",
            "Epoch #37: Average loss is 0.014612665064632893\n",
            "Time taken for epoch: 6.13428521156311s\n",
            "\n",
            "\n",
            "Epoch #38: Average loss is 0.013628060387240517\n",
            "Time taken for epoch: 6.1298828125s\n",
            "\n",
            "\n",
            "Epoch #39: Average loss is 0.013124733291980294\n",
            "Time taken for epoch: 6.149715900421143s\n",
            "\n",
            "\n",
            "Epoch #40: Average loss is 0.012403169415063328\n",
            ".........................................................\n",
            "Epoch #40: Validation F1 is 0.9999925969795677\n",
            "Time taken for epoch: 53.75709629058838s\n",
            "\n",
            "\n",
            "Epoch #41: Average loss is 0.011796484055618445\n",
            "Time taken for epoch: 6.092661619186401s\n",
            "\n",
            "\n",
            "Epoch #42: Average loss is 0.011199405193328857\n",
            "Time taken for epoch: 6.1009840965271s\n",
            "\n",
            "\n",
            "Epoch #43: Average loss is 0.010830096966690487\n",
            "Time taken for epoch: 6.0950586795806885s\n",
            "\n",
            "\n",
            "Epoch #44: Average loss is 0.010071299442400535\n",
            "Time taken for epoch: 6.154942750930786s\n",
            "\n",
            "\n",
            "Epoch #45: Average loss is 0.009457022644993332\n",
            ".........................................................\n",
            "Epoch #45: Validation F1 is 1.0\n",
            "Time taken for epoch: 53.24525213241577s\n",
            "\n",
            "\n",
            "Epoch #46: Average loss is 0.009219579336543878\n",
            "Time taken for epoch: 6.099981784820557s\n",
            "\n",
            "\n",
            "Epoch #47: Average loss is 0.008854926225418846\n",
            "Time taken for epoch: 6.110229015350342s\n",
            "\n",
            "\n",
            "Epoch #48: Average loss is 0.008208014397985405\n",
            "Time taken for epoch: 6.080949783325195s\n",
            "\n",
            "\n",
            "Epoch #49: Average loss is 0.007806599947313467\n",
            "Time taken for epoch: 6.142884254455566s\n",
            "\n",
            "\n",
            "Epoch #50: Average loss is 0.007346960164399611\n",
            ".........................................................\n",
            "Epoch #50: Validation F1 is 1.0\n",
            "Time taken for epoch: 55.16267275810242s\n",
            "\n",
            "\n",
            "Epoch #51: Average loss is 0.006751889866880244\n",
            "Time taken for epoch: 4.748127460479736s\n",
            "\n",
            "\n",
            "Epoch #52: Average loss is 0.006551202637039953\n",
            "Time taken for epoch: 5.160619735717773s\n",
            "\n",
            "\n",
            "Epoch #53: Average loss is 0.006032939102086756\n",
            "Time taken for epoch: 6.106224298477173s\n",
            "\n",
            "\n",
            "Epoch #54: Average loss is 0.005931328542323576\n",
            "Time taken for epoch: 6.159732341766357s\n",
            "\n",
            "\n",
            "Epoch #55: Average loss is 0.005815346467619141\n",
            ".........................................................\n",
            "Epoch #55: Validation F1 is 1.0\n",
            "Time taken for epoch: 55.52713060379028s\n",
            "\n",
            "\n",
            "Epoch #56: Average loss is 0.005803354814027746\n",
            "Time taken for epoch: 6.117855787277222s\n",
            "\n",
            "\n",
            "Epoch #57: Average loss is 0.005243778911729654\n",
            "Time taken for epoch: 6.118950366973877s\n",
            "\n",
            "\n",
            "Epoch #58: Average loss is 0.005070397513918579\n",
            "Time taken for epoch: 4.796580076217651s\n",
            "\n",
            "\n",
            "Epoch #59: Average loss is 0.004794230175515016\n",
            "Time taken for epoch: 4.759682655334473s\n",
            "\n",
            "\n",
            "Epoch #60: Average loss is 0.005040513838434385\n",
            ".........................................................\n",
            "Epoch #60: Validation F1 is 0.9999777906098699\n",
            "Time taken for epoch: 54.69186091423035s\n",
            "\n",
            "\n",
            "Epoch #61: Average loss is 0.004647240767048465\n",
            "Time taken for epoch: 6.129385948181152s\n",
            "\n",
            "\n",
            "Epoch #62: Average loss is 0.004823462182862891\n",
            "Time taken for epoch: 6.126836538314819s\n",
            "\n",
            "\n",
            "Epoch #63: Average loss is 0.004336503425923487\n",
            "Time taken for epoch: 6.190420150756836s\n",
            "\n",
            "\n",
            "Epoch #64: Average loss is 0.0041889011947852045\n",
            "Time taken for epoch: 6.123161315917969s\n",
            "\n",
            "\n",
            "Epoch #65: Average loss is 0.00432150449241615\n",
            ".........................................................\n",
            "Epoch #65: Validation F1 is 1.0\n",
            "Time taken for epoch: 53.9020721912384s\n",
            "\n",
            "\n",
            "Epoch #66: Average loss is 0.004047009088616404\n",
            "Time taken for epoch: 6.1656999588012695s\n",
            "\n",
            "\n",
            "Epoch #67: Average loss is 0.003994151220346491\n",
            "Time taken for epoch: 6.143325328826904s\n",
            "\n",
            "\n",
            "Epoch #68: Average loss is 0.0037385620864936048\n",
            "Time taken for epoch: 6.16369366645813s\n",
            "\n",
            "\n",
            "Epoch #69: Average loss is 0.003698473410266969\n",
            "Time taken for epoch: 6.148519992828369s\n",
            "\n",
            "\n",
            "Epoch #70: Average loss is 0.0034858255403944186\n",
            ".........................................................\n",
            "Epoch #70: Validation F1 is 1.0\n",
            "Time taken for epoch: 54.11742687225342s\n",
            "\n",
            "\n",
            "Epoch #71: Average loss is 0.0038785765239865416\n",
            "Time taken for epoch: 6.0648112297058105s\n",
            "\n",
            "\n",
            "Epoch #72: Average loss is 0.003278363650250766\n",
            "Time taken for epoch: 6.135138034820557s\n",
            "\n",
            "\n",
            "Epoch #73: Average loss is 0.0033246988578078647\n",
            "Time taken for epoch: 6.160478353500366s\n",
            "\n",
            "\n",
            "Epoch #74: Average loss is 0.0033611086471420195\n",
            "Time taken for epoch: 6.164952754974365s\n",
            "\n",
            "\n",
            "Epoch #75: Average loss is 0.00325956258457154\n",
            ".........................................................\n",
            "Epoch #75: Validation F1 is 1.0\n",
            "Time taken for epoch: 53.94996380805969s\n",
            "\n",
            "\n",
            "Epoch #76: Average loss is 0.002795008803562572\n",
            "Time taken for epoch: 6.159539222717285s\n",
            "\n",
            "\n",
            "Epoch #77: Average loss is 0.0026954281570700307\n",
            "Time taken for epoch: 6.187224626541138s\n",
            "\n",
            "\n",
            "Epoch #78: Average loss is 0.0026583175024845534\n",
            "Time taken for epoch: 6.154263019561768s\n",
            "\n",
            "\n",
            "Epoch #79: Average loss is 0.0026601664943154903\n",
            "Time taken for epoch: 6.142176628112793s\n",
            "\n",
            "\n",
            "Epoch #80: Average loss is 0.0025142900870802503\n",
            ".........................................................\n",
            "Epoch #80: Validation F1 is 1.0\n",
            "Time taken for epoch: 53.74171710014343s\n",
            "\n",
            "\n",
            "Epoch #81: Average loss is 0.002337245452735159\n",
            "Time taken for epoch: 6.187666416168213s\n",
            "\n",
            "\n",
            "Epoch #82: Average loss is 0.0022527817375440564\n",
            "Time taken for epoch: 6.157307386398315s\n",
            "\n",
            "\n",
            "Epoch #83: Average loss is 0.002129966852436256\n",
            "Time taken for epoch: 6.151840925216675s\n",
            "\n",
            "\n",
            "Epoch #84: Average loss is 0.0022086007572296594\n",
            "Time taken for epoch: 6.136725902557373s\n",
            "\n",
            "\n",
            "Epoch #85: Average loss is 0.0020792099627821394\n",
            ".........................................................\n",
            "Epoch #85: Validation F1 is 1.0\n",
            "Time taken for epoch: 55.73956346511841s\n",
            "\n",
            "\n",
            "Epoch #86: Average loss is 0.002042332557418073\n",
            "Time taken for epoch: 4.632305383682251s\n",
            "\n",
            "\n",
            "Epoch #87: Average loss is 0.0020128991685083343\n",
            "Time taken for epoch: 4.608012437820435s\n",
            "\n",
            "\n",
            "Epoch #88: Average loss is 0.0019305884166775891\n",
            "Time taken for epoch: 6.021528720855713s\n",
            "\n",
            "\n",
            "Epoch #89: Average loss is 0.0018864514590758417\n",
            "Time taken for epoch: 6.258448362350464s\n",
            "\n",
            "\n",
            "Epoch #90: Average loss is 0.0020254494494292884\n",
            ".........................................................\n",
            "Epoch #90: Validation F1 is 1.0\n",
            "Time taken for epoch: 55.89912557601929s\n",
            "\n",
            "\n",
            "Epoch #91: Average loss is 0.0016301097012021476\n",
            "Time taken for epoch: 6.149678707122803s\n",
            "\n",
            "\n",
            "Epoch #92: Average loss is 0.0015612272230080433\n",
            "Time taken for epoch: 6.234804630279541s\n",
            "\n",
            "\n",
            "Epoch #93: Average loss is 0.0016808247185933092\n",
            "Time taken for epoch: 5.036663055419922s\n",
            "\n",
            "\n",
            "Epoch #94: Average loss is 0.001633895853883587\n",
            "Time taken for epoch: 4.604790449142456s\n",
            "\n",
            "\n",
            "Epoch #95: Average loss is 0.001666413845313299\n",
            ".........................................................\n",
            "Epoch #95: Validation F1 is 1.0\n",
            "Time taken for epoch: 55.296212673187256s\n",
            "\n",
            "\n",
            "Epoch #96: Average loss is 0.0016133898039050918\n",
            "Time taken for epoch: 6.236031532287598s\n",
            "\n",
            "\n",
            "Epoch #97: Average loss is 0.00155335903672191\n",
            "Time taken for epoch: 6.186993598937988s\n",
            "\n",
            "\n",
            "Epoch #98: Average loss is 0.0014675861174085487\n",
            "Time taken for epoch: 6.150676012039185s\n",
            "\n",
            "\n",
            "Epoch #99: Average loss is 0.001514052467666463\n",
            "Time taken for epoch: 6.153904438018799s\n",
            "\n",
            "\n",
            "Epoch #100: Average loss is 0.00150527200254146\n",
            ".........................................................\n",
            "Epoch #100: Validation F1 is 1.0\n",
            "Time taken for epoch: 53.99691677093506s\n",
            "\n",
            "\n",
            "Epoch #101: Average loss is 0.0014203369244286377\n",
            "Time taken for epoch: 6.169251918792725s\n",
            "\n",
            "\n",
            "Epoch #102: Average loss is 0.0014527345113068198\n",
            "Time taken for epoch: 6.1533355712890625s\n",
            "\n",
            "\n",
            "Epoch #103: Average loss is 0.0012701491077960882\n",
            "Time taken for epoch: 6.041265249252319s\n",
            "\n",
            "\n",
            "Epoch #104: Average loss is 0.0013416153671763217\n",
            "Time taken for epoch: 6.136312961578369s\n",
            "\n",
            "\n",
            "Epoch #105: Average loss is 0.0012174837933141842\n",
            ".........................................................\n",
            "Epoch #105: Validation F1 is 1.0\n",
            "Time taken for epoch: 53.555368185043335s\n",
            "\n",
            "\n",
            "Epoch #106: Average loss is 0.0012668577573236284\n",
            "Time taken for epoch: 6.106640100479126s\n",
            "\n",
            "\n",
            "Epoch #107: Average loss is 0.0012177743189062716\n",
            "Time taken for epoch: 6.12023663520813s\n",
            "\n",
            "\n",
            "Epoch #108: Average loss is 0.0011771747400052845\n",
            "Time taken for epoch: 6.074797868728638s\n",
            "\n",
            "\n",
            "Epoch #109: Average loss is 0.0013517118498243184\n",
            "Time taken for epoch: 6.1261186599731445s\n",
            "\n",
            "\n",
            "Epoch #110: Average loss is 0.0013068847514255645\n",
            ".........................................................\n",
            "Epoch #110: Validation F1 is 1.0\n",
            "Time taken for epoch: 53.51428985595703s\n",
            "\n",
            "\n",
            "Epoch #111: Average loss is 0.001104498377470817\n",
            "Time taken for epoch: 6.083935737609863s\n",
            "\n",
            "\n",
            "Epoch #112: Average loss is 0.0010562607597805456\n",
            "Time taken for epoch: 6.072673082351685s\n",
            "\n",
            "\n",
            "Epoch #113: Average loss is 0.0010774978912053887\n",
            "Time taken for epoch: 6.120827913284302s\n",
            "\n",
            "\n",
            "Epoch #114: Average loss is 0.0010263503719599814\n",
            "Time taken for epoch: 6.1183366775512695s\n",
            "\n",
            "\n",
            "Epoch #115: Average loss is 0.0010807862014755502\n",
            ".........................................................\n",
            "Epoch #115: Validation F1 is 1.0\n",
            "Time taken for epoch: 53.89240598678589s\n",
            "\n",
            "\n",
            "Epoch #116: Average loss is 0.0012456740521398994\n",
            "Time taken for epoch: 5.845227003097534s\n",
            "\n",
            "\n",
            "Epoch #117: Average loss is 0.001056971546365983\n",
            "Time taken for epoch: 6.130239009857178s\n",
            "\n",
            "\n",
            "Epoch #118: Average loss is 0.0011072145340990068\n",
            "Time taken for epoch: 6.111187934875488s\n",
            "\n",
            "\n",
            "Epoch #119: Average loss is 0.0009956514315045853\n",
            "Time taken for epoch: 6.081917762756348s\n",
            "\n",
            "\n",
            "Epoch #120: Average loss is 0.0010527674205756436\n",
            ".........................................................\n",
            "Epoch #120: Validation F1 is 1.0\n",
            "Time taken for epoch: 55.90172743797302s\n",
            "\n",
            "\n",
            "Epoch #121: Average loss is 0.001163069303050482\n",
            "Time taken for epoch: 5.570906162261963s\n",
            "\n",
            "\n",
            "Epoch #122: Average loss is 0.001017596072860114\n",
            "Time taken for epoch: 4.6575236320495605s\n",
            "\n",
            "\n",
            "Epoch #123: Average loss is 0.0009829665984660905\n",
            "Time taken for epoch: 4.674164056777954s\n",
            "\n",
            "\n",
            "Epoch #124: Average loss is 0.0008885484892784411\n",
            "Time taken for epoch: 6.101512432098389s\n",
            "\n",
            "\n",
            "Epoch #125: Average loss is 0.0011930235586219673\n",
            ".........................................................\n",
            "Epoch #125: Validation F1 is 1.0\n",
            "Time taken for epoch: 56.36125183105469s\n",
            "\n",
            "\n",
            "Epoch #126: Average loss is 0.0009568345843258107\n",
            "Time taken for epoch: 6.137139081954956s\n",
            "\n",
            "\n",
            "Epoch #127: Average loss is 0.0008532211102040795\n",
            "Time taken for epoch: 6.210108280181885s\n",
            "\n",
            "\n",
            "Epoch #128: Average loss is 0.0008543310685652412\n",
            "Time taken for epoch: 6.21027398109436s\n",
            "\n",
            "\n",
            "Epoch #129: Average loss is 0.0009912442946612525\n",
            "Time taken for epoch: 4.874155044555664s\n",
            "\n",
            "\n",
            "Epoch #130: Average loss is 0.0007434415084814342\n",
            ".........................................................\n",
            "Epoch #130: Validation F1 is 1.0\n",
            "Time taken for epoch: 54.26972556114197s\n",
            "\n",
            "\n",
            "Epoch #131: Average loss is 0.0008804844058532682\n",
            "Time taken for epoch: 6.190570116043091s\n",
            "\n",
            "\n",
            "Epoch #132: Average loss is 0.0009527733259730869\n",
            "Time taken for epoch: 6.172441720962524s\n",
            "\n",
            "\n",
            "Epoch #133: Average loss is 0.0008236284241623556\n",
            "Time taken for epoch: 6.132296562194824s\n",
            "\n",
            "\n",
            "Epoch #134: Average loss is 0.0008050444324908312\n",
            "Time taken for epoch: 6.1464619636535645s\n",
            "\n",
            "\n",
            "Epoch #135: Average loss is 0.0009218582987927625\n",
            ".........................................................\n",
            "Epoch #135: Validation F1 is 1.0\n",
            "Time taken for epoch: 54.328757524490356s\n",
            "\n",
            "\n",
            "Epoch #136: Average loss is 0.000829660075800752\n",
            "Time taken for epoch: 6.203700065612793s\n",
            "\n",
            "\n",
            "Epoch #137: Average loss is 0.0008371250253144858\n",
            "Time taken for epoch: 6.195018529891968s\n",
            "\n",
            "\n",
            "Epoch #138: Average loss is 0.0009395180611075679\n",
            "Time taken for epoch: 6.192967176437378s\n",
            "\n",
            "\n",
            "Epoch #139: Average loss is 0.000908502895423832\n",
            "Time taken for epoch: 6.216537237167358s\n",
            "\n",
            "\n",
            "Epoch #140: Average loss is 0.0009108741692681279\n",
            ".........................................................\n",
            "Epoch #140: Validation F1 is 1.0\n",
            "Time taken for epoch: 53.97327399253845s\n",
            "\n",
            "\n",
            "Epoch #141: Average loss is 0.0006610027155612544\n",
            "Time taken for epoch: 6.197954416275024s\n",
            "\n",
            "\n",
            "Epoch #142: Average loss is 0.0008153477629659594\n",
            "Time taken for epoch: 6.1671319007873535s\n",
            "\n",
            "\n",
            "Epoch #143: Average loss is 0.0007319163471725511\n",
            "Time taken for epoch: 6.223365545272827s\n",
            "\n",
            "\n",
            "Epoch #144: Average loss is 0.0008380740414658148\n",
            "Time taken for epoch: 6.219383478164673s\n",
            "\n",
            "\n",
            "Epoch #145: Average loss is 0.0007817329512747367\n",
            ".........................................................\n",
            "Epoch #145: Validation F1 is 1.0\n",
            "Time taken for epoch: 54.44430756568909s\n",
            "\n",
            "\n",
            "Epoch #146: Average loss is 0.0007351026459299546\n",
            "Time taken for epoch: 6.160168647766113s\n",
            "\n",
            "\n",
            "Epoch #147: Average loss is 0.0007525623856377529\n",
            "Time taken for epoch: 6.192046165466309s\n",
            "\n",
            "\n",
            "Epoch #148: Average loss is 0.0007488350189265071\n",
            "Time taken for epoch: 6.2100372314453125s\n",
            "\n",
            "\n",
            "Epoch #149: Average loss is 0.0009576970441493258\n",
            "Time taken for epoch: 6.259013652801514s\n",
            "\n",
            "\n",
            "Epoch #150: Average loss is 0.0006937389846441673\n",
            ".........................................................\n",
            "Epoch #150: Validation F1 is 1.0\n",
            "Time taken for epoch: 54.23399233818054s\n",
            "\n",
            "\n",
            "Epoch #151: Average loss is 0.0008323821901932307\n",
            "Time taken for epoch: 6.216026067733765s\n",
            "\n",
            "\n",
            "Epoch #152: Average loss is 0.0007197921147194898\n",
            "Time taken for epoch: 6.175621271133423s\n",
            "\n",
            "\n",
            "Epoch #153: Average loss is 0.0008020520351419691\n",
            "Time taken for epoch: 6.241904258728027s\n",
            "\n",
            "\n",
            "Epoch #154: Average loss is 0.0006566418778109235\n",
            "Time taken for epoch: 6.121005296707153s\n",
            "\n",
            "\n",
            "Epoch #155: Average loss is 0.000871042559026844\n",
            ".........................................................\n",
            "Epoch #155: Validation F1 is 1.0\n",
            "Time taken for epoch: 56.45130252838135s\n",
            "\n",
            "\n",
            "Epoch #156: Average loss is 0.0006805733791326121\n",
            "Time taken for epoch: 4.745537996292114s\n",
            "\n",
            "\n",
            "Epoch #157: Average loss is 0.0006627782885011078\n",
            "Time taken for epoch: 4.6032023429870605s\n",
            "\n",
            "\n",
            "Epoch #158: Average loss is 0.0008020255109456937\n",
            "Time taken for epoch: 5.4350056648254395s\n",
            "\n",
            "\n",
            "Epoch #159: Average loss is 0.0007094686296962512\n",
            "Time taken for epoch: 6.16666054725647s\n",
            "\n",
            "\n",
            "Epoch #160: Average loss is 0.0005811037566147408\n",
            ".........................................................\n",
            "Epoch #160: Validation F1 is 1.0\n",
            "Time taken for epoch: 56.51287269592285s\n",
            "\n",
            "\n",
            "Epoch #161: Average loss is 0.0007434862025224397\n",
            "Time taken for epoch: 6.2186503410339355s\n",
            "\n",
            "\n",
            "Epoch #162: Average loss is 0.0007462175196916279\n",
            "Time taken for epoch: 6.238769292831421s\n",
            "\n",
            "\n",
            "Epoch #163: Average loss is 0.0006753255888583631\n",
            "Time taken for epoch: 5.446722984313965s\n",
            "\n",
            "\n",
            "Epoch #164: Average loss is 0.0006697653120095816\n",
            "Time taken for epoch: 4.6412880420684814s\n",
            "\n",
            "\n",
            "Epoch #165: Average loss is 0.0007183339754960293\n",
            ".........................................................\n",
            "Epoch #165: Validation F1 is 1.0\n",
            "Time taken for epoch: 54.7279155254364s\n",
            "\n",
            "\n",
            "Epoch #166: Average loss is 0.0006219650090497453\n",
            "Time taken for epoch: 6.178839921951294s\n",
            "\n",
            "\n",
            "Epoch #167: Average loss is 0.000630162075912166\n",
            "Time taken for epoch: 6.196357727050781s\n",
            "\n",
            "\n",
            "Epoch #168: Average loss is 0.0007059317157028191\n",
            "Time taken for epoch: 6.159864664077759s\n",
            "\n",
            "\n",
            "Epoch #169: Average loss is 0.0007211543503621619\n",
            "Time taken for epoch: 6.1487815380096436s\n",
            "\n",
            "\n",
            "Epoch #170: Average loss is 0.000608985523164544\n",
            ".........................................................\n",
            "Epoch #170: Validation F1 is 1.0\n",
            "Time taken for epoch: 55.3217556476593s\n",
            "\n",
            "\n",
            "Epoch #171: Average loss is 0.0004947555794044294\n",
            "Time taken for epoch: 6.291874885559082s\n",
            "\n",
            "\n",
            "Epoch #172: Average loss is 0.0007444214979477693\n",
            "Time taken for epoch: 6.296535015106201s\n",
            "\n",
            "\n",
            "Epoch #173: Average loss is 0.0006314686857513152\n",
            "Time taken for epoch: 6.228407859802246s\n",
            "\n",
            "\n",
            "Epoch #174: Average loss is 0.0007085363576738422\n",
            "Time taken for epoch: 6.220474004745483s\n",
            "\n",
            "\n",
            "Epoch #175: Average loss is 0.0006163799132385369\n",
            ".........................................................\n",
            "Epoch #175: Validation F1 is 1.0\n",
            "Time taken for epoch: 56.20119857788086s\n",
            "\n",
            "\n",
            "Epoch #176: Average loss is 0.0006886315747558708\n",
            "Time taken for epoch: 6.277035236358643s\n",
            "\n",
            "\n",
            "Epoch #177: Average loss is 0.0005913075681099953\n",
            "Time taken for epoch: 6.27292799949646s\n",
            "\n",
            "\n",
            "Epoch #178: Average loss is 0.0007299899996481448\n",
            "Time taken for epoch: 6.246031999588013s\n",
            "\n",
            "\n",
            "Epoch #179: Average loss is 0.0006820260340140925\n",
            "Time taken for epoch: 6.243102550506592s\n",
            "\n",
            "\n",
            "Epoch #180: Average loss is 0.00071403006533122\n",
            ".........................................................\n",
            "Epoch #180: Validation F1 is 1.0\n",
            "Time taken for epoch: 56.223878622055054s\n",
            "\n",
            "\n",
            "Epoch #181: Average loss is 0.00048825585909879817\n",
            "Time taken for epoch: 6.2488133907318115s\n",
            "\n",
            "\n",
            "Epoch #182: Average loss is 0.0006482463302866867\n",
            "Time taken for epoch: 6.250208139419556s\n",
            "\n",
            "\n",
            "Epoch #183: Average loss is 0.0007192586748876945\n",
            "Time taken for epoch: 6.220529317855835s\n",
            "\n",
            "\n",
            "Epoch #184: Average loss is 0.0005643970353654974\n",
            "Time taken for epoch: 6.2233359813690186s\n",
            "\n",
            "\n",
            "Epoch #185: Average loss is 0.0005059785857075541\n",
            ".........................................................\n",
            "Epoch #185: Validation F1 is 1.0\n",
            "Time taken for epoch: 56.52105259895325s\n",
            "\n",
            "\n",
            "Epoch #186: Average loss is 0.0006263306158345788\n",
            "Time taken for epoch: 6.236769914627075s\n",
            "\n",
            "\n",
            "Epoch #187: Average loss is 0.0007340225374921122\n",
            "Time taken for epoch: 6.287763595581055s\n",
            "\n",
            "\n",
            "Epoch #188: Average loss is 0.0006279131221365081\n",
            "Time taken for epoch: 6.32504415512085s\n",
            "\n",
            "\n",
            "Epoch #189: Average loss is 0.0005703143828092531\n",
            "Time taken for epoch: 6.243462562561035s\n",
            "\n",
            "\n",
            "Epoch #190: Average loss is 0.0006585949108800075\n",
            ".........................................................\n",
            "Epoch #190: Validation F1 is 1.0\n",
            "Time taken for epoch: 56.08055758476257s\n",
            "\n",
            "\n",
            "Epoch #191: Average loss is 0.0005600340213519909\n",
            "Time taken for epoch: 6.23085618019104s\n",
            "\n",
            "\n",
            "Epoch #192: Average loss is 0.00047864522280481955\n",
            "Time taken for epoch: 6.215572118759155s\n",
            "\n",
            "\n",
            "Epoch #193: Average loss is 0.0006373546855239612\n",
            "Time taken for epoch: 6.234889507293701s\n",
            "\n",
            "\n",
            "Epoch #194: Average loss is 0.00057829383421146\n",
            "Time taken for epoch: 6.190078973770142s\n",
            "\n",
            "\n",
            "Epoch #195: Average loss is 0.0005758361289028674\n",
            ".........................................................\n",
            "Epoch #195: Validation F1 is 1.0\n",
            "Time taken for epoch: 56.44354701042175s\n",
            "\n",
            "\n",
            "Epoch #196: Average loss is 0.0007370922164005202\n",
            "Time taken for epoch: 6.248011827468872s\n",
            "\n",
            "\n",
            "Epoch #197: Average loss is 0.00048137811179508894\n",
            "Time taken for epoch: 6.297720909118652s\n",
            "\n",
            "\n",
            "Epoch #198: Average loss is 0.0006530852836779862\n",
            "Time taken for epoch: 6.2442944049835205s\n",
            "\n",
            "\n",
            "Epoch #199: Average loss is 0.0005412334291112429\n",
            "Time taken for epoch: 6.245243310928345s\n",
            "\n",
            "\n",
            "Epoch #200: Average loss is 0.0005800603532892031\n",
            ".........................................................\n",
            "Epoch #200: Validation F1 is 1.0\n",
            "Time taken for epoch: 57.45781850814819s\n",
            "\n",
            "\n",
            "Epoch #201: Average loss is 0.0005416164556825404\n",
            "Time taken for epoch: 4.921418905258179s\n",
            "\n",
            "\n",
            "Epoch #202: Average loss is 0.0005569009946339065\n",
            "Time taken for epoch: 5.4379754066467285s\n",
            "\n",
            "\n",
            "Epoch #203: Average loss is 0.0005734155877871672\n",
            "Time taken for epoch: 6.2429609298706055s\n",
            "\n",
            "\n",
            "Epoch #204: Average loss is 0.0004283724438735387\n",
            "Time taken for epoch: 6.26149845123291s\n",
            "\n",
            "\n",
            "Epoch #205: Average loss is 0.0006368686944349773\n",
            ".........................................................\n",
            "Epoch #205: Validation F1 is 1.0\n",
            "Time taken for epoch: 57.81114101409912s\n",
            "\n",
            "\n",
            "Epoch #206: Average loss is 0.0006225670454781115\n",
            "Time taken for epoch: 6.241177797317505s\n",
            "\n",
            "\n",
            "Epoch #207: Average loss is 0.0004882499036628158\n",
            "Time taken for epoch: 5.149315357208252s\n",
            "\n",
            "\n",
            "Epoch #208: Average loss is 0.0005314546216686722\n",
            "Time taken for epoch: 4.912918567657471s\n",
            "\n",
            "\n",
            "Epoch #209: Average loss is 0.0005658047515074335\n",
            "Time taken for epoch: 5.703100681304932s\n",
            "\n",
            "\n",
            "Epoch #210: Average loss is 0.0005830617510865624\n",
            ".........................................................\n",
            "Epoch #210: Validation F1 is 1.0\n",
            "Time taken for epoch: 57.626057147979736s\n",
            "\n",
            "\n",
            "Epoch #211: Average loss is 0.0005906048610712686\n",
            "Time taken for epoch: 6.281238317489624s\n",
            "\n",
            "\n",
            "Epoch #212: Average loss is 0.0004521711543849152\n",
            "Time taken for epoch: 6.225271701812744s\n",
            "\n",
            "\n",
            "Epoch #213: Average loss is 0.0004791961222872487\n",
            "Time taken for epoch: 6.310126543045044s\n",
            "\n",
            "\n",
            "Epoch #214: Average loss is 0.0005932713836470308\n",
            "Time taken for epoch: 5.087280750274658s\n",
            "\n",
            "\n",
            "Epoch #215: Average loss is 0.00048411631099750394\n",
            ".........................................................\n",
            "Epoch #215: Validation F1 is 1.0\n",
            "Time taken for epoch: 56.515970945358276s\n",
            "\n",
            "\n",
            "Epoch #216: Average loss is 0.0005096570666622332\n",
            "Time taken for epoch: 6.28403115272522s\n",
            "\n",
            "\n",
            "Epoch #217: Average loss is 0.0005873499543829692\n",
            "Time taken for epoch: 6.28974175453186s\n",
            "\n",
            "\n",
            "Epoch #218: Average loss is 0.0005511679873921417\n",
            "Time taken for epoch: 6.220882177352905s\n",
            "\n",
            "\n",
            "Epoch #219: Average loss is 0.0005050215424327891\n",
            "Time taken for epoch: 6.243514060974121s\n",
            "\n",
            "\n",
            "Epoch #220: Average loss is 0.0006365582570449786\n",
            ".........................................................\n",
            "Epoch #220: Validation F1 is 1.0\n",
            "Time taken for epoch: 56.128318071365356s\n",
            "\n",
            "\n",
            "Epoch #221: Average loss is 0.0005022337871681278\n",
            "Time taken for epoch: 6.2537384033203125s\n",
            "\n",
            "\n",
            "Epoch #222: Average loss is 0.0005317491727409004\n",
            "Time taken for epoch: 6.244167327880859s\n",
            "\n",
            "\n",
            "Epoch #223: Average loss is 0.0005785969965816346\n",
            "Time taken for epoch: 6.252583742141724s\n",
            "\n",
            "\n",
            "Epoch #224: Average loss is 0.00044970835508946846\n",
            "Time taken for epoch: 6.2522056102752686s\n",
            "\n",
            "\n",
            "Epoch #225: Average loss is 0.0005109197433840664\n",
            ".........................................................\n",
            "Epoch #225: Validation F1 is 1.0\n",
            "Time taken for epoch: 56.09410810470581s\n",
            "\n",
            "\n",
            "Epoch #226: Average loss is 0.0004262450691587421\n",
            "Time taken for epoch: 6.261147499084473s\n",
            "\n",
            "\n",
            "Epoch #227: Average loss is 0.00058065149507052\n",
            "Time taken for epoch: 6.24388575553894s\n",
            "\n",
            "\n",
            "Epoch #228: Average loss is 0.00039677558172115826\n",
            "Time taken for epoch: 6.293525457382202s\n",
            "\n",
            "\n",
            "Epoch #229: Average loss is 0.0004821911880329329\n",
            "Time taken for epoch: 6.241097688674927s\n",
            "\n",
            "\n",
            "Epoch #230: Average loss is 0.0004990266043751035\n",
            ".........................................................\n",
            "Epoch #230: Validation F1 is 1.0\n",
            "Time taken for epoch: 56.088056325912476s\n",
            "\n",
            "\n",
            "Epoch #231: Average loss is 0.0005891589943106131\n",
            "Time taken for epoch: 6.279316663742065s\n",
            "\n",
            "\n",
            "Epoch #232: Average loss is 0.0005891679358602333\n",
            "Time taken for epoch: 6.210872173309326s\n",
            "\n",
            "\n",
            "Epoch #233: Average loss is 0.0005146063797534831\n",
            "Time taken for epoch: 6.250427961349487s\n",
            "\n",
            "\n",
            "Epoch #234: Average loss is 0.0005380289349624137\n",
            "Time taken for epoch: 6.259818077087402s\n",
            "\n",
            "\n",
            "Epoch #235: Average loss is 0.0004854934598147843\n",
            ".........................................................\n",
            "Epoch #235: Validation F1 is 1.0\n",
            "Time taken for epoch: 55.933125257492065s\n",
            "\n",
            "\n",
            "Epoch #236: Average loss is 0.0004419799383766884\n",
            "Time taken for epoch: 6.211800575256348s\n",
            "\n",
            "\n",
            "Epoch #237: Average loss is 0.00047927298199081434\n",
            "Time taken for epoch: 6.2304463386535645s\n",
            "\n",
            "\n",
            "Epoch #238: Average loss is 0.0004342980389628792\n",
            "Time taken for epoch: 6.298433065414429s\n",
            "\n",
            "\n",
            "Epoch #239: Average loss is 0.0004908994439433122\n",
            "Time taken for epoch: 6.282296657562256s\n",
            "\n",
            "\n",
            "Epoch #240: Average loss is 0.00061804708740965\n",
            ".........................................................\n",
            "Epoch #240: Validation F1 is 1.0\n",
            "Time taken for epoch: 56.256627798080444s\n",
            "\n",
            "\n",
            "Epoch #241: Average loss is 0.0004582909430044108\n",
            "Time taken for epoch: 6.155247926712036s\n",
            "\n",
            "\n",
            "Epoch #242: Average loss is 0.0004479938023036488\n",
            "Time taken for epoch: 6.29421067237854s\n",
            "\n",
            "\n",
            "Epoch #243: Average loss is 0.00047918677010279175\n",
            "Time taken for epoch: 6.287724256515503s\n",
            "\n",
            "\n",
            "Epoch #244: Average loss is 0.0005096005650719032\n",
            "Time taken for epoch: 6.270272493362427s\n",
            "\n",
            "\n",
            "Epoch #245: Average loss is 0.0004658921924500545\n",
            ".........................................................\n",
            "Epoch #245: Validation F1 is 1.0\n",
            "Time taken for epoch: 56.19662809371948s\n",
            "\n",
            "\n",
            "Epoch #246: Average loss is 0.0004489891295330987\n",
            "Time taken for epoch: 6.316530227661133s\n",
            "\n",
            "\n",
            "Epoch #247: Average loss is 0.0005280986288158197\n",
            "Time taken for epoch: 6.341944217681885s\n",
            "\n",
            "\n",
            "Epoch #248: Average loss is 0.00046953167098561405\n",
            "Time taken for epoch: 6.30487585067749s\n",
            "\n",
            "\n",
            "Epoch #249: Average loss is 0.0003967552859264995\n",
            "Time taken for epoch: 6.272264003753662s\n",
            "\n",
            "\n",
            "Epoch #250: Average loss is 0.0004404288585929963\n",
            ".........................................................\n",
            "Epoch #250: Validation F1 is 1.0\n",
            "Time taken for epoch: 56.9336633682251s\n",
            "\n",
            "\n",
            "Epoch #251: Average loss is 0.000462556097574836\n",
            "Time taken for epoch: 4.779822587966919s\n",
            "\n",
            "\n",
            "Epoch #252: Average loss is 0.00044983105490246087\n",
            "Time taken for epoch: 6.258135080337524s\n",
            "\n",
            "\n",
            "Epoch #253: Average loss is 0.0005288521317803922\n",
            "Time taken for epoch: 6.2372987270355225s\n",
            "\n",
            "\n",
            "Epoch #254: Average loss is 0.0005116578071303795\n",
            "Time taken for epoch: 6.243643283843994s\n",
            "\n",
            "\n",
            "Epoch #255: Average loss is 0.0004638209260964585\n",
            ".........................................................\n",
            "Epoch #255: Validation F1 is 1.0\n",
            "Time taken for epoch: 57.58033847808838s\n",
            "\n",
            "\n",
            "Epoch #256: Average loss is 0.00040560432014091123\n",
            "Time taken for epoch: 5.75696325302124s\n",
            "\n",
            "\n",
            "Epoch #257: Average loss is 0.0005652794026334757\n",
            "Time taken for epoch: 4.817903757095337s\n",
            "\n",
            "\n",
            "Epoch #258: Average loss is 0.000350678512926\n",
            "Time taken for epoch: 5.018535375595093s\n",
            "\n",
            "\n",
            "Epoch #259: Average loss is 0.0006591785400289357\n",
            "Time taken for epoch: 6.262020111083984s\n",
            "\n",
            "\n",
            "Epoch #260: Average loss is 0.00040782607821003894\n",
            ".........................................................\n",
            "Epoch #260: Validation F1 is 1.0\n",
            "Time taken for epoch: 57.512696266174316s\n",
            "\n",
            "\n",
            "Epoch #261: Average loss is 0.0005065482321272915\n",
            "Time taken for epoch: 6.268416404724121s\n",
            "\n",
            "\n",
            "Epoch #262: Average loss is 0.0004878586402628571\n",
            "Time taken for epoch: 6.274250507354736s\n",
            "\n",
            "\n",
            "Epoch #263: Average loss is 0.0004302425097800248\n",
            "Time taken for epoch: 5.731372594833374s\n",
            "\n",
            "\n",
            "Epoch #264: Average loss is 0.0005111467413331007\n",
            "Time taken for epoch: 5.014665603637695s\n",
            "\n",
            "\n",
            "Epoch #265: Average loss is 0.0004010204989026533\n",
            ".........................................................\n",
            "Epoch #265: Validation F1 is 1.0\n",
            "Time taken for epoch: 56.50448751449585s\n",
            "\n",
            "\n",
            "Epoch #266: Average loss is 0.0005844726848348122\n",
            "Time taken for epoch: 6.243048667907715s\n",
            "\n",
            "\n",
            "Epoch #267: Average loss is 0.0005047268155127919\n",
            "Time taken for epoch: 6.234764337539673s\n",
            "\n",
            "\n",
            "Epoch #268: Average loss is 0.0003948481436681403\n",
            "Time taken for epoch: 6.182496547698975s\n",
            "\n",
            "\n",
            "Epoch #269: Average loss is 0.00043196584228604075\n",
            "Time taken for epoch: 6.22558069229126s\n",
            "\n",
            "\n",
            "Epoch #270: Average loss is 0.0004568325390250215\n",
            ".........................................................\n",
            "Epoch #270: Validation F1 is 1.0\n",
            "Time taken for epoch: 55.719600677490234s\n",
            "\n",
            "\n",
            "Epoch #271: Average loss is 0.000476084584463226\n",
            "Time taken for epoch: 6.21769642829895s\n",
            "\n",
            "\n",
            "Epoch #272: Average loss is 0.000501633838697065\n",
            "Time taken for epoch: 6.232313632965088s\n",
            "\n",
            "\n",
            "Epoch #273: Average loss is 0.00047997900507956124\n",
            "Time taken for epoch: 6.215752601623535s\n",
            "\n",
            "\n",
            "Epoch #274: Average loss is 0.0005607921632084375\n",
            "Time taken for epoch: 6.248729705810547s\n",
            "\n",
            "\n",
            "Epoch #275: Average loss is 0.000419962769366167\n",
            ".........................................................\n",
            "Epoch #275: Validation F1 is 1.0\n",
            "Time taken for epoch: 56.21712589263916s\n",
            "\n",
            "\n",
            "Epoch #276: Average loss is 0.0003765724449072473\n",
            "Time taken for epoch: 6.248038053512573s\n",
            "\n",
            "\n",
            "Epoch #277: Average loss is 0.0003563955250865547\n",
            "Time taken for epoch: 6.251576900482178s\n",
            "\n",
            "\n",
            "Epoch #278: Average loss is 0.000451249031324955\n",
            "Time taken for epoch: 6.228958606719971s\n",
            "\n",
            "\n",
            "Epoch #279: Average loss is 0.00048358538627023035\n",
            "Time taken for epoch: 6.284329175949097s\n",
            "\n",
            "\n",
            "Epoch #280: Average loss is 0.0005197597775703697\n",
            ".........................................................\n",
            "Epoch #280: Validation F1 is 1.0\n",
            "Time taken for epoch: 55.90612173080444s\n",
            "\n",
            "\n",
            "Epoch #281: Average loss is 0.0003793964705336192\n",
            "Time taken for epoch: 6.222267150878906s\n",
            "\n",
            "\n",
            "Epoch #282: Average loss is 0.00034214214954166283\n",
            "Time taken for epoch: 6.2632012367248535s\n",
            "\n",
            "\n",
            "Epoch #283: Average loss is 0.0004112737613993684\n",
            "Time taken for epoch: 6.270475625991821s\n",
            "\n",
            "\n",
            "Epoch #284: Average loss is 0.00046647609446356204\n",
            "Time taken for epoch: 6.290919065475464s\n",
            "\n",
            "\n",
            "Epoch #285: Average loss is 0.0004930513997128906\n",
            ".........................................................\n",
            "Epoch #285: Validation F1 is 1.0\n",
            "Time taken for epoch: 56.342878103256226s\n",
            "\n",
            "\n",
            "Epoch #286: Average loss is 0.000382499547647765\n",
            "Time taken for epoch: 6.2666308879852295s\n",
            "\n",
            "\n",
            "Epoch #287: Average loss is 0.00040814105500531795\n",
            "Time taken for epoch: 6.247302532196045s\n",
            "\n",
            "\n",
            "Epoch #288: Average loss is 0.000556805040206301\n",
            "Time taken for epoch: 6.256489276885986s\n",
            "\n",
            "\n",
            "Epoch #289: Average loss is 0.00035729370094284403\n",
            "Time taken for epoch: 6.237700939178467s\n",
            "\n",
            "\n",
            "Epoch #290: Average loss is 0.00031166004777333\n",
            ".........................................................\n",
            "Epoch #290: Validation F1 is 1.0\n",
            "Time taken for epoch: 56.385592222213745s\n",
            "\n",
            "\n",
            "Epoch #291: Average loss is 0.00035640963698016194\n",
            "Time taken for epoch: 6.250882387161255s\n",
            "\n",
            "\n",
            "Epoch #292: Average loss is 0.00046606820770345316\n",
            "Time taken for epoch: 6.241938352584839s\n",
            "\n",
            "\n",
            "Epoch #293: Average loss is 0.000648846982553045\n",
            "Time taken for epoch: 6.263030052185059s\n",
            "\n",
            "\n",
            "Epoch #294: Average loss is 0.00030175531926134784\n",
            "Time taken for epoch: 6.267122030258179s\n",
            "\n",
            "\n",
            "Epoch #295: Average loss is 0.0003565434332025082\n",
            ".........................................................\n",
            "Epoch #295: Validation F1 is 1.0\n",
            "Time taken for epoch: 56.058202505111694s\n",
            "\n",
            "\n",
            "Epoch #296: Average loss is 0.00034939559772384303\n",
            "Time taken for epoch: 6.253013610839844s\n",
            "\n",
            "\n",
            "Epoch #297: Average loss is 0.0003870484291069766\n",
            "Time taken for epoch: 6.272738695144653s\n",
            "\n",
            "\n",
            "Epoch #298: Average loss is 0.0004457486408743231\n",
            "Time taken for epoch: 6.230085849761963s\n",
            "\n",
            "\n",
            "Epoch #299: Average loss is 0.0004647181200036559\n",
            "Time taken for epoch: 6.2730278968811035s\n",
            "\n",
            "\n",
            "Epoch #300: Average loss is 0.00040805532880767715\n",
            ".........................................................\n",
            "Epoch #300: Validation F1 is 1.0\n",
            "Time taken for epoch: 57.069228410720825s\n",
            "\n",
            "\n",
            "Epoch #301: Average loss is 0.0004786637603562364\n",
            "Time taken for epoch: 5.040373086929321s\n",
            "\n",
            "\n",
            "Epoch #302: Average loss is 0.0005241316814984505\n",
            "Time taken for epoch: 6.256245851516724s\n",
            "\n",
            "\n",
            "Epoch #303: Average loss is 0.0003415645619154222\n",
            "Time taken for epoch: 6.25885796546936s\n",
            "\n",
            "\n",
            "Epoch #304: Average loss is 0.00044702228458239307\n",
            "Time taken for epoch: 6.241139888763428s\n",
            "\n",
            "\n",
            "Epoch #305: Average loss is 0.0003614134907709538\n",
            ".........................................................\n",
            "Epoch #305: Validation F1 is 1.0\n",
            "Time taken for epoch: 57.62580680847168s\n",
            "\n",
            "\n",
            "Epoch #306: Average loss is 0.00035691938103506497\n",
            "Time taken for epoch: 5.514845132827759s\n",
            "\n",
            "\n",
            "Epoch #307: Average loss is 0.0004126772319755724\n",
            "Time taken for epoch: 4.824620485305786s\n",
            "\n",
            "\n",
            "Epoch #308: Average loss is 0.0004011675195458035\n",
            "Time taken for epoch: 5.131694793701172s\n",
            "\n",
            "\n",
            "Epoch #309: Average loss is 0.0003709017167865467\n",
            "Time taken for epoch: 6.287289619445801s\n",
            "\n",
            "\n",
            "Epoch #310: Average loss is 0.0005867947032270927\n",
            ".........................................................\n",
            "Epoch #310: Validation F1 is 1.0\n",
            "Time taken for epoch: 57.69613480567932s\n",
            "\n",
            "\n",
            "Epoch #311: Average loss is 0.0004386217876809597\n",
            "Time taken for epoch: 6.251998662948608s\n",
            "\n",
            "\n",
            "Epoch #312: Average loss is 0.00041742246476335115\n",
            "Time taken for epoch: 6.2726967334747314s\n",
            "\n",
            "\n",
            "Epoch #313: Average loss is 0.000423992829528288\n",
            "Time taken for epoch: 5.298425912857056s\n",
            "\n",
            "\n",
            "Epoch #314: Average loss is 0.00046888584493798486\n",
            "Time taken for epoch: 4.825155735015869s\n",
            "\n",
            "\n",
            "Epoch #315: Average loss is 0.0004091490418876573\n",
            ".........................................................\n",
            "Epoch #315: Validation F1 is 1.0\n",
            "Time taken for epoch: 56.88253617286682s\n",
            "\n",
            "\n",
            "Epoch #316: Average loss is 0.0003846404192113874\n",
            "Time taken for epoch: 6.23326563835144s\n",
            "\n",
            "\n",
            "Epoch #317: Average loss is 0.00032894698336652557\n",
            "Time taken for epoch: 6.22444224357605s\n",
            "\n",
            "\n",
            "Epoch #318: Average loss is 0.0004722325419829253\n",
            "Time taken for epoch: 6.246742248535156s\n",
            "\n",
            "\n",
            "Epoch #319: Average loss is 0.0005005807596333196\n",
            "Time taken for epoch: 6.2503533363342285s\n",
            "\n",
            "\n",
            "Epoch #320: Average loss is 0.00038557513352417217\n",
            ".........................................................\n",
            "Epoch #320: Validation F1 is 1.0\n",
            "Time taken for epoch: 55.47600603103638s\n",
            "\n",
            "\n",
            "Epoch #321: Average loss is 0.0003420417664427886\n",
            "Time taken for epoch: 6.2649009227752686s\n",
            "\n",
            "\n",
            "Epoch #322: Average loss is 0.000373765128448819\n",
            "Time taken for epoch: 6.235234260559082s\n",
            "\n",
            "\n",
            "Epoch #323: Average loss is 0.0003887863006881768\n",
            "Time taken for epoch: 6.313864231109619s\n",
            "\n",
            "\n",
            "Epoch #324: Average loss is 0.00040297184678315213\n",
            "Time taken for epoch: 6.253832101821899s\n",
            "\n",
            "\n",
            "Epoch #325: Average loss is 0.0003865968047021953\n",
            ".........................................................\n",
            "Epoch #325: Validation F1 is 1.0\n",
            "Time taken for epoch: 55.983086585998535s\n",
            "\n",
            "\n",
            "Epoch #326: Average loss is 0.00043473994295103086\n",
            "Time taken for epoch: 6.247692823410034s\n",
            "\n",
            "\n",
            "Epoch #327: Average loss is 0.0004101391602267136\n",
            "Time taken for epoch: 6.262906312942505s\n",
            "\n",
            "\n",
            "Epoch #328: Average loss is 0.00035010712631143787\n",
            "Time taken for epoch: 6.216540575027466s\n",
            "\n",
            "\n",
            "Epoch #329: Average loss is 0.00035509752972656217\n",
            "Time taken for epoch: 6.296576261520386s\n",
            "\n",
            "\n",
            "Epoch #330: Average loss is 0.00040056092245019197\n",
            ".........................................................\n",
            "Epoch #330: Validation F1 is 1.0\n",
            "Time taken for epoch: 56.27645206451416s\n",
            "\n",
            "\n",
            "Epoch #331: Average loss is 0.00027855263813762575\n",
            "Time taken for epoch: 6.259039878845215s\n",
            "\n",
            "\n",
            "Epoch #332: Average loss is 0.0004232400582259288\n",
            "Time taken for epoch: 6.228729963302612s\n",
            "\n",
            "\n",
            "Epoch #333: Average loss is 0.00034520411855434456\n",
            "Time taken for epoch: 6.2665321826934814s\n",
            "\n",
            "\n",
            "Epoch #334: Average loss is 0.0003809771727780268\n",
            "Time taken for epoch: 6.239777326583862s\n",
            "\n",
            "\n",
            "Epoch #335: Average loss is 0.0003770262934873851\n",
            ".........................................................\n",
            "Epoch #335: Validation F1 is 1.0\n",
            "Time taken for epoch: 56.26569437980652s\n",
            "\n",
            "\n",
            "Epoch #336: Average loss is 0.0004934528546153969\n",
            "Time taken for epoch: 6.227691888809204s\n",
            "\n",
            "\n",
            "Epoch #337: Average loss is 0.0002939878463439527\n",
            "Time taken for epoch: 6.275386810302734s\n",
            "\n",
            "\n",
            "Epoch #338: Average loss is 0.00036541832971933116\n",
            "Time taken for epoch: 6.2328362464904785s\n",
            "\n",
            "\n",
            "Epoch #339: Average loss is 0.0004825979806183669\n",
            "Time taken for epoch: 6.235679864883423s\n",
            "\n",
            "\n",
            "Epoch #340: Average loss is 0.00030540924812764086\n",
            ".........................................................\n",
            "Epoch #340: Validation F1 is 1.0\n",
            "Time taken for epoch: 56.11160397529602s\n",
            "\n",
            "\n",
            "Epoch #341: Average loss is 0.000400662312072705\n",
            "Time taken for epoch: 6.237682819366455s\n",
            "\n",
            "\n",
            "Epoch #342: Average loss is 0.0005981365347421767\n",
            "Time taken for epoch: 6.25370979309082s\n",
            "\n",
            "\n",
            "Epoch #343: Average loss is 0.00033808228184271786\n",
            "Time taken for epoch: 6.253227710723877s\n",
            "\n",
            "\n",
            "Epoch #344: Average loss is 0.0002715523838075266\n",
            "Time taken for epoch: 6.279971599578857s\n",
            "\n",
            "\n",
            "Epoch #345: Average loss is 0.0003746808365192717\n",
            ".........................................................\n",
            "Epoch #345: Validation F1 is 1.0\n",
            "Time taken for epoch: 56.04377841949463s\n",
            "\n",
            "\n",
            "Epoch #346: Average loss is 0.0002960244765846356\n",
            "Time taken for epoch: 6.307840824127197s\n",
            "\n",
            "\n",
            "Epoch #347: Average loss is 0.0003759988633585939\n",
            "Time taken for epoch: 6.280973434448242s\n",
            "\n",
            "\n",
            "Epoch #348: Average loss is 0.0003387398533575631\n",
            "Time taken for epoch: 6.233387470245361s\n",
            "\n",
            "\n",
            "Epoch #349: Average loss is 0.0003064315007314791\n",
            "Time taken for epoch: 6.2434306144714355s\n",
            "\n",
            "\n",
            "Epoch #350: Average loss is 0.00039329667550595733\n",
            ".........................................................\n",
            "Epoch #350: Validation F1 is 1.0\n",
            "Time taken for epoch: 56.52556610107422s\n",
            "\n",
            "\n",
            "Epoch #351: Average loss is 0.00037849109646130173\n",
            "Time taken for epoch: 5.1120593547821045s\n",
            "\n",
            "\n",
            "Epoch #352: Average loss is 0.00044392524998935795\n",
            "Time taken for epoch: 6.231485605239868s\n",
            "\n",
            "\n",
            "Epoch #353: Average loss is 0.0004084943606883624\n",
            "Time taken for epoch: 6.259331703186035s\n",
            "\n",
            "\n",
            "Epoch #354: Average loss is 0.00031061232884692597\n",
            "Time taken for epoch: 6.241950035095215s\n",
            "\n",
            "\n",
            "Epoch #355: Average loss is 0.00044324083591669076\n",
            ".........................................................\n",
            "Epoch #355: Validation F1 is 1.0\n",
            "Time taken for epoch: 56.96171760559082s\n",
            "\n",
            "\n",
            "Epoch #356: Average loss is 0.0003712983215680449\n",
            "Time taken for epoch: 6.179131031036377s\n",
            "\n",
            "\n",
            "Epoch #357: Average loss is 0.00040752863977912865\n",
            "Time taken for epoch: 4.980419635772705s\n",
            "\n",
            "\n",
            "Epoch #358: Average loss is 0.000303200003149363\n",
            "Time taken for epoch: 5.067681312561035s\n",
            "\n",
            "\n",
            "Epoch #359: Average loss is 0.00034969346766350405\n",
            "Time taken for epoch: 6.1695396900177s\n",
            "\n",
            "\n",
            "Epoch #360: Average loss is 0.0003356803363122809\n",
            ".........................................................\n",
            "Epoch #360: Validation F1 is 1.0\n",
            "Time taken for epoch: 57.07782435417175s\n",
            "\n",
            "\n",
            "Epoch #361: Average loss is 0.0002976333301416566\n",
            "Time taken for epoch: 6.258594512939453s\n",
            "\n",
            "\n",
            "Epoch #362: Average loss is 0.00045347027027876013\n",
            "Time taken for epoch: 6.232915878295898s\n",
            "\n",
            "\n",
            "Epoch #363: Average loss is 0.0002450487404368889\n",
            "Time taken for epoch: 6.169361114501953s\n",
            "\n",
            "\n",
            "Epoch #364: Average loss is 0.00046656998291938283\n",
            "Time taken for epoch: 5.1558756828308105s\n",
            "\n",
            "\n",
            "Epoch #365: Average loss is 0.0003204105120959058\n",
            ".........................................................\n",
            "Epoch #365: Validation F1 is 1.0\n",
            "Time taken for epoch: 56.471861600875854s\n",
            "\n",
            "\n",
            "Epoch #366: Average loss is 0.0003493586803839814\n",
            "Time taken for epoch: 6.240405082702637s\n",
            "\n",
            "\n",
            "Epoch #367: Average loss is 0.00037995893720007087\n",
            "Time taken for epoch: 6.289059162139893s\n",
            "\n",
            "\n",
            "Epoch #368: Average loss is 0.00022780981080561307\n",
            "Time taken for epoch: 6.222254514694214s\n",
            "\n",
            "\n",
            "Epoch #369: Average loss is 0.0003261696239375548\n",
            "Time taken for epoch: 6.250654697418213s\n",
            "\n",
            "\n",
            "Epoch #370: Average loss is 0.00044395912842850926\n",
            ".........................................................\n",
            "Epoch #370: Validation F1 is 1.0\n",
            "Time taken for epoch: 55.9355947971344s\n",
            "\n",
            "\n",
            "Epoch #371: Average loss is 0.00035699939002774446\n",
            "Time taken for epoch: 6.301888465881348s\n",
            "\n",
            "\n",
            "Epoch #372: Average loss is 0.0004096194884752751\n",
            "Time taken for epoch: 6.246968030929565s\n",
            "\n",
            "\n",
            "Epoch #373: Average loss is 0.0003469869171870717\n",
            "Time taken for epoch: 6.253591060638428s\n",
            "\n",
            "\n",
            "Epoch #374: Average loss is 0.0002962763100489004\n",
            "Time taken for epoch: 6.244016647338867s\n",
            "\n",
            "\n",
            "Epoch #375: Average loss is 0.00035497282732750235\n",
            ".........................................................\n",
            "Epoch #375: Validation F1 is 1.0\n",
            "Time taken for epoch: 56.41678833961487s\n",
            "\n",
            "\n",
            "Epoch #376: Average loss is 0.00028907354251310203\n",
            "Time taken for epoch: 6.30418586730957s\n",
            "\n",
            "\n",
            "Epoch #377: Average loss is 0.00032740118443244783\n",
            "Time taken for epoch: 6.280698299407959s\n",
            "\n",
            "\n",
            "Epoch #378: Average loss is 0.0003762393503085251\n",
            "Time taken for epoch: 6.22004246711731s\n",
            "\n",
            "\n",
            "Epoch #379: Average loss is 0.0005004510680656595\n",
            "Time taken for epoch: 6.2510364055633545s\n",
            "\n",
            "\n",
            "Epoch #380: Average loss is 0.00034260173422606183\n",
            ".........................................................\n",
            "Epoch #380: Validation F1 is 1.0\n",
            "Time taken for epoch: 55.98083472251892s\n",
            "\n",
            "\n",
            "Epoch #381: Average loss is 0.00027056583096257073\n",
            "Time taken for epoch: 6.238861322402954s\n",
            "\n",
            "\n",
            "Epoch #382: Average loss is 0.0003309380064213959\n",
            "Time taken for epoch: 6.283870458602905s\n",
            "\n",
            "\n",
            "Epoch #383: Average loss is 0.00034977490211329294\n",
            "Time taken for epoch: 6.2275614738464355s\n",
            "\n",
            "\n",
            "Epoch #384: Average loss is 0.00033215274568849256\n",
            "Time taken for epoch: 6.240620374679565s\n",
            "\n",
            "\n",
            "Epoch #385: Average loss is 0.0003948591112324114\n",
            ".........................................................\n",
            "Epoch #385: Validation F1 is 1.0\n",
            "Time taken for epoch: 56.25452923774719s\n",
            "\n",
            "\n",
            "Epoch #386: Average loss is 0.0002757122212379828\n",
            "Time taken for epoch: 6.2521467208862305s\n",
            "\n",
            "\n",
            "Epoch #387: Average loss is 0.00031874295162803414\n",
            "Time taken for epoch: 6.251463413238525s\n",
            "\n",
            "\n",
            "Epoch #388: Average loss is 0.00021349540870990797\n",
            "Time taken for epoch: 6.268342971801758s\n",
            "\n",
            "\n",
            "Epoch #389: Average loss is 0.0004097436440355927\n",
            "Time taken for epoch: 6.270578622817993s\n",
            "\n",
            "\n",
            "Epoch #390: Average loss is 0.0003485530936591709\n",
            ".........................................................\n",
            "Epoch #390: Validation F1 is 1.0\n",
            "Time taken for epoch: 56.0950608253479s\n",
            "\n",
            "\n",
            "Epoch #391: Average loss is 0.00031556587765913316\n",
            "Time taken for epoch: 6.252076864242554s\n",
            "\n",
            "\n",
            "Epoch #392: Average loss is 0.00036249686640884546\n",
            "Time taken for epoch: 6.220771789550781s\n",
            "\n",
            "\n",
            "Epoch #393: Average loss is 0.0002898479191733511\n",
            "Time taken for epoch: 6.302190065383911s\n",
            "\n",
            "\n",
            "Epoch #394: Average loss is 0.00042727223143123813\n",
            "Time taken for epoch: 6.299712896347046s\n",
            "\n",
            "\n",
            "Epoch #395: Average loss is 0.0002538780828439889\n",
            ".........................................................\n",
            "Epoch #395: Validation F1 is 1.0\n",
            "Time taken for epoch: 56.020166873931885s\n",
            "\n",
            "\n",
            "Epoch #396: Average loss is 0.0003711957314468843\n",
            "Time taken for epoch: 6.317704916000366s\n",
            "\n",
            "\n",
            "Epoch #397: Average loss is 0.00027750085357992145\n",
            "Time taken for epoch: 6.210366487503052s\n",
            "\n",
            "\n",
            "Epoch #398: Average loss is 0.0004067640566993052\n",
            "Time taken for epoch: 6.2784974575042725s\n",
            "\n",
            "\n",
            "Epoch #399: Average loss is 0.0003623918606293349\n",
            "Time taken for epoch: 6.281625986099243s\n",
            "\n",
            "\n",
            "Epoch #400: Average loss is 0.0003910185257175019\n",
            ".........................................................\n",
            "Epoch #400: Validation F1 is 1.0\n",
            "Time taken for epoch: 57.149515867233276s\n",
            "\n",
            "\n",
            "Epoch #401: Average loss is 0.00031449763152421737\n",
            "Time taken for epoch: 4.816167831420898s\n",
            "\n",
            "\n",
            "Epoch #402: Average loss is 0.00033344770538759703\n",
            "Time taken for epoch: 5.881404876708984s\n",
            "\n",
            "\n",
            "Epoch #403: Average loss is 0.00027487916889084674\n",
            "Time taken for epoch: 6.245869398117065s\n",
            "\n",
            "\n",
            "Epoch #404: Average loss is 0.00030672986392043334\n",
            "Time taken for epoch: 6.266117334365845s\n",
            "\n",
            "\n",
            "Epoch #405: Average loss is 0.00032952874763901086\n",
            ".........................................................\n",
            "Epoch #405: Validation F1 is 1.0\n",
            "Time taken for epoch: 57.59170055389404s\n",
            "\n",
            "\n",
            "Epoch #406: Average loss is 0.00029239569694052784\n",
            "Time taken for epoch: 6.180539608001709s\n",
            "\n",
            "\n",
            "Epoch #407: Average loss is 0.00037241370031956144\n",
            "Time taken for epoch: 4.7752296924591064s\n",
            "\n",
            "\n",
            "Epoch #408: Average loss is 0.00035313770405991817\n",
            "Time taken for epoch: 4.822093963623047s\n",
            "\n",
            "\n",
            "Epoch #409: Average loss is 0.0004621231744103069\n",
            "Time taken for epoch: 5.943942546844482s\n",
            "\n",
            "\n",
            "Epoch #410: Average loss is 0.00045066051630985584\n",
            ".........................................................\n",
            "Epoch #410: Validation F1 is 1.0\n",
            "Time taken for epoch: 57.71172833442688s\n",
            "\n",
            "\n",
            "Epoch #411: Average loss is 0.0003278044654042686\n",
            "Time taken for epoch: 6.260866641998291s\n",
            "\n",
            "\n",
            "Epoch #412: Average loss is 0.0002481183891035875\n",
            "Time taken for epoch: 6.301376104354858s\n",
            "\n",
            "\n",
            "Epoch #413: Average loss is 0.0002662281478731327\n",
            "Time taken for epoch: 6.086819887161255s\n",
            "\n",
            "\n",
            "Epoch #414: Average loss is 0.0003419914276976973\n",
            "Time taken for epoch: 4.743532657623291s\n",
            "\n",
            "\n",
            "Epoch #415: Average loss is 0.0003533821447530904\n",
            ".........................................................\n",
            "Epoch #415: Validation F1 is 1.0\n",
            "Time taken for epoch: 56.072678327560425s\n",
            "\n",
            "\n",
            "Epoch #416: Average loss is 0.0003038291678240057\n",
            "Time taken for epoch: 6.265532493591309s\n",
            "\n",
            "\n",
            "Epoch #417: Average loss is 0.00025138985696078936\n",
            "Time taken for epoch: 6.279548645019531s\n",
            "\n",
            "\n",
            "Epoch #418: Average loss is 0.00031902843736437113\n",
            "Time taken for epoch: 6.250722646713257s\n",
            "\n",
            "\n",
            "Epoch #419: Average loss is 0.00031489724147427804\n",
            "Time taken for epoch: 6.246023893356323s\n",
            "\n",
            "\n",
            "Epoch #420: Average loss is 0.0003380878581325912\n",
            ".........................................................\n",
            "Epoch #420: Validation F1 is 1.0\n",
            "Time taken for epoch: 56.007933378219604s\n",
            "\n",
            "\n",
            "Epoch #421: Average loss is 0.0004189604305874026\n",
            "Time taken for epoch: 6.257218599319458s\n",
            "\n",
            "\n",
            "Epoch #422: Average loss is 0.0005255439939436554\n",
            "Time taken for epoch: 6.267829418182373s\n",
            "\n",
            "\n",
            "Epoch #423: Average loss is 0.0002246516322177033\n",
            "Time taken for epoch: 6.21442723274231s\n",
            "\n",
            "\n",
            "Epoch #424: Average loss is 0.00028708052156515705\n",
            "Time taken for epoch: 6.263939142227173s\n",
            "\n",
            "\n",
            "Epoch #425: Average loss is 0.00023887670185407235\n",
            ".........................................................\n",
            "Epoch #425: Validation F1 is 1.0\n",
            "Time taken for epoch: 56.42732381820679s\n",
            "\n",
            "\n",
            "Epoch #426: Average loss is 0.0002768263151059121\n",
            "Time taken for epoch: 6.262796401977539s\n",
            "\n",
            "\n",
            "Epoch #427: Average loss is 0.0003808022835599129\n",
            "Time taken for epoch: 6.292210340499878s\n",
            "\n",
            "\n",
            "Epoch #428: Average loss is 0.0004084042796724437\n",
            "Time taken for epoch: 6.2696263790130615s\n",
            "\n",
            "\n",
            "Epoch #429: Average loss is 0.0002527213885029293\n",
            "Time taken for epoch: 6.2925004959106445s\n",
            "\n",
            "\n",
            "Epoch #430: Average loss is 0.00034112616587865177\n",
            ".........................................................\n",
            "Epoch #430: Validation F1 is 1.0\n",
            "Time taken for epoch: 56.250561475753784s\n",
            "\n",
            "\n",
            "Epoch #431: Average loss is 0.0002767991019532524\n",
            "Time taken for epoch: 6.215432643890381s\n",
            "\n",
            "\n",
            "Epoch #432: Average loss is 0.0002660099449005631\n",
            "Time taken for epoch: 6.255721092224121s\n",
            "\n",
            "\n",
            "Epoch #433: Average loss is 0.0003264230640969698\n",
            "Time taken for epoch: 6.276597261428833s\n",
            "\n",
            "\n",
            "Epoch #434: Average loss is 0.0002890930370166542\n",
            "Time taken for epoch: 6.318456649780273s\n",
            "\n",
            "\n",
            "Epoch #435: Average loss is 0.0003202880298502148\n",
            ".........................................................\n",
            "Epoch #435: Validation F1 is 1.0\n",
            "Time taken for epoch: 55.952505588531494s\n",
            "\n",
            "\n",
            "Epoch #436: Average loss is 0.0002850565932324874\n",
            "Time taken for epoch: 6.282667875289917s\n",
            "\n",
            "\n",
            "Epoch #437: Average loss is 0.0002941497068018685\n",
            "Time taken for epoch: 6.255659818649292s\n",
            "\n",
            "\n",
            "Epoch #438: Average loss is 0.00026789985136322985\n",
            "Time taken for epoch: 6.278390407562256s\n",
            "\n",
            "\n",
            "Epoch #439: Average loss is 0.0003406348540415315\n",
            "Time taken for epoch: 6.260377407073975s\n",
            "\n",
            "\n",
            "Epoch #440: Average loss is 0.0003505608112189091\n",
            ".........................................................\n",
            "Epoch #440: Validation F1 is 1.0\n",
            "Time taken for epoch: 56.335062980651855s\n",
            "\n",
            "\n",
            "Epoch #441: Average loss is 0.00038544715347597956\n",
            "Time taken for epoch: 6.255618572235107s\n",
            "\n",
            "\n",
            "Epoch #442: Average loss is 0.00025255880334952964\n",
            "Time taken for epoch: 6.2556211948394775s\n",
            "\n",
            "\n",
            "Epoch #443: Average loss is 0.000610303493297882\n",
            "Time taken for epoch: 6.284597873687744s\n",
            "\n",
            "\n",
            "Epoch #444: Average loss is 0.0002867299015350808\n",
            "Time taken for epoch: 6.268647909164429s\n",
            "\n",
            "\n",
            "Epoch #445: Average loss is 0.0003240665400840549\n",
            ".........................................................\n",
            "Epoch #445: Validation F1 is 1.0\n",
            "Time taken for epoch: 56.35978317260742s\n",
            "\n",
            "\n",
            "Epoch #446: Average loss is 0.0002860976268028834\n",
            "Time taken for epoch: 6.247731685638428s\n",
            "\n",
            "\n",
            "Epoch #447: Average loss is 0.00023070462864982093\n",
            "Time taken for epoch: 6.287866115570068s\n",
            "\n",
            "\n",
            "Epoch #448: Average loss is 0.00039422591082863317\n",
            "Time taken for epoch: 6.225152492523193s\n",
            "\n",
            "\n",
            "Epoch #449: Average loss is 0.00025143895222855565\n",
            "Time taken for epoch: 6.230649948120117s\n",
            "\n",
            "\n",
            "Epoch #450: Average loss is 0.0002813548512939532\n",
            ".........................................................\n",
            "Epoch #450: Validation F1 is 1.0\n",
            "Time taken for epoch: 56.94207167625427s\n",
            "\n",
            "\n",
            "Epoch #451: Average loss is 0.0004328361663485541\n",
            "Time taken for epoch: 4.849469900131226s\n",
            "\n",
            "\n",
            "Epoch #452: Average loss is 0.00021835284230292017\n",
            "Time taken for epoch: 6.287069797515869s\n",
            "\n",
            "\n",
            "Epoch #453: Average loss is 0.00019613089693242122\n",
            "Time taken for epoch: 6.2808849811553955s\n",
            "\n",
            "\n",
            "Epoch #454: Average loss is 0.00030895055516844475\n",
            "Time taken for epoch: 6.218946695327759s\n",
            "\n",
            "\n",
            "Epoch #455: Average loss is 0.00031391056120709336\n",
            ".........................................................\n",
            "Epoch #455: Validation F1 is 1.0\n",
            "Time taken for epoch: 57.710891246795654s\n",
            "\n",
            "\n",
            "Epoch #456: Average loss is 0.0002842113057037447\n",
            "Time taken for epoch: 5.672804355621338s\n",
            "\n",
            "\n",
            "Epoch #457: Average loss is 0.00027515339553550196\n",
            "Time taken for epoch: 4.862767934799194s\n",
            "\n",
            "\n",
            "Epoch #458: Average loss is 0.00026445940904118795\n",
            "Time taken for epoch: 4.770766735076904s\n",
            "\n",
            "\n",
            "Epoch #459: Average loss is 0.00027976072662366075\n",
            "Time taken for epoch: 6.271002531051636s\n",
            "\n",
            "\n",
            "Epoch #460: Average loss is 0.0002969090955290691\n",
            ".........................................................\n",
            "Epoch #460: Validation F1 is 1.0\n",
            "Time taken for epoch: 57.59875798225403s\n",
            "\n",
            "\n",
            "Epoch #461: Average loss is 0.000266812627835154\n",
            "Time taken for epoch: 6.2695534229278564s\n",
            "\n",
            "\n",
            "Epoch #462: Average loss is 0.00031092952332781147\n",
            "Time taken for epoch: 6.244553804397583s\n",
            "\n",
            "\n",
            "Epoch #463: Average loss is 0.00028258160629371154\n",
            "Time taken for epoch: 5.735194683074951s\n",
            "\n",
            "\n",
            "Epoch #464: Average loss is 0.00039102002198382655\n",
            "Time taken for epoch: 4.856286525726318s\n",
            "\n",
            "\n",
            "Epoch #465: Average loss is 0.0002239769780236303\n",
            ".........................................................\n",
            "Epoch #465: Validation F1 is 1.0\n",
            "Time taken for epoch: 55.737634897232056s\n",
            "\n",
            "\n",
            "Epoch #466: Average loss is 0.00028299567712969696\n",
            "Time taken for epoch: 6.2654664516448975s\n",
            "\n",
            "\n",
            "Epoch #467: Average loss is 0.0003296218882072329\n",
            "Time taken for epoch: 6.238922357559204s\n",
            "\n",
            "\n",
            "Epoch #468: Average loss is 0.00034898376548577896\n",
            "Time taken for epoch: 6.281196594238281s\n",
            "\n",
            "\n",
            "Epoch #469: Average loss is 0.0002556264731012763\n",
            "Time taken for epoch: 6.282078504562378s\n",
            "\n",
            "\n",
            "Epoch #470: Average loss is 0.00029786282571876656\n",
            ".........................................................\n",
            "Epoch #470: Validation F1 is 1.0\n",
            "Time taken for epoch: 55.705793619155884s\n",
            "\n",
            "\n",
            "Epoch #471: Average loss is 0.0002810349058179579\n",
            "Time taken for epoch: 6.220519542694092s\n",
            "\n",
            "\n",
            "Epoch #472: Average loss is 0.0002576343383872073\n",
            "Time taken for epoch: 6.264873504638672s\n",
            "\n",
            "\n",
            "Epoch #473: Average loss is 0.0003128721703140198\n",
            "Time taken for epoch: 6.277805328369141s\n",
            "\n",
            "\n",
            "Epoch #474: Average loss is 0.0003920044705874817\n",
            "Time taken for epoch: 6.269671440124512s\n",
            "\n",
            "\n",
            "Epoch #475: Average loss is 0.0002093717798965776\n",
            ".........................................................\n",
            "Epoch #475: Validation F1 is 1.0\n",
            "Time taken for epoch: 56.08537840843201s\n",
            "\n",
            "\n",
            "Epoch #476: Average loss is 0.00024231446726237968\n",
            "Time taken for epoch: 6.257120847702026s\n",
            "\n",
            "\n",
            "Epoch #477: Average loss is 0.0003073051825574819\n",
            "Time taken for epoch: 6.285038471221924s\n",
            "\n",
            "\n",
            "Epoch #478: Average loss is 0.00022286610962207002\n",
            "Time taken for epoch: 6.223712205886841s\n",
            "\n",
            "\n",
            "Epoch #479: Average loss is 0.0003270132483683281\n",
            "Time taken for epoch: 6.2701499462127686s\n",
            "\n",
            "\n",
            "Epoch #480: Average loss is 0.0003320052704354263\n",
            ".........................................................\n",
            "Epoch #480: Validation F1 is 1.0\n",
            "Time taken for epoch: 56.14358472824097s\n",
            "\n",
            "\n",
            "Epoch #481: Average loss is 0.00022201870075857895\n",
            "Time taken for epoch: 6.265411853790283s\n",
            "\n",
            "\n",
            "Epoch #482: Average loss is 0.00036652485469555057\n",
            "Time taken for epoch: 6.234228610992432s\n",
            "\n",
            "\n",
            "Epoch #483: Average loss is 0.00026267440912609646\n",
            "Time taken for epoch: 6.2569260597229s\n",
            "\n",
            "\n",
            "Epoch #484: Average loss is 0.00022981892165464362\n",
            "Time taken for epoch: 6.24833869934082s\n",
            "\n",
            "\n",
            "Epoch #485: Average loss is 0.00028995617936541544\n",
            ".........................................................\n",
            "Epoch #485: Validation F1 is 1.0\n",
            "Time taken for epoch: 56.154714822769165s\n",
            "\n",
            "\n",
            "Epoch #486: Average loss is 0.00028940483008530767\n",
            "Time taken for epoch: 6.26662278175354s\n",
            "\n",
            "\n",
            "Epoch #487: Average loss is 0.0003447246261182752\n",
            "Time taken for epoch: 6.210509777069092s\n",
            "\n",
            "\n",
            "Epoch #488: Average loss is 0.00025611994127959606\n",
            "Time taken for epoch: 6.25793981552124s\n",
            "\n",
            "\n",
            "Epoch #489: Average loss is 0.00024704429352924407\n",
            "Time taken for epoch: 6.25246262550354s\n",
            "\n",
            "\n",
            "Epoch #490: Average loss is 0.00045061870660396784\n",
            ".........................................................\n",
            "Epoch #490: Validation F1 is 1.0\n",
            "Time taken for epoch: 56.108866691589355s\n",
            "\n",
            "\n",
            "Epoch #491: Average loss is 0.0002227703411517723\n",
            "Time taken for epoch: 6.23626708984375s\n",
            "\n",
            "\n",
            "Epoch #492: Average loss is 0.0002465297172804842\n",
            "Time taken for epoch: 6.275366306304932s\n",
            "\n",
            "\n",
            "Epoch #493: Average loss is 0.00027879831664500267\n",
            "Time taken for epoch: 6.288439750671387s\n",
            "\n",
            "\n",
            "Epoch #494: Average loss is 0.00020225077680960466\n",
            "Time taken for epoch: 6.203534126281738s\n",
            "\n",
            "\n",
            "Epoch #495: Average loss is 0.0003626969182369066\n",
            ".........................................................\n",
            "Epoch #495: Validation F1 is 1.0\n",
            "Time taken for epoch: 56.09365963935852s\n",
            "\n",
            "\n",
            "Epoch #496: Average loss is 0.00024562138818105773\n",
            "Time taken for epoch: 6.279083490371704s\n",
            "\n",
            "\n",
            "Epoch #497: Average loss is 0.0003411268493265298\n",
            "Time taken for epoch: 6.233077049255371s\n",
            "\n",
            "\n",
            "Epoch #498: Average loss is 0.00023733184339208593\n",
            "Time taken for epoch: 6.297944068908691s\n",
            "\n",
            "\n",
            "Epoch #499: Average loss is 0.00024954971468711543\n",
            "Time taken for epoch: 6.282807111740112s\n",
            "\n",
            "\n",
            "Epoch #500: Average loss is 0.00026342818402756365\n",
            ".........................................................\n",
            "Epoch #500: Validation F1 is 1.0\n",
            "Time taken for epoch: 56.854822874069214s\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-102-23017c904a18>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m transformer, transformer_stats = task_transformer.train(500, train_loader, valid_loader, freq=5,\n\u001b[0;32m---> 15\u001b[0;31m                                 out_dir=out_dir, train_eval=False)\n\u001b[0m",
            "\u001b[0;32m/content/seq_seq_different.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, epochs, train_loader, valid_loader, freq, out_dir, create_dir, train_eval)\u001b[0m\n\u001b[1;32m    562\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    563\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 564\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot_stats\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfreq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfreq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    565\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Training completed in {}s\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart_training\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    566\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstats\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/seq_seq_different.py\u001b[0m in \u001b[0;36mplot_stats\u001b[0;34m(self, stats, freq, out_dir)\u001b[0m\n\u001b[1;32m    434\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mstats\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    435\u001b[0m             \u001b[0mstats\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstats\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 436\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfreq\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstats\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'epoch'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfreq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    437\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    438\u001b[0m         self.plot_history(stats['train_score'], stats['valid_score'], x,\n",
            "\u001b[0;31mIndexError\u001b[0m: index 0 is out of bounds for axis 0 with size 0"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MCcFhnSG6yf4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!zip -r results-seq_different.zip results/Seq2SeqDifferent/transformer/\n",
        "\n",
        "from google.colab import files\n",
        "files.download('results-seq_different.zip')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "A7XytRoVZgmv",
        "colab": {}
      },
      "source": [
        "# task_transformer.model.load(\"results/Seq2SeqDifferent/transformer/model_epoch_100.pkl\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VUtwY3hr6Wi-",
        "colab_type": "text"
      },
      "source": [
        "### Evaluate"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "e5be1a52-3b48-400a-9974-779957450be4",
        "id": "gLdhXI9MZgm0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 361
        }
      },
      "source": [
        "transformer_f1 = task_transformer.evaluate(test_loader, True)\n",
        "print(transformer_f1)"
      ],
      "execution_count": 122,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "."
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/content/seq_seq_different.py:271: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  tgt = torch.tensor(start_token).view(1,1,-1).repeat(src.shape[0],1,1).float()\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "...............................\n",
            "Confusion Matrix: \n",
            " [[75760     0]\n",
            " [    0 75240]]\n",
            "\n",
            "Classification Report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00     75760\n",
            "           1       1.00      1.00      1.00     75240\n",
            "\n",
            "    accuracy                           1.00    151000\n",
            "   macro avg       1.00      1.00      1.00    151000\n",
            "weighted avg       1.00      1.00      1.00    151000\n",
            "\n",
            "(1.0, 0.31577759329229593)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "2f4d564e-0a9b-4e89-b183-df2cd5a2bee3",
        "id": "RUPppxfrZgm5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 91
        }
      },
      "source": [
        "for x, y in test_loader:\n",
        "    x = x.to(device)\n",
        "    y = y.to(device)\n",
        "    break\n",
        "print(x.shape, y.shape)\n",
        "o = model.generate(x, start_token=START, max_len=y.shape[0])"
      ],
      "execution_count": 123,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([16, 32, 2]) torch.Size([151, 32, 2])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/content/seq_seq_different.py:271: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  tgt = torch.tensor(start_token).view(1,1,-1).repeat(src.shape[0],1,1).float()\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "18ce5cb7-914d-4211-e121-bd621e3ea46e",
        "id": "vvgb-lQ5Zgm9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "z1 = torch.transpose(torch.argmax(y,2), 1, 0).detach().cpu().long().numpy()\n",
        "z2 = torch.transpose(o[:,:,1], 1, 0).detach().cpu().numpy()\n",
        "z2 = np.round(z2).astype(int)\n",
        "# print(z1[0,:10])\n",
        "# print(z2[0,:10])\n",
        "# print(np.bitwise_xor(z1[0, :10], z2[0, :10]))\n",
        "\n",
        "from matplotlib.colors import ListedColormap\n",
        "# plt.matshow(np.bitwise_xor(z1, z2), cmap=cmap)\n",
        "cmap1 = ListedColormap(['w', 'blue'])\n",
        "img1 = plt.imshow(np.bitwise_xor(z1, z2), cmap=cmap1, alpha=0.5)\n",
        "cmap2 = ListedColormap(['w', 'orange'])\n",
        "img2 = plt.imshow(z1, cmap=cmap2, alpha=0.7)\n",
        "plt.savefig(os.path.join(out_dir, 'test.png'), transparent = True, \n",
        "            bbox_inches = 'tight', pad_inches = 0, dpi=300)\n",
        "plt.show()"
      ],
      "execution_count": 124,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAABpCAYAAAAqXNiiAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\niJWgDl0IIVaCOnQhhFgJ/wdKMiEmnATYXQAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "6zCHn-S2ZgnD"
      },
      "source": [
        "### Test with longer output"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "c688dcc3-ef5e-47ae-abe3-7f8981a9600a",
        "id": "TIQsIBFaZgnE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 397
        }
      },
      "source": [
        "long_output_train_loader, \\\n",
        "long_output_test_loader, \\\n",
        "long_output_val_loader = create_ncopy_task(sequence_length=15, \n",
        "                                           n_copy=20,\n",
        "                                           batch_size=batch_size,\n",
        "                                           start_token=1,\n",
        "                                           train_test_ratio=0.9, \n",
        "                                           train_valid_ratio=0.8)\n",
        "\n",
        "\n",
        "transformer_f1 = task_transformer.evaluate(long_output_test_loader, True)\n",
        "print(transformer_f1)\n",
        "\n",
        "for x, y in long_output_test_loader:\n",
        "    x = x.to(device)\n",
        "    y = y.to(device)\n",
        "    break\n",
        "\n",
        "o = model.generate(x, start_token=START, max_len=y.shape[0])"
      ],
      "execution_count": 125,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([16, 9000, 2]) torch.Size([301, 9000, 2])\n",
            "torch.Size([16, 1000, 2]) torch.Size([301, 1000, 2])\n",
            "."
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/content/seq_seq_different.py:271: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  tgt = torch.tensor(start_token).view(1,1,-1).repeat(src.shape[0],1,1).float()\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "...............................\n",
            "Confusion Matrix: \n",
            " [[116396  36864]\n",
            " [ 21283 126457]]\n",
            "\n",
            "Classification Report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.76      0.80    153260\n",
            "           1       0.77      0.86      0.81    147740\n",
            "\n",
            "    accuracy                           0.81    301000\n",
            "   macro avg       0.81      0.81      0.81    301000\n",
            "weighted avg       0.81      0.81      0.81    301000\n",
            "\n",
            "(0.8130688192991085, 0.5077605657279491)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "3935bbe8-6f75-4b77-d485-22d0dda38fff",
        "id": "jKLrjH3rZgnI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 78
        }
      },
      "source": [
        "z1 = torch.transpose(torch.argmax(y[:],2), 1, 0).detach().cpu().long().numpy()\n",
        "z1[:,0] = 1\n",
        "z2 = torch.transpose(o[:,:,1], 1, 0).detach().cpu().numpy()\n",
        "z2 = np.round(z2).astype(int)\n",
        "# print(z1[0,:10])\n",
        "# print(z2[0,:10])\n",
        "# print(np.bitwise_xor(z1[0, :10], z2[0, :10]))\n",
        "\n",
        "from matplotlib.colors import ListedColormap\n",
        "# plt.matshow(np.bitwise_xor(z1, z2), cmap=cmap)\n",
        "cmap1 = ListedColormap(['w', 'blue'])\n",
        "img1 = plt.imshow(np.bitwise_xor(z1, z2), cmap=cmap1, alpha=0.7)\n",
        "cmap2 = ListedColormap(['w', 'orange'])\n",
        "img2 = plt.imshow(z1, cmap=cmap2, alpha=0.7)\n",
        "plt.tick_params(labelsize=0, left=False, bottom=False)\n",
        "plt.savefig(os.path.join(out_dir, 'longer_output.png'), transparent = True, \n",
        "            bbox_inches = 'tight', pad_inches = 0, dpi=300)\n",
        "plt.show()"
      ],
      "execution_count": 126,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWgAAAA9CAYAAACA0fMlAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "BT5n7vlOZgnP"
      },
      "source": [
        "### Test with longer input"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "faa5b459-759d-45a6-95d3-90d7a2a65642",
        "id": "tcJ-jLSmZgnQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 397
        }
      },
      "source": [
        "long_input_train_loader, \\\n",
        "long_input_test_loader, \\\n",
        "long_input_val_loader = create_ncopy_task(sequence_length=25, \n",
        "                                           n_copy=10,\n",
        "                                           batch_size=batch_size, \n",
        "                                           start_token=1,\n",
        "                                           train_test_ratio=0.9, \n",
        "                                           train_valid_ratio=0.8)\n",
        "\n",
        "\n",
        "transformer_f1 = task_transformer.evaluate(long_input_test_loader, True)\n",
        "print(transformer_f1)\n",
        "\n",
        "for x, y in long_input_test_loader:\n",
        "    x = x.to(device)\n",
        "    y = y.to(device)\n",
        "    break\n",
        "\n",
        "o = model.generate(x, start_token=START, max_len=y.shape[0])"
      ],
      "execution_count": 127,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([26, 9000, 2]) torch.Size([251, 9000, 2])\n",
            "torch.Size([26, 1000, 2]) torch.Size([251, 1000, 2])\n",
            "."
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/content/seq_seq_different.py:271: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  tgt = torch.tensor(start_token).view(1,1,-1).repeat(src.shape[0],1,1).float()\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "...............................\n",
            "Confusion Matrix: \n",
            " [[60616 63284]\n",
            " [42973 84127]]\n",
            "\n",
            "Classification Report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.59      0.49      0.53    123900\n",
            "           1       0.57      0.66      0.61    127100\n",
            "\n",
            "    accuracy                           0.58    251000\n",
            "   macro avg       0.58      0.58      0.57    251000\n",
            "weighted avg       0.58      0.58      0.57    251000\n",
            "\n",
            "(0.6129226151228913, 0.7386819943785667)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "b4302b47-ec3f-47e4-8767-729f348bb4ba",
        "id": "qfz9ZVbAZgnW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "z1 = torch.transpose(torch.argmax(y[:],2), 1, 0).detach().cpu().long().numpy()\n",
        "z1[:,0] = 1\n",
        "z2 = torch.transpose(o[:,:,1], 1, 0).detach().cpu().numpy()\n",
        "z2 = np.round(z2).astype(int)\n",
        "# print(z1[0,:10])\n",
        "# print(z2[0,:10])\n",
        "# print(np.bitwise_xor(z1[0, :10], z2[0, :10]))\n",
        "\n",
        "from matplotlib.colors import ListedColormap\n",
        "# plt.matshow(np.bitwise_xor(z1, z2), cmap=cmap)\n",
        "cmap1 = ListedColormap(['w', 'blue'])\n",
        "img1 = plt.imshow(np.bitwise_xor(z1, z2), cmap=cmap1, alpha=0.7)\n",
        "cmap2 = ListedColormap(['w', 'orange'])\n",
        "img2 = plt.imshow(z1, cmap=cmap2, alpha=0.7)\n",
        "plt.tick_params(labelsize=0, left=False, bottom=False)\n",
        "plt.savefig(os.path.join(out_dir, 'longer_input.png'), transparent = True, \n",
        "            bbox_inches = 'tight', pad_inches = 0, dpi=300)\n",
        "plt.show()"
      ],
      "execution_count": 128,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWgAAABECAYAAACs/K8sAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRXbQiUQi8aD4f5qmmZQ8299DAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0fiXHmZ190lN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}