{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-11T17:44:13.269932Z",
     "start_time": "2019-07-11T17:44:11.998096Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "import os\n",
    "import json\n",
    "import time\n",
    "import random\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, f1_score, classification_report\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "\n",
    "from IPython.display import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-11T17:44:13.283402Z",
     "start_time": "2019-07-11T17:44:13.276530Z"
    }
   },
   "outputs": [],
   "source": [
    "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device = torch.device('cpu')\n",
    "seed = 42\n",
    "\n",
    "batch_size = 8\n",
    "# Percentage of training data\n",
    "learning_rate = 0.001\n",
    "epochs = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XOR task\n",
    "\n",
    "The entire dataset comprises of the binary representation of all numbers uptil a range defined. The binary sequence from left to right (most significant to least significant) is the input. While the y or the output for an input is calculated as: $a1 \\oplus a10 \\wedge a3 \\oplus a7$. Where, the most significant bit is a1, the least significant bit is a10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-11T17:44:13.450545Z",
     "start_time": "2019-07-11T17:44:13.287324Z"
    }
   },
   "outputs": [],
   "source": [
    "# Generating data\n",
    "state_size = 10\n",
    "data_x = []\n",
    "for i in range(pow(2, state_size)):\n",
    "    data_x.append([int(x) for x in list(np.binary_repr(i, width=state_size))])\n",
    "data_x = np.array(data_x)\n",
    "\n",
    "data_y = []\n",
    "for x in data_x:\n",
    "    # a1 xor a10 ^ a3 xor a7\n",
    "    data_y.append(np.bitwise_and(np.bitwise_xor(x[0], x[9]), \n",
    "                                 np.bitwise_xor(x[2], x[6])))\n",
    "data_y = np.array(data_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-11T17:44:13.520693Z",
     "start_time": "2019-07-11T17:44:13.452782Z"
    }
   },
   "outputs": [],
   "source": [
    "# Reshaping for tensors\n",
    "data_x = np.transpose(data_x).reshape(state_size, pow(2, state_size), 1)\n",
    "data_x = torch.from_numpy(data_x).float()\n",
    "data_y = torch.from_numpy(data_y).float()\n",
    "\n",
    "# Reshaping X to 2-input dimensions\n",
    "data_x = torch.zeros(data_x.shape[0], data_x.shape[1], 2).scatter_(2, data_x.long(), 1).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-11T17:44:13.545763Z",
     "start_time": "2019-07-11T17:44:13.522651Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 1024, 2])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-11T17:44:13.590060Z",
     "start_time": "2019-07-11T17:44:13.548706Z"
    }
   },
   "outputs": [],
   "source": [
    "# Creating training and test sets\n",
    "train_size = 0.7\n",
    "ordering = torch.randperm(pow(2, state_size))\n",
    "data_x = data_x[:, ordering, :]\n",
    "data_y = data_y[ordering]\n",
    "train_x = data_x[:,:int(train_size * len(ordering)),:]\n",
    "train_y = data_y[:int(train_size * len(ordering))]\n",
    "test_x = data_x[:,int(train_size * len(ordering)):,:]\n",
    "test_y = data_y[int(train_size * len(ordering)):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-11T17:44:13.648312Z",
     "start_time": "2019-07-11T17:44:13.592735Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 716, 2]) torch.Size([716]) torch.Size([10, 308, 2]) torch.Size([308])\n"
     ]
    }
   ],
   "source": [
    "print(train_x.shape, train_y.shape, test_x.shape, test_y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-10T22:42:19.802670Z",
     "start_time": "2019-07-10T22:42:19.797161Z"
    }
   },
   "outputs": [],
   "source": [
    "# Input dim\n",
    "input_dim = 2\n",
    "# Number of hidden nodes\n",
    "hidden_dim = 16\n",
    "# Number of output nodes\n",
    "output_dim = 1\n",
    "# Number of LSTMs cells to be stacked\n",
    "layers = 1\n",
    "# Boolean value for bidirectioanl or not\n",
    "bidirectional = True\n",
    "# Boolean value to use LayerNorm or not\n",
    "layernorm = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-10T22:42:20.737545Z",
     "start_time": "2019-07-10T22:42:20.719199Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_lstm(model, train_x, train_y, test_x, test_y, epochs, loss_fn, optimizer):\n",
    "    train_size = train_x.shape[1]\n",
    "    for i in range(1, epochs + 1):\n",
    "        model.train()\n",
    "        loss_tracker = []\n",
    "        ordering = torch.randperm(train_size)\n",
    "        train_x = train_x[:,ordering,:]\n",
    "        train_y = train_y[ordering]\n",
    "        for j in range(int(float(train_size)/batch_size) + 1):\n",
    "            optimizer.zero_grad()\n",
    "            start = j*batch_size\n",
    "            end = min((j+1)*batch_size, train_size)\n",
    "            batch = end - start\n",
    "            if batch is 0:\n",
    "                continue\n",
    "            if model.bidirectional:\n",
    "                hidden_state = torch.zeros(2 * layers, batch, hidden_dim).to(device)\n",
    "                cell_state = torch.zeros(2 * layers, batch, hidden_dim).to(device)\n",
    "            else:\n",
    "                hidden_state = torch.zeros(layers, batch, hidden_dim).to(device)\n",
    "                cell_state = torch.zeros(layers, batch, hidden_dim).to(device)\n",
    "            o = model(train_x[:,start:end,:], hidden_state, cell_state)\n",
    "            loss = loss_fn(o.view(-1), train_y[start:end])\n",
    "            loss_tracker.append(loss.item())\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            print(\"Epoch #{:<3d}: Batch {:>3d}/{:<3d} -- \"\n",
    "                  \"Loss: {:2.5}\".format(i, j+1, int(train_size/batch_size) + 1, \n",
    "                                        loss_tracker[-1]), end='\\r')\n",
    "        print()\n",
    "        f1_train = evaluate_lstm(model, train_x, train_y)\n",
    "        f1_test = evaluate_lstm(model, test_x, test_y)\n",
    "        print(\"Average Loss: {:2.6}\".format(np.mean(loss_tracker)))\n",
    "        print(\"Training F1: {:3.4}\".format(f1_train))\n",
    "        print(\"Test F1: {:3.4}\".format(f1_test))\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "def evaluate_lstm(model, x, y):\n",
    "    model.eval()\n",
    "    test_size = x.shape[1]\n",
    "    labels = []\n",
    "    preds = []\n",
    "    for j in range(int(test_size/batch_size) + 1):\n",
    "        optimizer.zero_grad()\n",
    "        start = j*batch_size\n",
    "        end = min((j+1)*batch_size, test_size)\n",
    "        batch = end - start\n",
    "        if batch == 0:\n",
    "            continue\n",
    "        if model.bidirectional:\n",
    "            hidden_state = torch.zeros(2 * layers, batch, hidden_dim).to(device)\n",
    "            cell_state = torch.zeros(2 * layers, batch, hidden_dim).to(device)\n",
    "        else:\n",
    "            hidden_state = torch.zeros(layers, batch, hidden_dim).to(device)\n",
    "            cell_state = torch.zeros(layers, batch, hidden_dim).to(device)\n",
    "        with torch.no_grad():\n",
    "            o = model(x[:,start:end,:], hidden_state, cell_state)\n",
    "        pred = torch.round(torch.sigmoid(o.view(-1))).cpu().detach().numpy()\n",
    "        preds.extend(pred)\n",
    "        labels.extend(y[start:end].int().detach().cpu().numpy())\n",
    "    return f1_score(labels, preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Our implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-10T22:42:39.452954Z",
     "start_time": "2019-07-10T22:42:39.424034Z"
    }
   },
   "outputs": [],
   "source": [
    "from lstm import LSTMCell\n",
    "\n",
    "class LSTM(nn.Module):\n",
    "    \"\"\"A complete LSTM architecture\n",
    "\n",
    "    Allows to stack multiple LSTM cells and also\n",
    "    create a bidirectional LSTM network.\n",
    "\n",
    "    Parameters\n",
    "    ==========\n",
    "    input_dim: Dimension of input data\n",
    "    hidden_dim: Size of hidden state\n",
    "    layernorm: True/False\n",
    "    layers: Number of LSTM cells to stack\n",
    "    bidirectional: True/False\n",
    "\n",
    "    \"\"\"\n",
    "    def __init__(self, input_dim, hidden_dim, layers=1, bidirectional=False, layernorm=False):\n",
    "        super().__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.layers = layers\n",
    "        self.bidirectional = bidirectional\n",
    "        self.layernorm = layernorm\n",
    "\n",
    "        if self.layers < 1:\n",
    "            raise ValueError(\"layers need to be > 1\")\n",
    "        self.model = []\n",
    "        for i in range(self.layers):\n",
    "            self.model.append(LSTMCell(input_dim, hidden_dim, layernorm))\n",
    "        self.model = nn.ModuleList(self.model)\n",
    "        if self.bidirectional:\n",
    "            self.model_rev = []\n",
    "            for i in range(self.layers):\n",
    "                self.model_rev.append(LSTMCell(input_dim, hidden_dim, layernorm))\n",
    "            self.model_rev = nn.ModuleList(self.model_rev)\n",
    "\n",
    "    def forward(self, x, hidden_state, cell_state):\n",
    "        \"\"\"Forward pass for the LSTM network\n",
    "\n",
    "        Parameters\n",
    "        ==========\n",
    "        x: [sequence_length, batch_size, input_dim]\n",
    "        hidden_state: [1, batch_size, hidden_dim]\n",
    "        cell_state: [1, batch_size, hidden_dim]\n",
    "\n",
    "        Returns\n",
    "        =======\n",
    "        output, (hidden_state, cell_state)\n",
    "            output: [sequence_length, batch_size, hidden_dim]\n",
    "                contains the output/hidden_state from all the timesteps\n",
    "                for the final layer in sequence 1...T\n",
    "            hidden_state: [layers, batch_size, hidden_dim]\n",
    "                contains the hidden_state from the last timestep T\n",
    "                from all the layers\n",
    "            cell_state: [layers, batch_size, hidden_dim]\n",
    "                contains the cell_state from the last timestep T\n",
    "                from all the layers\n",
    "\n",
    "            If bidirectional=True\n",
    "                output: [sequence_length, batch_size, 2 * hidden_dim]\n",
    "                    [:,:,:hidden_dim] - for left-to-right\n",
    "                    [:,:,hidden_dim:] - for right-to-left\n",
    "                hidden_state: [2 * layers, batch_size, hidden_dim]\n",
    "                    [:layers,:,:] - for left-to-right\n",
    "                    [layers:,:,:] - for right-to-left\n",
    "                cell_state: [layers, batch_size, hidden_dim]\n",
    "                    [:layers,:,:] - for left-to-right\n",
    "                    [layers:,:,:] - for right-to-left\n",
    "        \"\"\"\n",
    "        device = 'cpu'\n",
    "        if x.is_cuda:\n",
    "            device = 'cuda'\n",
    "        seq_length = x.shape[0]\n",
    "        # Left-to-right pass\n",
    "        # index of states is equivalent to index of layer in LSTM stack\n",
    "        hidden_states = hidden_state[:self.layers,:,:].view(self.layers, 1,\n",
    "                                                            hidden_state.shape[1],\n",
    "                                                            hidden_state.shape[2])\n",
    "        cell_states = cell_state[:self.layers,:,:].view(self.layers, 1,\n",
    "                                                        cell_state.shape[1],\n",
    "                                                        cell_state.shape[2])\n",
    "        output = torch.tensor([], requires_grad=True).to(device)\n",
    "        # forward pass for one cell at a time along layers\n",
    "        for j in range(self.layers):\n",
    "            output, (hidden_states[j], cell_states[j]) = self.model[j](x, hidden_states[j].clone(),\n",
    "                                                                  cell_states[j].clone())\n",
    "        hidden_states = hidden_states.squeeze(1)\n",
    "        cell_states = cell_states.squeeze(1)\n",
    "\n",
    "        ## TODO:\n",
    "        ## The current code will work if bidirectional=False and\n",
    "        ## the hidden_state.shape[0] > self.layers owing to [:layers,:,:].\n",
    "        ## Maybe a warning should be raised without termination.\n",
    "\n",
    "        # Right-to-left pass\n",
    "        if self.bidirectional:\n",
    "            # flipping inputs/rearranging x to be in reverse timestep order\n",
    "            x = torch.flip(x, [0])  # reversing only the sequence dimension\n",
    "            # index of states is equivalent to index of layer in LSTM stack\n",
    "            hidden_states_rev = hidden_state[self.layers:,:,:].view(self.layers, 1,\n",
    "                                                                hidden_state.shape[1],\n",
    "                                                                hidden_state.shape[2])\n",
    "            cell_states_rev = cell_state[self.layers:,:,:].view(self.layers, 1,\n",
    "                                                             cell_state.shape[1],\n",
    "                                                             cell_state.shape[2])\n",
    "            output_rev = torch.tensor([], requires_grad=True).to(device)\n",
    "            # forward pass for one cell at a time along layers\n",
    "            for j in range(self.layers):\n",
    "                output_rev, (hidden_states_rev[j], cell_states_rev[j]) = self.model_rev[j](x,\n",
    "                                                                        hidden_states_rev[j].clone(),\n",
    "                                                                        cell_states_rev[j].clone())\n",
    "            # flipping outputs to be in correct timestep order\n",
    "            output_rev = torch.flip(output_rev, [0]) # reversing only the sequence dimension\n",
    "            hidden_states_rev = hidden_states_rev.squeeze(1)\n",
    "            cell_states_rev = cell_states_rev.squeeze(1)\n",
    "            # concatenating tensors\n",
    "            ## creating tensors as expected in\n",
    "            ## here: https://pytorch.org/docs/stable/nn.html#torch.nn.LSTM\n",
    "            hidden_states = torch.cat((hidden_states,\n",
    "                                       hidden_states_rev), dim=0)\n",
    "            cell_states = torch.cat((cell_states,\n",
    "                                     cell_states_rev), dim=0)\n",
    "            output = torch.cat((output,\n",
    "                                output_rev), dim=2)\n",
    "\n",
    "        return output, (hidden_states, cell_states)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-10T22:42:40.700885Z",
     "start_time": "2019-07-10T22:42:40.684845Z"
    }
   },
   "outputs": [],
   "source": [
    "# from lstm import LSTM\n",
    "\n",
    "class LSTMSeqLabel(nn.Module):\n",
    "    \"\"\" LSTM Class for Sequence Labelling (many-to-one)\n",
    "\n",
    "    The class creates the LSTM architecture as specified by the parameters.\n",
    "    A fully connected layer is added to reduce the last hidden state to output_dim.\n",
    "\n",
    "    Parameters\n",
    "    ==========\n",
    "    vocab_len: int from imdb dataset\n",
    "    embed_dim: dimensions of the embeddings\n",
    "    hidden_dim: number of hidden nodes required\n",
    "    output_dim: numer of output nodes required (1 for sentiment analysis)\n",
    "    pretrained_vec: weights from imdb object\n",
    "    layers: number of LSTM cells to be stacked for depth\n",
    "    bidirectional: boolean\n",
    "    layernorm: boolean\n",
    "\n",
    "    \"\"\"\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim,\n",
    "                 layers=1, bidirectional=False, layernorm=False):\n",
    "        super().__init__()\n",
    "\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.bidirectional = bidirectional\n",
    "        self.layernorm = layernorm\n",
    "        \n",
    "        self.lstm = LSTM(input_dim=input_dim, hidden_dim=hidden_dim, layers=layers,\n",
    "                         bidirectional=bidirectional, layernorm=layernorm)\n",
    "        if self.bidirectional:\n",
    "            self.fc = nn.Linear(2 * hidden_dim, output_dim)\n",
    "        else:\n",
    "            self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, x, hidden_state, cell_state):\n",
    "        output, (_, _) = self.lstm(x, hidden_state, cell_state)\n",
    "        output = output[-1].unsqueeze(0)\n",
    "        output = self.fc(output)\n",
    "        return output\n",
    "\n",
    "    def save(self, file_path='./model.pkl'):\n",
    "        torch.save(self.state_dict(), file_path)\n",
    "\n",
    "    def load(self, file_path):\n",
    "        self.load_state_dict(torch.load(file_path))\n",
    "\n",
    "    def count_parameters(self):\n",
    "        tot_sum = sum(p.numel() for p in self.lstm.parameters() if p.requires_grad)\n",
    "        tot_sum += sum(p.numel() for p in self.fc.parameters() if p.requires_grad)\n",
    "        return tot_sum\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-10T22:42:42.210661Z",
     "start_time": "2019-07-10T22:42:42.193562Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2465\n"
     ]
    }
   ],
   "source": [
    "model = LSTMSeqLabel(input_dim, hidden_dim, output_dim, bidirectional=True, layers=layers).to(device)\n",
    "print(model.count_parameters())\n",
    "loss_fn = nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-10T22:42:54.176354Z",
     "start_time": "2019-07-10T22:42:43.991129Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #1  : Batch  90/90  -- Loss: 0.57015\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/ashwin/OS/Users/Ashwin/Documents/My Documents/MS/Freiburg/2019-SS/DLlab/dl-lab-ss19/labenv/lib/python3.6/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Loss: 0.619753\n",
      "Training F1: 0.0\n",
      "Test F1: 0.0\n",
      "Epoch #2  : Batch  90/90  -- Loss: 0.27476\n",
      "Average Loss: 0.561626\n",
      "Training F1: 0.0\n",
      "Test F1: 0.0\n",
      "Epoch #3  : Batch  90/90  -- Loss: 0.84467\n",
      "Average Loss: 0.566193\n",
      "Training F1: 0.0\n",
      "Test F1: 0.0\n",
      "Epoch #4  : Batch  90/90  -- Loss: 0.84708\n",
      "Average Loss: 0.565686\n",
      "Training F1: 0.0\n",
      "Test F1: 0.0\n",
      "Epoch #5  : Batch  90/90  -- Loss: 0.83391\n",
      "Average Loss: 0.566083\n",
      "Training F1: 0.0\n",
      "Test F1: 0.0\n",
      "Epoch #6  : Batch  90/90  -- Loss: 0.85345\n",
      "Average Loss: 0.566442\n",
      "Training F1: 0.0\n",
      "Test F1: 0.0\n",
      "Epoch #7  : Batch  27/90  -- Loss: 0.42597\r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-9862787b518d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtest_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_y\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mtrain_lstm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mloss_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-14-b9e8c6c76f2a>\u001b[0m in \u001b[0;36mtrain_lstm\u001b[0;34m(model, train_x, train_y, test_x, test_y, epochs, loss_fn, optimizer)\u001b[0m\n\u001b[1;32m     23\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m             \u001b[0mloss_tracker\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m             print(\"Epoch #{:<3d}: Batch {:>3d}/{:<3d} -- \"\n",
      "\u001b[0;32m/media/ashwin/OS/Users/Ashwin/Documents/My Documents/MS/Freiburg/2019-SS/DLlab/dl-lab-ss19/labenv/lib/python3.6/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    105\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m         \"\"\"\n\u001b[0;32m--> 107\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/ashwin/OS/Users/Ashwin/Documents/My Documents/MS/Freiburg/2019-SS/DLlab/dl-lab-ss19/labenv/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     91\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     92\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_x = train_x.to(device)\n",
    "train_y = train_y.to(device)\n",
    "test_x = test_x.to(device)\n",
    "test_y = test_y.to(device)\n",
    "\n",
    "train_lstm(model, train_x, train_y, test_x, test_y, epochs=500, loss_fn=loss_fn, optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PyTorch baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-10T22:43:10.040503Z",
     "start_time": "2019-07-10T22:43:10.013795Z"
    }
   },
   "outputs": [],
   "source": [
    "# using PyTorch LSTM module\n",
    "class PyTorchBaseline(nn.Module):\n",
    "\n",
    "    def __init__(self, n_input, n_hidden, n_output, \n",
    "                 layers=1, bidirectional=False, layernorm=False):\n",
    "        super().__init__()\n",
    "\n",
    "        self.hidden_dim = n_hidden\n",
    "        self.bidirectional = bidirectional\n",
    "        self.layers = layers\n",
    "        self.layernorm = layernorm\n",
    "\n",
    "        self.lstm = nn.LSTM(n_input, n_hidden, bidirectional=self.bidirectional, num_layers=layers)\n",
    "        if self.bidirectional:\n",
    "            self.fc = nn.Linear(2 * n_hidden, n_output)\n",
    "        else:\n",
    "            self.fc = nn.Linear(n_hidden, n_output)\n",
    "        if self.layernorm and self.bidirectional:\n",
    "            self.ln = LayerNorm(2 * self.hidden_dim)\n",
    "        elif self.layernorm:\n",
    "            self.ln = LayerNorm(self.hidden_dim)\n",
    "\n",
    "    def forward(self, x, h, c):\n",
    "        o, (_, _) = self.lstm(x, (h, c))\n",
    "        o = o[-1].unsqueeze(0)\n",
    "        if self.layernorm:\n",
    "            output = self.fc(self.ln(o))\n",
    "        else:\n",
    "            output = self.fc(o)\n",
    "        return output\n",
    "\n",
    "    def save(self, file_path='./model.pkl'):\n",
    "        torch.save(self.state_dict(), file_path)\n",
    "\n",
    "    def load(self, file_path):\n",
    "        self.load_state_dict(torch.load(file_path))\n",
    "\n",
    "    def count_parameters(self):\n",
    "        tot_sum = sum(p.numel() for p in self.lstm.parameters() if p.requires_grad)\n",
    "        tot_sum += sum(p.numel() for p in self.fc.parameters() if p.requires_grad)\n",
    "        return tot_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-10T22:43:13.382581Z",
     "start_time": "2019-07-10T22:43:13.377419Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2593\n"
     ]
    }
   ],
   "source": [
    "model = PyTorchBaseline(input_dim, hidden_dim, output_dim, bidirectional=bidirectional, layers=layers).to(device)\n",
    "print(model.count_parameters())\n",
    "loss_fn = nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-10T22:43:35.459595Z",
     "start_time": "2019-07-10T22:43:29.011353Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #1  : Batch  90/90  -- Loss: 0.57037\n",
      "Average Loss: 0.617523\n",
      "Training F1: 0.0\n",
      "Test F1: 0.0\n",
      "Epoch #2  : Batch  90/90  -- Loss: 0.56855\n",
      "Average Loss: 0.564826\n",
      "Training F1: 0.0\n",
      "Test F1: 0.0\n",
      "Epoch #3  : Batch  90/90  -- Loss: 0.56483\n",
      "Average Loss: 0.563855\n",
      "Training F1: 0.0\n",
      "Test F1: 0.0\n",
      "Epoch #4  : Batch  90/90  -- Loss: 0.55875\n",
      "Average Loss: 0.563758\n",
      "Training F1: 0.0\n",
      "Test F1: 0.0\n",
      "Epoch #5  : Batch  90/90  -- Loss: 0.28745\n",
      "Average Loss: 0.561983\n",
      "Training F1: 0.0\n",
      "Test F1: 0.0\n",
      "Epoch #6  : Batch  90/90  -- Loss: 0.56647\n",
      "Average Loss: 0.56343\n",
      "Training F1: 0.0\n",
      "Test F1: 0.0\n",
      "Epoch #7  : Batch  90/90  -- Loss: 0.56415\n",
      "Average Loss: 0.563175\n",
      "Training F1: 0.0\n",
      "Test F1: 0.0\n",
      "Epoch #8  : Batch  90/90  -- Loss: 0.56221\n",
      "Average Loss: 0.563539\n",
      "Training F1: 0.0\n",
      "Test F1: 0.0\n",
      "Epoch #9  : Batch  90/90  -- Loss: 0.29676\n",
      "Average Loss: 0.562005\n",
      "Training F1: 0.0\n",
      "Test F1: 0.0\n",
      "Epoch #10 : Batch  64/90  -- Loss: 0.56243\r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-9862787b518d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtest_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_y\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mtrain_lstm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mloss_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-14-b9e8c6c76f2a>\u001b[0m in \u001b[0;36mtrain_lstm\u001b[0;34m(model, train_x, train_y, test_x, test_y, epochs, loss_fn, optimizer)\u001b[0m\n\u001b[1;32m     23\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m             \u001b[0mloss_tracker\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m             print(\"Epoch #{:<3d}: Batch {:>3d}/{:<3d} -- \"\n",
      "\u001b[0;32m/media/ashwin/OS/Users/Ashwin/Documents/My Documents/MS/Freiburg/2019-SS/DLlab/dl-lab-ss19/labenv/lib/python3.6/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    105\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m         \"\"\"\n\u001b[0;32m--> 107\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/ashwin/OS/Users/Ashwin/Documents/My Documents/MS/Freiburg/2019-SS/DLlab/dl-lab-ss19/labenv/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     91\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     92\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_x = train_x.to(device)\n",
    "train_y = train_y.to(device)\n",
    "test_x = test_x.to(device)\n",
    "test_y = test_y.to(device)\n",
    "\n",
    "train_lstm(model, train_x, train_y, test_x, test_y, epochs=500, loss_fn=loss_fn, optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "our = LSTMSeqLabel(input_dim, hidden_dim, output_dim, bidirectional=True, layers=layers).to(device)\n",
    "pytorch = PyTorchBaseline(input_dim, hidden_dim, output_dim, bidirectional=bidirectional, layers=layers).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our implementation\n",
      "==================\n",
      "# of parameters: 2465\n",
      "lstm.model.0.weights     : torch.Size([18, 64])\n",
      "lstm.model.0.bias        : torch.Size([64])\n",
      "lstm.model_rev.0.weights : torch.Size([18, 64])\n",
      "lstm.model_rev.0.bias    : torch.Size([64])\n",
      "fc.weight                : torch.Size([1, 32])\n",
      "fc.bias                  : torch.Size([1])\n"
     ]
    }
   ],
   "source": [
    "print(\"Our implementation\\n{}\".format(\"=\" * len(\"Our implementation\")))\n",
    "print(\"# of parameters: {}\".format(our.count_parameters()))\n",
    "for name, param in our.named_parameters():\n",
    "    print(\"{:<25}: {}\".format(name, param.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch implementation\n",
      "======================\n",
      "# of parameters: 2593\n",
      "lstm.weight_ih_l0        : torch.Size([64, 2])\n",
      "lstm.weight_hh_l0        : torch.Size([64, 16])\n",
      "lstm.bias_ih_l0          : torch.Size([64])\n",
      "lstm.bias_hh_l0          : torch.Size([64])\n",
      "lstm.weight_ih_l0_reverse: torch.Size([64, 2])\n",
      "lstm.weight_hh_l0_reverse: torch.Size([64, 16])\n",
      "lstm.bias_ih_l0_reverse  : torch.Size([64])\n",
      "lstm.bias_hh_l0_reverse  : torch.Size([64])\n",
      "fc.weight                : torch.Size([1, 32])\n",
      "fc.bias                  : torch.Size([1])\n"
     ]
    }
   ],
   "source": [
    "print(\"PyTorch implementation\\n{}\".format(\"=\" * len(\"PyTorch implementation\")))\n",
    "print(\"# of parameters: {}\".format(pytorch.count_parameters()))\n",
    "for name, param in pytorch.named_parameters():\n",
    "    print(\"{:<25}: {}\".format(name, param.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PyTorch uses $Wh + b_h + Wx + b_x$ whereas we are using $Wx' + b$, where $x'$ is $h, x$ concatenated. Therefore PyTorch has an extra set of biases for each direction.\n",
    "\n",
    "For one direction - 64 <br>\n",
    "For reverse direction - 64 <br>\n",
    "\n",
    "Our model has $6978$ parameters while the PyTorch model has $6978 + 64 + 64 + 128 = 7234$ parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-11T17:44:15.089031Z",
     "start_time": "2019-07-11T17:44:15.073760Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_transformer(model, train_x, train_y, test_x, test_y, epochs, loss_fn, optimizer):\n",
    "    train_size = train_x.shape[1]\n",
    "    for i in range(1, epochs + 1):\n",
    "        model.train()\n",
    "        loss_tracker = []\n",
    "        ordering = torch.randperm(train_size)\n",
    "        train_x = train_x[:,ordering,:]\n",
    "        train_y = train_y[ordering]\n",
    "        for j in range(int(float(train_size)/batch_size) + 1):\n",
    "            optimizer.zero_grad()\n",
    "            start = j*batch_size\n",
    "            end = min((j+1)*batch_size, train_size)\n",
    "            batch = end - start\n",
    "            if batch is 0:\n",
    "                continue\n",
    "            o = model(train_x[:,start:end,:])\n",
    "            # transform output to be of same dim as label\n",
    "            o = o.mean(dim=0)  # mean over all attention output\n",
    "            loss = loss_fn(o.view(-1), train_y[start:end])\n",
    "            loss_tracker.append(loss.item())\n",
    "            loss.backward()\n",
    "            # plot_grad_flow(model.named_parameters())\n",
    "            optimizer.step()\n",
    "            print(\"Epoch #{:<3d}: Batch {:>3d}/{:<3d} -- \"\n",
    "                  \"Loss: {:2.5}\".format(i, j+1, int(train_size/batch_size) + 1, \n",
    "                                        loss_tracker[-1]), end='\\r')\n",
    "        print()\n",
    "        f1_train = evaluate_transformer(model, train_x, train_y)\n",
    "        f1_test = evaluate_transformer(model, test_x, test_y)\n",
    "        print(\"Average Loss: {:2.6}\".format(np.mean(loss_tracker)))\n",
    "        print(\"Training F1: {:3.4}\".format(f1_train))\n",
    "        print(\"Test F1: {:3.4}\".format(f1_test))\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "def evaluate_transformer(model, x, y):\n",
    "    model.eval()\n",
    "    test_size = x.shape[1]\n",
    "    labels = []\n",
    "    preds = []\n",
    "    for j in range(int(test_size/batch_size) + 1):\n",
    "        optimizer.zero_grad()\n",
    "        start = j*batch_size\n",
    "        end = min((j+1)*batch_size, test_size)\n",
    "        batch = end - start\n",
    "        if batch == 0:\n",
    "            continue\n",
    "        with torch.no_grad():\n",
    "            o = model(x[:,start:end,:])\n",
    "            # transform output to be of same dim as label\n",
    "            o = o.mean(dim=0)  # mean over all attention output\n",
    "        pred = torch.round(torch.sigmoid(o.view(-1))).cpu().detach().numpy()\n",
    "        preds.extend(pred)\n",
    "        labels.extend(y[start:end].int().detach().cpu().numpy())\n",
    "    return f1_score(labels, preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Our implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-11T17:52:02.554068Z",
     "start_time": "2019-07-11T17:52:02.540664Z"
    }
   },
   "outputs": [],
   "source": [
    "from transformer import PositionalEncoding, Encoder, init_weights\n",
    "\n",
    "class TransformerSeqLabel(nn.Module):\n",
    "    \"\"\" Transformer Class for Sequence Labelling (many-to-one)\n",
    "\n",
    "    The class creates the Transformer encoder architecture as specified by the parameters.\n",
    "    A fully connected layer is added to reduce the attention to output_dim.\n",
    "    The final prediction is averaged over sequence length to get final score\n",
    "\n",
    "    Parameters\n",
    "    ==========\n",
    "    in_dim: input vocab size from imdb dataset\n",
    "    out_dim: output dimensions of the model\n",
    "    model_dim: embedding dimension, also the dimensionality at which the transformer operates\n",
    "    key_dim: dimensions for query & key in attention calculation\n",
    "    value_dim: dimensions for value in attention calculation\n",
    "    ff_dim: dimensions for Positionwise feed-forward sublayer\n",
    "    max_len: max length to generate positional encodings (default=10000)\n",
    "    batch_first: transposes the 1st 2 dimensions of the input to have 'batch' as the first\n",
    "        if the input dimensions are of form [seq_len, batch, dim] (default=True)\n",
    "    \"\"\"\n",
    "    def __init__(self, in_dim, out_dim, N, heads, model_dim, key_dim, value_dim, ff_dim, \n",
    "                 max_len=10000, batch_first=False):\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        self.batch_first = batch_first\n",
    "        \n",
    "        self.embed = nn.Linear(in_dim, model_dim)\n",
    "        self.pos_enc = PositionalEncoding(model_dim, max_len)\n",
    "        self.encoder = Encoder(N, heads, model_dim, key_dim, value_dim, ff_dim)\n",
    "        # final output layer\n",
    "        self.fc = nn.Linear(model_dim, out_dim, bias=False)\n",
    "        \n",
    "        # xavier initialization\n",
    "        for p in self.parameters():\n",
    "            if p.dim() > 1:\n",
    "                nn.init.xavier_uniform(p)\n",
    "    \n",
    "    def forward(self, x, mask=None):\n",
    "        # transpose to use [batch, seq_len, dim]\n",
    "        if not self.batch_first:\n",
    "            x = x.transpose(0, 1)\n",
    "            \n",
    "        x = self.embed(x)\n",
    "        x = self.pos_enc(x)\n",
    "        x = self.encoder(x, mask)\n",
    "        x = self.fc(x)\n",
    "        \n",
    "        # transpose back to original [seq_len, batch, dim]\n",
    "        if not self.batch_first:\n",
    "            x = x.transpose(0, 1)\n",
    "        return x\n",
    "        \n",
    "    def save(self, file_path='./model.pkl'):\n",
    "        torch.save(self.state_dict(), file_path)\n",
    "\n",
    "    def load(self, file_path):\n",
    "        self.load_state_dict(torch.load(file_path))\n",
    "\n",
    "    def count_parameters(self):\n",
    "        tot_sum = sum(p.numel() for p in self.parameters() if p.requires_grad)\n",
    "        return tot_sum\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-11T17:52:03.371183Z",
     "start_time": "2019-07-11T17:52:03.361045Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2615\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/ashwin/OS/Users/Ashwin/Documents/My Documents/MS/Freiburg/2019-SS/DLlab/dl-lab-ss19/labenv/lib/python3.6/site-packages/ipykernel_launcher.py:38: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n"
     ]
    }
   ],
   "source": [
    "transformer = TransformerSeqLabel(in_dim=2, out_dim=1, N=1, heads=5, model_dim=12, \n",
    "                                  key_dim=4, value_dim=3, ff_dim=64)\n",
    "transformer = transformer.to(device)\n",
    "\n",
    "print(transformer.count_parameters())\n",
    "loss_fn = nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(transformer.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-11T17:52:04.522372Z",
     "start_time": "2019-07-11T17:52:04.517779Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TransformerSeqLabel(\n",
       "  (embed): Linear(in_features=2, out_features=12, bias=True)\n",
       "  (pos_enc): PositionalEncoding()\n",
       "  (encoder): Encoder(\n",
       "    (enc_stack): ModuleList(\n",
       "      (0): EncoderCell(\n",
       "        (self_attn): MultiHeadAttention(\n",
       "          (Wq): Linear(in_features=12, out_features=20, bias=True)\n",
       "          (Wk): Linear(in_features=12, out_features=20, bias=True)\n",
       "          (Wv): Linear(in_features=12, out_features=15, bias=True)\n",
       "          (attn): ScaledDotProductAttention(\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "          (Wout): Linear(in_features=15, out_features=12, bias=True)\n",
       "          (norm): LayerNorm(torch.Size([12]), eps=1e-06, elementwise_affine=True)\n",
       "        )\n",
       "        (pos_ff): PositionWiseFeedForward(\n",
       "          (w1): Linear(in_features=12, out_features=64, bias=True)\n",
       "          (w2): Linear(in_features=64, out_features=12, bias=True)\n",
       "          (norm): LayerNorm(torch.Size([12]), eps=1e-06, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (fc): Linear(in_features=12, out_features=1, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-11T17:52:29.844750Z",
     "start_time": "2019-07-11T17:52:06.503706Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #1  : Batch  90/90  -- Loss: 0.87938\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/ashwin/OS/Users/Ashwin/Documents/My Documents/MS/Freiburg/2019-SS/DLlab/dl-lab-ss19/labenv/lib/python3.6/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Loss: 0.573061\n",
      "Training F1: 0.0\n",
      "Test F1: 0.0\n",
      "Epoch #2  : Batch  90/90  -- Loss: 0.57491\n",
      "Average Loss: 0.567357\n",
      "Training F1: 0.0\n",
      "Test F1: 0.0\n",
      "Epoch #3  : Batch  90/90  -- Loss: 0.54193\n",
      "Average Loss: 0.567091\n",
      "Training F1: 0.0\n",
      "Test F1: 0.0\n",
      "Epoch #4  : Batch  90/90  -- Loss: 0.82007\n",
      "Average Loss: 0.564284\n",
      "Training F1: 0.0\n",
      "Test F1: 0.0\n",
      "Epoch #5  : Batch  90/90  -- Loss: 0.80727\n",
      "Average Loss: 0.564001\n",
      "Training F1: 0.0\n",
      "Test F1: 0.0\n",
      "Epoch #6  : Batch  90/90  -- Loss: 0.54679\n",
      "Average Loss: 0.550503\n",
      "Training F1: 0.0\n",
      "Test F1: 0.0\n",
      "Epoch #7  : Batch  90/90  -- Loss: 0.79833\n",
      "Average Loss: 0.547285\n",
      "Training F1: 0.0\n",
      "Test F1: 0.0\n",
      "Epoch #8  : Batch  90/90  -- Loss: 0.71438\n",
      "Average Loss: 0.528918\n",
      "Training F1: 0.0\n",
      "Test F1: 0.0\n",
      "Epoch #9  : Batch  90/90  -- Loss: 0.43879\n",
      "Average Loss: 0.501055\n",
      "Training F1: 0.05435\n",
      "Test F1: 0.02564\n",
      "Epoch #10 : Batch  90/90  -- Loss: 0.37526\n",
      "Average Loss: 0.471004\n",
      "Training F1: 0.1158\n",
      "Test F1: 0.122\n",
      "Epoch #11 : Batch  90/90  -- Loss: 0.60099\n",
      "Average Loss: 0.438095\n",
      "Training F1: 0.2365\n",
      "Test F1: 0.1667\n",
      "Epoch #12 : Batch  90/90  -- Loss: 0.84193\n",
      "Average Loss: 0.403068\n",
      "Training F1: 0.21\n",
      "Test F1: 0.122\n",
      "Epoch #13 : Batch  90/90  -- Loss: 0.21056\n",
      "Average Loss: 0.389146\n",
      "Training F1: 0.4958\n",
      "Test F1: 0.3617\n",
      "Epoch #14 : Batch  90/90  -- Loss: 0.41584\n",
      "Average Loss: 0.358102\n",
      "Training F1: 0.4367\n",
      "Test F1: 0.2697\n",
      "Epoch #15 : Batch  90/90  -- Loss: 0.201547\n",
      "Average Loss: 0.334835\n",
      "Training F1: 0.679\n",
      "Test F1: 0.5333\n",
      "Epoch #16 : Batch  90/90  -- Loss: 0.136173\n",
      "Average Loss: 0.320246\n",
      "Training F1: 0.726\n",
      "Test F1: 0.5607\n",
      "Epoch #17 : Batch  90/90  -- Loss: 0.12811\n",
      "Average Loss: 0.29174\n",
      "Training F1: 0.9687\n",
      "Test F1: 0.9306\n",
      "Epoch #18 : Batch  90/90  -- Loss: 0.086663\n",
      "Average Loss: 0.272336\n",
      "Training F1: 0.9683\n",
      "Test F1: 0.9078\n",
      "Epoch #19 : Batch  90/90  -- Loss: 0.121647\n",
      "Average Loss: 0.241825\n",
      "Training F1: 0.9915\n",
      "Test F1: 0.9664\n",
      "Epoch #20 : Batch  90/90  -- Loss: 0.147971\n",
      "Average Loss: 0.22474\n",
      "Training F1: 0.9471\n",
      "Test F1: 0.8507\n",
      "Epoch #21 : Batch  90/90  -- Loss: 0.303376\n",
      "Average Loss: 0.188262\n",
      "Training F1: 0.9944\n",
      "Test F1: 0.9733\n",
      "Epoch #22 : Batch  90/90  -- Loss: 0.108922\n",
      "Average Loss: 0.165501\n",
      "Training F1: 1.0\n",
      "Test F1: 0.9935\n",
      "Epoch #23 : Batch  90/90  -- Loss: 0.062113\n",
      "Average Loss: 0.140213\n",
      "Training F1: 1.0\n",
      "Test F1: 0.9733\n",
      "Epoch #24 : Batch  90/90  -- Loss: 0.075674\n",
      "Average Loss: 0.132214\n",
      "Training F1: 1.0\n",
      "Test F1: 1.0\n",
      "Epoch #25 : Batch  90/90  -- Loss: 0.2049137\n",
      "Average Loss: 0.115586\n",
      "Training F1: 0.9887\n",
      "Test F1: 0.9524\n",
      "Epoch #26 : Batch  90/90  -- Loss: 0.081913\n",
      "Average Loss: 0.113438\n",
      "Training F1: 1.0\n",
      "Test F1: 1.0\n",
      "Epoch #27 : Batch  90/90  -- Loss: 0.028097\n",
      "Average Loss: 0.0916389\n",
      "Training F1: 1.0\n",
      "Test F1: 1.0\n",
      "Epoch #28 : Batch  90/90  -- Loss: 0.081918\n",
      "Average Loss: 0.081139\n",
      "Training F1: 0.9972\n",
      "Test F1: 0.9804\n",
      "Epoch #29 : Batch  90/90  -- Loss: 0.0769517\n",
      "Average Loss: 0.0787208\n",
      "Training F1: 1.0\n",
      "Test F1: 1.0\n",
      "Epoch #30 : Batch  90/90  -- Loss: 0.0041057\n",
      "Average Loss: 0.0574407\n",
      "Training F1: 1.0\n",
      "Test F1: 1.0\n",
      "Epoch #31 : Batch  90/90  -- Loss: 0.0086908\n",
      "Average Loss: 0.0434852\n",
      "Training F1: 1.0\n",
      "Test F1: 1.0\n",
      "Epoch #32 : Batch  90/90  -- Loss: 0.0026432\n",
      "Average Loss: 0.0346364\n",
      "Training F1: 1.0\n",
      "Test F1: 1.0\n",
      "Epoch #33 : Batch  90/90  -- Loss: 0.0364977\n",
      "Average Loss: 0.038239\n",
      "Training F1: 1.0\n",
      "Test F1: 1.0\n",
      "Epoch #34 : Batch  90/90  -- Loss: 0.07373367\n",
      "Average Loss: 0.0386095\n",
      "Training F1: 1.0\n",
      "Test F1: 1.0\n",
      "Epoch #35 : Batch  90/90  -- Loss: 0.00447771\n",
      "Average Loss: 0.0240076\n",
      "Training F1: 1.0\n",
      "Test F1: 1.0\n",
      "Epoch #36 : Batch  90/90  -- Loss: 0.0048045\n",
      "Average Loss: 0.0200157\n",
      "Training F1: 1.0\n",
      "Test F1: 1.0\n",
      "Epoch #37 : Batch  90/90  -- Loss: 0.0103231\n",
      "Average Loss: 0.019531\n",
      "Training F1: 1.0\n",
      "Test F1: 1.0\n",
      "Epoch #38 : Batch  90/90  -- Loss: 0.00620844\n",
      "Average Loss: 0.0240602\n",
      "Training F1: 1.0\n",
      "Test F1: 1.0\n",
      "Epoch #39 : Batch  90/90  -- Loss: 0.00326348\n",
      "Average Loss: 0.0134541\n",
      "Training F1: 1.0\n",
      "Test F1: 1.0\n",
      "Epoch #40 : Batch  69/90  -- Loss: 0.00080948\r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-440df0a57928>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m train_transformer(transformer, train_x, train_y, test_x, test_y, epochs=epochs, \n\u001b[0;32m----> 2\u001b[0;31m                   loss_fn=loss_fn, optimizer=optimizer)\n\u001b[0m",
      "\u001b[0;32m<ipython-input-8-afbe26ef6f44>\u001b[0m in \u001b[0;36mtrain_transformer\u001b[0;34m(model, train_x, train_y, test_x, test_y, epochs, loss_fn, optimizer)\u001b[0m\n\u001b[1;32m     14\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m                 \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m             \u001b[0mo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_x\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m             \u001b[0;31m# transform output to be of same dim as label\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m             \u001b[0mo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# mean over all attention output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/ashwin/OS/Users/Ashwin/Documents/My Documents/MS/Freiburg/2019-SS/DLlab/dl-lab-ss19/labenv/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-19-c760c77a8d5d>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, mask)\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpos_enc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/ashwin/OS/Users/Ashwin/Documents/My Documents/MS/Freiburg/2019-SS/DLlab/dl-lab-ss19/labenv/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/ashwin/OS/Users/Ashwin/Documents/My Documents/MS/Freiburg/2019-SS/DLlab/dl-lab-project/SequenceModelling/src/transformer.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, mask)\u001b[0m\n\u001b[1;32m    262\u001b[0m         \u001b[0;31m# get attention\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0menc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menc_stack\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 264\u001b[0;31m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    265\u001b[0m         \u001b[0;31m# x = self.norm(x)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/ashwin/OS/Users/Ashwin/Documents/My Documents/MS/Freiburg/2019-SS/DLlab/dl-lab-ss19/labenv/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/ashwin/OS/Users/Ashwin/Documents/My Documents/MS/Freiburg/2019-SS/DLlab/dl-lab-project/SequenceModelling/src/transformer.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, mask)\u001b[0m\n\u001b[1;32m    181\u001b[0m         '''    \n\u001b[1;32m    182\u001b[0m         \u001b[0;31m# get attention\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 183\u001b[0;31m         \u001b[0mattn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mself_attn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    184\u001b[0m         \u001b[0;31m# position wise feed forward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m         \u001b[0mpos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpos_ff\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/ashwin/OS/Users/Ashwin/Documents/My Documents/MS/Freiburg/2019-SS/DLlab/dl-lab-ss19/labenv/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/ashwin/OS/Users/Ashwin/Documents/My Documents/MS/Freiburg/2019-SS/DLlab/dl-lab-project/SequenceModelling/src/transformer.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, q, k, v, mask)\u001b[0m\n\u001b[1;32m    112\u001b[0m         \u001b[0mattn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mWout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m         \u001b[0;31m# add and normalize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0mattn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresidual\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mattn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mattn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/ashwin/OS/Users/Ashwin/Documents/My Documents/MS/Freiburg/2019-SS/DLlab/dl-lab-ss19/labenv/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/ashwin/OS/Users/Ashwin/Documents/My Documents/MS/Freiburg/2019-SS/DLlab/dl-lab-ss19/labenv/lib/python3.6/site-packages/torch/nn/modules/normalization.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    155\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m         return F.layer_norm(\n\u001b[0;32m--> 157\u001b[0;31m             input, self.normalized_shape, self.weight, self.bias, self.eps)\n\u001b[0m\u001b[1;32m    158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/ashwin/OS/Users/Ashwin/Documents/My Documents/MS/Freiburg/2019-SS/DLlab/dl-lab-ss19/labenv/lib/python3.6/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlayer_norm\u001b[0;34m(input, normalized_shape, weight, bias, eps)\u001b[0m\n\u001b[1;32m   1723\u001b[0m     \"\"\"\n\u001b[1;32m   1724\u001b[0m     return torch.layer_norm(input, normalized_shape, weight, bias, eps,\n\u001b[0;32m-> 1725\u001b[0;31m                             torch.backends.cudnn.enabled)\n\u001b[0m\u001b[1;32m   1726\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1727\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_transformer(transformer, train_x, train_y, test_x, test_y, epochs=epochs, \n",
    "                  loss_fn=loss_fn, optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline implementation\n",
    "\n",
    "From github: https://github.com/jadore801120/attention-is-all-you-need-pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-11T19:08:20.523415Z",
     "start_time": "2019-07-11T19:08:20.502285Z"
    }
   },
   "outputs": [],
   "source": [
    "import transformer_baseline as tb\n",
    "\n",
    "class TransformerBaseline(nn.Module):\n",
    "    def __init__(self, in_dim, out_dim, N, heads, model_dim, key_dim, value_dim, ff_dim, \n",
    "                 max_len=10000, batch_first=True):\n",
    "        super().__init__()\n",
    "        self.name = 'transformer'\n",
    "        \n",
    "        self.batch_first = batch_first\n",
    "        \n",
    "        self.encoder = tb.Models.Encoder(\n",
    "            n_src_vocab=in_dim, len_max_seq=max_len,\n",
    "            d_word_vec=model_dim, d_model=model_dim, d_inner=ff_dim,\n",
    "            n_layers=N, n_head=heads, d_k=key_dim, d_v=value_dim,\n",
    "            dropout=0.0, embedding='linear')\n",
    "        \n",
    "        self.fc = nn.Linear(model_dim, out_dim, bias=False)\n",
    "        \n",
    "        # This was important from their code. \n",
    "        # Initialize parameters with Glorot / fan_avg.\n",
    "        for p in self.parameters():\n",
    "            if p.dim() > 1:\n",
    "                nn.init.xavier_uniform_(p)\n",
    "                \n",
    "    def forward(self, x):\n",
    "            \n",
    "        if not self.batch_first:\n",
    "            x = x.transpose(0,1)\n",
    "            \n",
    "        x = self.encoder(x, x)\n",
    "        x = self.fc(x)\n",
    "        \n",
    "        if not self.batch_first:\n",
    "            x = x.transpose(0,1)\n",
    "        return x\n",
    "      \n",
    "    def save(self, file_path='./model.pkl'):\n",
    "        torch.save(self.state_dict(), file_path)\n",
    "\n",
    "    def load(self, file_path):\n",
    "        self.load_state_dict(torch.load(file_path))\n",
    "\n",
    "    def count_parameters(self):\n",
    "        tot_sum = sum(p.numel() for p in self.parameters() if p.requires_grad)\n",
    "        return tot_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-11T19:08:21.339090Z",
     "start_time": "2019-07-11T19:08:21.017889Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2615\n"
     ]
    }
   ],
   "source": [
    "baseline = TransformerBaseline(in_dim=2, out_dim=1, N=1, heads=5, model_dim=12, \n",
    "                                  key_dim=4, value_dim=3, ff_dim=64)\n",
    "baseline = baseline.to(device)\n",
    "# transformer.apply(init_weights)\n",
    "\n",
    "print(baseline.count_parameters())\n",
    "loss_fn = nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(baseline.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-11T19:08:21.929012Z",
     "start_time": "2019-07-11T19:08:21.920069Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TransformerBaseline(\n",
       "  (encoder): Encoder(\n",
       "    (src_word_emb): Linear(in_features=2, out_features=12, bias=True)\n",
       "    (position_enc): Embedding(10001, 12)\n",
       "    (layer_stack): ModuleList(\n",
       "      (0): EncoderLayer(\n",
       "        (slf_attn): MultiHeadAttention(\n",
       "          (w_qs): Linear(in_features=12, out_features=20, bias=True)\n",
       "          (w_ks): Linear(in_features=12, out_features=20, bias=True)\n",
       "          (w_vs): Linear(in_features=12, out_features=15, bias=True)\n",
       "          (attention): ScaledDotProductAttention(\n",
       "            (dropout): Dropout(p=0.1)\n",
       "            (softmax): Softmax()\n",
       "          )\n",
       "          (layer_norm): LayerNorm(torch.Size([12]), eps=1e-05, elementwise_affine=True)\n",
       "          (fc): Linear(in_features=15, out_features=12, bias=True)\n",
       "          (dropout): Dropout(p=0.0)\n",
       "        )\n",
       "        (pos_ffn): PositionwiseFeedForward(\n",
       "          (w_1): Conv1d(12, 64, kernel_size=(1,), stride=(1,))\n",
       "          (w_2): Conv1d(64, 12, kernel_size=(1,), stride=(1,))\n",
       "          (layer_norm): LayerNorm(torch.Size([12]), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.0)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (fc): Linear(in_features=12, out_features=1, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-11T19:08:22.849927Z",
     "start_time": "2019-07-11T19:08:22.819545Z"
    }
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "expand(torch.ByteTensor{[10, 1, 8, 2]}, size=[-1, 8, -1]): the number of sizes provided (3) must be greater or equal to the number of dimensions in the tensor (4)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-101-933f728ed5a4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m train_transformer(baseline, train_x, train_y, test_x, test_y, epochs=500, \n\u001b[0;32m----> 2\u001b[0;31m                   loss_fn=loss_fn, optimizer=optimizer)\n\u001b[0m",
      "\u001b[0;32m<ipython-input-8-afbe26ef6f44>\u001b[0m in \u001b[0;36mtrain_transformer\u001b[0;34m(model, train_x, train_y, test_x, test_y, epochs, loss_fn, optimizer)\u001b[0m\n\u001b[1;32m     14\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m                 \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m             \u001b[0mo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_x\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m             \u001b[0;31m# transform output to be of same dim as label\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m             \u001b[0mo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# mean over all attention output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/ashwin/OS/Users/Ashwin/Documents/My Documents/MS/Freiburg/2019-SS/DLlab/dl-lab-ss19/labenv/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-98-f155fd80f3a8>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     28\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/ashwin/OS/Users/Ashwin/Documents/My Documents/MS/Freiburg/2019-SS/DLlab/dl-lab-ss19/labenv/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/ashwin/OS/Users/Ashwin/Documents/My Documents/MS/Freiburg/2019-SS/DLlab/dl-lab-project/SequenceModelling/src/transformer_baseline/Models.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, src_seq, src_pos, return_attns)\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m         \u001b[0;31m# -- Prepare masks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m         \u001b[0mslf_attn_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_attn_key_pad_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseq_k\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msrc_seq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseq_q\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msrc_seq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m         \u001b[0mnon_pad_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_non_pad_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc_seq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/ashwin/OS/Users/Ashwin/Documents/My Documents/MS/Freiburg/2019-SS/DLlab/dl-lab-project/SequenceModelling/src/transformer_baseline/Models.py\u001b[0m in \u001b[0;36mget_attn_key_pad_mask\u001b[0;34m(seq_k, seq_q)\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0mlen_q\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mseq_q\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0mpadding_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mseq_k\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mConstants\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPAD\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m     \u001b[0mpadding_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpadding_mask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen_q\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# b x lq x lk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mpadding_mask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: expand(torch.ByteTensor{[10, 1, 8, 2]}, size=[-1, 8, -1]): the number of sizes provided (3) must be greater or equal to the number of dimensions in the tensor (4)"
     ]
    }
   ],
   "source": [
    "train_transformer(baseline, train_x, train_y, test_x, test_y, epochs=500, \n",
    "                  loss_fn=loss_fn, optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "237.594px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
