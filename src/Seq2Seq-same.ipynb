{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset, random_split\n",
    "\n",
    "import os\n",
    "import re\n",
    "import json\n",
    "import time\n",
    "\n",
    "import random\n",
    "import numpy as np\n",
    "from jiwer import wer\n",
    "from collections import OrderedDict\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, f1_score, classification_report\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "from IPython.display import Image\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "seed = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Common parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "split_ratio = 0.8\n",
    "learning_rate = 0.001\n",
    "\n",
    "device = \"cuda\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading bAbi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data size:    8000\n",
      "Validation data size:  2000\n",
      "Test data size:        1000\n"
     ]
    }
   ],
   "source": [
    "from babi import babiDataset\n",
    "\n",
    "task = 2\n",
    "\n",
    "babi = babiDataset(task=task, split_ratio=split_ratio, device=device)\n",
    "babi.load(verbose=True)\n",
    "train_loader, valid_loader, test_loader = babi.create_data_loader(batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input dim\n",
    "input_dim = babi.max_vocab_size\n",
    "# Number of hidden nodes\n",
    "hidden_dim = 256\n",
    "# Number of output nodes\n",
    "output_dim = babi.max_vocab_size\n",
    "# Number of LSTMs cells to be stacked\n",
    "layers = 1\n",
    "# Boolean value for bidirectioanl or not\n",
    "bidirectional = True\n",
    "# Boolean value to use LayerNorm or not\n",
    "layernorm = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Our implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our implementation\n",
      "==================\n",
      "# of parameters: 618532\n",
      "lstm.model.0.weights     : torch.Size([292, 1024])\n",
      "lstm.model.0.bias        : torch.Size([1024])\n",
      "lstm.model_rev.0.weights : torch.Size([292, 1024])\n",
      "lstm.model_rev.0.bias    : torch.Size([1024])\n",
      "fc.weight                : torch.Size([36, 512])\n",
      "fc.bias                  : torch.Size([36])\n"
     ]
    }
   ],
   "source": [
    "from seq_seq_same import LSTMSeq2SeqSame\n",
    "\n",
    "our = LSTMSeq2SeqSame(input_dim=input_dim, hidden_dim=hidden_dim, output_dim=output_dim, \n",
    "                        layers=layers, bidirectional=bidirectional).to(device)\n",
    "\n",
    "print(\"Our implementation\\n{}\".format(\"=\" * len(\"Our implementation\")))\n",
    "print(\"# of parameters: {}\".format(our.count_parameters()))\n",
    "for name, param in our.named_parameters():\n",
    "    print(\"{:<25}: {}\".format(name, param.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from seq_seq_same import Seq2SeqSame\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer_our = torch.optim.Adam(our.parameters(), lr=learning_rate)\n",
    "\n",
    "task_our = Seq2SeqSame(our, optimizer_our, loss_fn, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beginning training model with 160278 parameters\n",
      "Files will be saved in: dump/Seq2SeqSame/Our/\n",
      "\n",
      "Epoch #1: Batch 250/250 -- Loss = 0.1086023822426796; Time taken: 0.19549012184143066ss\n",
      "Epoch #1: Average loss is 0.3593522633612156\n",
      "Epoch #1: Train WER is 1.0\n",
      "Epoch #1: Validation WER is 1.0\n",
      "Time taken for epoch: 73.30066204071045s\n",
      "\n",
      "Epoch #2: Batch 250/250 -- Loss = 0.05617695674300194; Time taken: 0.19971561431884766ss\n",
      "Epoch #2: Average loss is 0.0696959458887577\n",
      "Time taken for epoch: 50.24725270271301s\n",
      "\n",
      "Epoch #3: Batch 250/250 -- Loss = 0.06047941371798515; Time taken: 0.2024221420288086s3s\n",
      "Epoch #3: Average loss is 0.06192107139527798\n",
      "Time taken for epoch: 50.09034013748169s\n",
      "\n",
      "Epoch #4: Batch 250/250 -- Loss = 0.059934236109256744; Time taken: 0.1997971534729004ss\n",
      "Epoch #4: Average loss is 0.05750268976390362\n",
      "Time taken for epoch: 50.126322984695435s\n",
      "\n",
      "Epoch #5: Batch 250/250 -- Loss = 0.04725957289338112; Time taken: 0.1984419822692871sss\n",
      "Epoch #5: Average loss is 0.0516423022300005\n",
      "Epoch #5: Train WER is 0.5602028937302511\n",
      "Epoch #5: Validation WER is 0.5655682582380632\n",
      "Time taken for epoch: 71.0014636516571s\n",
      "\n",
      "Epoch #6: Batch 250/250 -- Loss = 0.04450209438800812; Time taken: 0.1982567310333252sss\n",
      "Epoch #6: Average loss is 0.04734202142059803\n",
      "Time taken for epoch: 50.114222049713135s\n",
      "\n",
      "Epoch #7: Batch 250/250 -- Loss = 0.04520631954073906; Time taken: 0.2007765769958496sss\n",
      "Epoch #7: Average loss is 0.044962697580456734\n",
      "Time taken for epoch: 50.17753219604492s\n",
      "\n",
      "Epoch #8: Batch 250/250 -- Loss = 0.041246455162763596; Time taken: 0.1991722583770752ss\n",
      "Epoch #8: Average loss is 0.043330829866230484\n",
      "Time taken for epoch: 50.15565752983093s\n",
      "\n",
      "Epoch #9: Batch 250/250 -- Loss = 0.03459061682224274; Time taken: 0.1983933448791504sss\n",
      "Epoch #9: Average loss is 0.04181236246973276\n",
      "Time taken for epoch: 50.07165265083313s\n",
      "\n",
      "Epoch #10: Batch 250/250 -- Loss = 0.04304022714495659; Time taken: 0.20162558555603027ss\n",
      "Epoch #10: Average loss is 0.03994014793634414\n",
      "Epoch #10: Train WER is 0.44087809745551304\n",
      "Epoch #10: Validation WER is 0.44636852723604575\n",
      "Time taken for epoch: 70.85043787956238s\n",
      "\n",
      "Epoch #11: Batch 250/250 -- Loss = 0.03538980707526207; Time taken: 0.19704270362854004ss\n",
      "Epoch #11: Average loss is 0.03891990203410387\n",
      "Time taken for epoch: 50.09378695487976s\n",
      "\n",
      "Epoch #12: Batch 250/250 -- Loss = 0.025797875598073006; Time taken: 0.19101214408874512s\n",
      "Epoch #12: Average loss is 0.03775161070376635\n",
      "Time taken for epoch: 50.305811405181885s\n",
      "\n",
      "Epoch #13: Batch 250/250 -- Loss = 0.039456333965063095; Time taken: 0.19371986389160156s\n",
      "Epoch #13: Average loss is 0.03670039998739958\n",
      "Time taken for epoch: 50.40243864059448s\n",
      "\n",
      "Epoch #14: Batch 250/250 -- Loss = 0.03737432882189751; Time taken: 0.19144988059997559ss\n",
      "Epoch #14: Average loss is 0.03619101492315531\n",
      "Time taken for epoch: 50.39189004898071s\n",
      "\n",
      "Epoch #15: Batch 250/250 -- Loss = 0.030992161482572556; Time taken: 0.19227933883666992s\n",
      "Epoch #15: Average loss is 0.03547678451985121\n",
      "Epoch #15: Train WER is 0.42857142857142855\n",
      "Epoch #15: Validation WER is 0.4386348352387357\n",
      "Time taken for epoch: 72.9874815940857s\n",
      "\n",
      "Epoch #16: Batch 250/250 -- Loss = 0.03892771154642105; Time taken: 0.1972198486328125sss\n",
      "Epoch #16: Average loss is 0.034660220101475715\n",
      "Time taken for epoch: 49.78434491157532s\n",
      "\n",
      "Epoch #17: Batch 250/250 -- Loss = 0.03380455821752548; Time taken: 0.19333362579345703ss\n",
      "Epoch #17: Average loss is 0.034011778995394704\n",
      "Time taken for epoch: 49.34130048751831s\n",
      "\n",
      "Epoch #18: Batch 250/250 -- Loss = 0.03434637561440468; Time taken: 0.1959073543548584s2s\n",
      "Epoch #18: Average loss is 0.03345055502653122\n",
      "Time taken for epoch: 52.03696846961975s\n",
      "\n",
      "Epoch #19: Batch 250/250 -- Loss = 0.03216637670993805; Time taken: 0.21442842483520508ss\n",
      "Epoch #19: Average loss is 0.032828609459102154\n",
      "Time taken for epoch: 50.73887586593628s\n",
      "\n",
      "Epoch #20: Batch 250/250 -- Loss = 0.034726690500974655; Time taken: 0.19668054580688477s\n",
      "Epoch #20: Average loss is 0.03234391871094704\n",
      "Epoch #20: Train WER is 0.4271578247131216\n",
      "Epoch #20: Validation WER is 0.44031607262945527\n",
      "Time taken for epoch: 76.97628140449524s\n",
      "\n",
      "Epoch #21: Batch 250/250 -- Loss = 0.02921094186604023; Time taken: 0.20328736305236816ss\n",
      "Epoch #21: Average loss is 0.03193876411765814\n",
      "Time taken for epoch: 50.01292824745178s\n",
      "\n",
      "Epoch #22: Batch 250/250 -- Loss = 0.028309637680649757; Time taken: 0.19553256034851074s\n",
      "Epoch #22: Average loss is 0.0316865321919322\n",
      "Time taken for epoch: 49.70757555961609s\n",
      "\n",
      "Epoch #23: Batch 250/250 -- Loss = 0.029315512627363205; Time taken: 0.20285391807556152s\n",
      "Epoch #23: Average loss is 0.031344693884253504\n",
      "Time taken for epoch: 50.37895441055298s\n",
      "\n",
      "Epoch #24: Batch 250/250 -- Loss = 0.026476532220840454; Time taken: 0.20516395568847656s\n",
      "Epoch #24: Average loss is 0.031115651786327362\n",
      "Time taken for epoch: 50.00175380706787s\n",
      "\n",
      "Epoch #25: Batch 250/250 -- Loss = 0.03431854769587517; Time taken: 0.19478297233581543ss\n",
      "Epoch #25: Average loss is 0.030610725603997708\n",
      "Epoch #25: Train WER is 0.39876101779477796\n",
      "Epoch #25: Validation WER is 0.42316745124411564\n",
      "Time taken for epoch: 70.22580409049988s\n",
      "\n",
      "Epoch #26: Batch 250/250 -- Loss = 0.026153825223445892; Time taken: 0.19719481468200684s\n",
      "Epoch #26: Average loss is 0.03022982020676136\n",
      "Time taken for epoch: 49.610755920410156s\n",
      "\n",
      "Epoch #27: Batch 250/250 -- Loss = 0.02902769297361374; Time taken: 0.2112293243408203sss\n",
      "Epoch #27: Average loss is 0.030031248435378074\n",
      "Time taken for epoch: 49.94804835319519s\n",
      "\n",
      "Epoch #28: Batch 250/250 -- Loss = 0.028743185102939606; Time taken: 0.19171881675720215s\n",
      "Epoch #28: Average loss is 0.029613837391138077\n",
      "Time taken for epoch: 49.81534457206726s\n",
      "\n",
      "Epoch #29: Batch 250/250 -- Loss = 0.0314498171210289; Time taken: 0.19736289978027344s6s\n",
      "Epoch #29: Average loss is 0.02926145737618208\n",
      "Time taken for epoch: 48.7414915561676s\n",
      "\n",
      "Epoch #30: Batch 250/250 -- Loss = 0.03089323826134205; Time taken: 0.20493054389953613ss\n",
      "Epoch #30: Average loss is 0.02863029006123543\n",
      "Epoch #30: Train WER is 0.36994844503575586\n",
      "Epoch #30: Validation WER is 0.4117350369872226\n",
      "Time taken for epoch: 70.39961123466492s\n",
      "\n",
      "Epoch #31: Batch 250/250 -- Loss = 0.030090827494859695; Time taken: 0.19629120826721191s\n",
      "Epoch #31: Average loss is 0.028300445169210434\n",
      "Time taken for epoch: 49.28563046455383s\n",
      "\n",
      "Epoch #32: Batch 250/250 -- Loss = 0.030092718079686165; Time taken: 0.19824814796447754s\n",
      "Epoch #32: Average loss is 0.027663365848362445\n",
      "Time taken for epoch: 49.84413385391235s\n",
      "\n",
      "Epoch #33: Batch 250/250 -- Loss = 0.022720368579030037; Time taken: 0.1911165714263916ss\n",
      "Epoch #33: Average loss is 0.02709638722985983\n",
      "Time taken for epoch: 49.443206548690796s\n",
      "\n",
      "Epoch #34: Batch 250/250 -- Loss = 0.029617352411150932; Time taken: 0.1937847137451172ss\n",
      "Epoch #34: Average loss is 0.02688508344441652\n",
      "Time taken for epoch: 49.53630566596985s\n",
      "\n",
      "Epoch #35: Batch 250/250 -- Loss = 0.02252907305955887; Time taken: 0.23585987091064453ss\n",
      "Epoch #35: Average loss is 0.02600187810510397\n",
      "Epoch #35: Train WER is 0.31461001164144353\n",
      "Epoch #35: Validation WER is 0.37390719569603226\n",
      "Time taken for epoch: 69.30344581604004s\n",
      "\n",
      "Epoch #36: Batch 250/250 -- Loss = 0.022488942369818687; Time taken: 0.1918928623199463ss\n",
      "Epoch #36: Average loss is 0.0254067600145936\n",
      "Time taken for epoch: 48.88087248802185s\n",
      "\n",
      "Epoch #37: Batch 250/250 -- Loss = 0.027297712862491608; Time taken: 0.19967222213745117s\n",
      "Epoch #37: Average loss is 0.024435605525970457\n",
      "Time taken for epoch: 49.12846398353577s\n",
      "\n",
      "Epoch #38: Batch 250/250 -- Loss = 0.02406029775738716; Time taken: 0.19106078147888184ss\n",
      "Epoch #38: Average loss is 0.023672308657318352\n",
      "Time taken for epoch: 49.47666120529175s\n",
      "\n",
      "Epoch #39: Batch 250/250 -- Loss = 0.022371040657162666; Time taken: 0.19524860382080078s\n",
      "Epoch #39: Average loss is 0.02307853402942419\n",
      "Time taken for epoch: 48.66180491447449s\n",
      "\n",
      "Epoch #40: Batch 250/250 -- Loss = 0.020707078278064728; Time taken: 0.19202208518981934s\n",
      "Epoch #40: Average loss is 0.021991513047367333\n",
      "Epoch #40: Train WER is 0.25719274904373857\n",
      "Epoch #40: Validation WER is 0.33540685944855414\n",
      "Time taken for epoch: 70.54723143577576s\n",
      "\n",
      "Epoch #41: Batch 250/250 -- Loss = 0.030499499291181564; Time taken: 0.1999797821044922ss\n",
      "Epoch #41: Average loss is 0.02113959837332368\n",
      "Time taken for epoch: 49.9218213558197s\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #42: Batch 250/250 -- Loss = 0.020231936126947403; Time taken: 0.20758914947509766s\n",
      "Epoch #42: Average loss is 0.020300116766244172\n",
      "Time taken for epoch: 48.92496681213379s\n",
      "\n",
      "Epoch #43: Batch 250/250 -- Loss = 0.020987384021282196; Time taken: 0.19148731231689453s\n",
      "Epoch #43: Average loss is 0.019407514728605746\n",
      "Time taken for epoch: 48.63900923728943s\n",
      "\n",
      "Epoch #44: Batch 250/250 -- Loss = 0.01509177777916193; Time taken: 0.19069457054138184ss\n",
      "Epoch #44: Average loss is 0.018596263691782952\n",
      "Time taken for epoch: 48.71963357925415s\n",
      "\n",
      "Epoch #45: Batch 250/250 -- Loss = 0.020036883652210236; Time taken: 0.1917400360107422ss\n",
      "Epoch #45: Average loss is 0.0177453074157238\n",
      "Epoch #45: Train WER is 0.19383003492433062\n",
      "Epoch #45: Validation WER is 0.2710154673839946\n",
      "Time taken for epoch: 68.7478563785553s\n",
      "\n",
      "Epoch #46: Batch 250/250 -- Loss = 0.018564216792583466; Time taken: 0.19411659240722656s\n",
      "Epoch #46: Average loss is 0.016774785831570625\n",
      "Time taken for epoch: 49.30863690376282s\n",
      "\n",
      "Epoch #47: Batch 250/250 -- Loss = 0.013879385776817799; Time taken: 0.1901535987854004ss\n",
      "Epoch #47: Average loss is 0.015991792671382427\n",
      "Time taken for epoch: 48.836397886276245s\n",
      "\n",
      "Epoch #48: Batch 250/250 -- Loss = 0.013153547421097755; Time taken: 0.19702553749084473s\n",
      "Epoch #48: Average loss is 0.015199911659583449\n",
      "Time taken for epoch: 49.376991748809814s\n",
      "\n",
      "Epoch #49: Batch 250/250 -- Loss = 0.01064363680779934; Time taken: 0.19232559204101562ss\n",
      "Epoch #49: Average loss is 0.013934426832944154\n",
      "Time taken for epoch: 48.509307861328125s\n",
      "\n",
      "Epoch #50: Batch 250/250 -- Loss = 0.014494720846414566; Time taken: 0.1897292137145996ss\n",
      "Epoch #50: Average loss is 0.013931568128988147\n",
      "Epoch #50: Train WER is 0.12589389655745883\n",
      "Epoch #50: Validation WER is 0.21301277740416946\n",
      "Time taken for epoch: 68.47836303710938s\n",
      "\n",
      "Epoch #51: Batch 250/250 -- Loss = 0.010792592540383339; Time taken: 0.19205594062805176s\n",
      "Epoch #51: Average loss is 0.012942702237516642\n",
      "Time taken for epoch: 48.452595472335815s\n",
      "\n",
      "Epoch #52: Batch 250/250 -- Loss = 0.009722540155053139; Time taken: 0.1902322769165039ss\n",
      "Epoch #52: Average loss is 0.01219566764868796\n",
      "Time taken for epoch: 48.3783540725708s\n",
      "\n",
      "Epoch #53: Batch 250/250 -- Loss = 0.01756906695663929; Time taken: 0.19538354873657227sss\n",
      "Epoch #53: Average loss is 0.011397414859384298\n",
      "Time taken for epoch: 48.53349947929382s\n",
      "\n",
      "Epoch #54: Batch 250/250 -- Loss = 0.011872670613229275; Time taken: 0.19452118873596191ss\n",
      "Epoch #54: Average loss is 0.010704897679388523\n",
      "Time taken for epoch: 48.58752799034119s\n",
      "\n",
      "Epoch #55: Batch 250/250 -- Loss = 0.00840099435299635; Time taken: 0.19234848022460938sss\n",
      "Epoch #55: Average loss is 0.010087041741237044\n",
      "Epoch #55: Train WER is 0.08198902378180609\n",
      "Epoch #55: Validation WER is 0.17047747141896435\n",
      "Time taken for epoch: 67.72480535507202s\n",
      "\n",
      "Epoch #56: Batch 250/250 -- Loss = 0.00795203447341919; Time taken: 0.19707632064819336sss\n",
      "Epoch #56: Average loss is 0.009466565353795886\n",
      "Time taken for epoch: 48.51728439331055s\n",
      "\n",
      "Epoch #57: Batch 250/250 -- Loss = 0.006425443105399609; Time taken: 0.19153976440429688ss\n",
      "Epoch #57: Average loss is 0.009164205892011524\n",
      "Time taken for epoch: 48.319772481918335s\n",
      "\n",
      "Epoch #58: Batch 250/250 -- Loss = 0.006834572181105614; Time taken: 0.19264435768127441ss\n",
      "Epoch #58: Average loss is 0.008646519877947867\n",
      "Time taken for epoch: 47.9579381942749s\n",
      "\n",
      "Epoch #59: Batch 250/250 -- Loss = 0.008412189781665802; Time taken: 0.18868756294250488ss\n",
      "Epoch #59: Average loss is 0.009647015701979398\n",
      "Time taken for epoch: 48.111836671829224s\n",
      "\n",
      "Epoch #60: Batch 250/250 -- Loss = 0.009984607808291912; Time taken: 0.19144725799560547ss\n",
      "Epoch #60: Average loss is 0.007495459310244769\n",
      "Epoch #60: Train WER is 0.05292699151837685\n",
      "Epoch #60: Validation WER is 0.13466711499663753\n",
      "Time taken for epoch: 67.77970933914185s\n",
      "\n",
      "Epoch #61: Batch 250/250 -- Loss = 0.00817164871841669; Time taken: 0.19048643112182617sss\n",
      "Epoch #61: Average loss is 0.0068427190603688355\n",
      "Time taken for epoch: 48.63649582862854s\n",
      "\n",
      "Epoch #62: Batch 250/250 -- Loss = 0.00876444298774004; Time taken: 0.1927647590637207ssss\n",
      "Epoch #62: Average loss is 0.0058354765614494685\n",
      "Time taken for epoch: 48.56112837791443s\n",
      "\n",
      "Epoch #63: Batch 250/250 -- Loss = 0.007818510755896568; Time taken: 0.19027042388916016ss\n",
      "Epoch #63: Average loss is 0.006353961979039013\n",
      "Time taken for epoch: 48.94828796386719s\n",
      "\n",
      "Epoch #64: Batch 250/250 -- Loss = 0.0059486632235348225; Time taken: 0.19403338432312012s\n",
      "Epoch #64: Average loss is 0.006082376974634826\n",
      "Time taken for epoch: 48.42172312736511s\n",
      "\n",
      "Epoch #65: Batch 250/250 -- Loss = 0.006716890260577202; Time taken: 0.1918351650238037s8s\n",
      "Epoch #65: Average loss is 0.0058425160683691505\n",
      "Epoch #65: Train WER is 0.03621320472309995\n",
      "Epoch #65: Validation WER is 0.11146603900470746\n",
      "Time taken for epoch: 67.73135471343994s\n",
      "\n",
      "Epoch #66: Batch 250/250 -- Loss = 0.010189211927354336; Time taken: 0.18793654441833496ss\n",
      "Epoch #66: Average loss is 0.007623782990500331\n",
      "Time taken for epoch: 48.59137964248657s\n",
      "\n",
      "Epoch #67: Batch 250/250 -- Loss = 0.0032071731984615326; Time taken: 0.19720768928527832s\n",
      "Epoch #67: Average loss is 0.0054512769011780616\n",
      "Time taken for epoch: 48.10707092285156s\n",
      "\n",
      "Epoch #68: Batch 250/250 -- Loss = 0.003457485930994153; Time taken: 0.19641828536987305ss\n",
      "Epoch #68: Average loss is 0.0037864968297071757\n",
      "Time taken for epoch: 48.24827265739441s\n",
      "\n",
      "Epoch #69: Batch 250/250 -- Loss = 0.002980013843625784; Time taken: 0.19711899757385254ss\n",
      "Epoch #69: Average loss is 0.003568572305608541\n",
      "Time taken for epoch: 51.43342733383179s\n",
      "\n",
      "Epoch #70: Batch 250/250 -- Loss = 0.005581687670201063; Time taken: 0.19341421127319336ss\n",
      "Epoch #70: Average loss is 0.003754093670286238\n",
      "Epoch #70: Train WER is 0.0704723099950108\n",
      "Epoch #70: Validation WER is 0.1348352387357095\n",
      "Time taken for epoch: 69.24754095077515s\n",
      "\n",
      "Epoch #71: Batch 250/250 -- Loss = 0.006135581061244011; Time taken: 0.19505763053894043ss\n",
      "Epoch #71: Average loss is 0.005870499921962619\n",
      "Time taken for epoch: 49.721550941467285s\n",
      "\n",
      "Epoch #72: Batch 250/250 -- Loss = 0.003150827484205365; Time taken: 0.1915428638458252sss\n",
      "Epoch #72: Average loss is 0.0036526227993890644\n",
      "Time taken for epoch: 50.60556745529175s\n",
      "\n",
      "Epoch #73: Batch 250/250 -- Loss = 0.0032232021912932396; Time taken: 0.20891308784484863s\n",
      "Epoch #73: Average loss is 0.0033329063279088585\n",
      "Time taken for epoch: 48.732555866241455s\n",
      "\n",
      "Epoch #74: Batch 250/250 -- Loss = 0.004787301179021597; Time taken: 0.19270658493041992ss\n",
      "Epoch #74: Average loss is 0.003791769520845264\n",
      "Time taken for epoch: 48.27631640434265s\n",
      "\n",
      "Epoch #75: Batch 250/250 -- Loss = 0.0015056951669976115; Time taken: 0.19950032234191895s\n",
      "Epoch #75: Average loss is 0.0030814219983294608\n",
      "Epoch #75: Train WER is 0.019291535007483786\n",
      "Epoch #75: Validation WER is 0.0882649630127774\n",
      "Time taken for epoch: 68.03358793258667s\n",
      "\n",
      "Epoch #76: Batch 250/250 -- Loss = 0.003957978915423155; Time taken: 0.19411253929138184ss\n",
      "Epoch #76: Average loss is 0.0023088690193835645\n",
      "Time taken for epoch: 49.2578866481781s\n",
      "\n",
      "Epoch #77: Batch 250/250 -- Loss = 0.002580118365585804; Time taken: 0.1905500888824463sss\n",
      "Epoch #77: Average loss is 0.0035426288137678057\n",
      "Time taken for epoch: 48.698797941207886s\n",
      "\n",
      "Epoch #78: Batch 250/250 -- Loss = 0.0017946264706552029; Time taken: 0.18979811668395996s\n",
      "Epoch #78: Average loss is 0.002780004906700924\n",
      "Time taken for epoch: 48.618602991104126s\n",
      "\n",
      "Epoch #79: Batch 250/250 -- Loss = 0.001565511105582118; Time taken: 0.1894369125366211sss\n",
      "Epoch #79: Average loss is 0.003506888665026054\n",
      "Time taken for epoch: 47.97801756858826s\n",
      "\n",
      "Epoch #80: Batch 250/250 -- Loss = 0.0030300298240035772; Time taken: 0.18690156936645508s\n",
      "Epoch #80: Average loss is 0.002661413243971765\n",
      "Epoch #80: Train WER is 0.018044237485448197\n",
      "Epoch #80: Validation WER is 0.08422999327505044\n",
      "Time taken for epoch: 67.23866987228394s\n",
      "\n",
      "Epoch #81: Batch 250/250 -- Loss = 0.002130622509866953; Time taken: 0.1901111602783203sss\n",
      "Epoch #81: Average loss is 0.0019409056943841278\n",
      "Time taken for epoch: 47.823622941970825s\n",
      "\n",
      "Epoch #82: Batch 250/250 -- Loss = 0.0043594990856945515; Time taken: 0.19781875610351562s\n",
      "Epoch #82: Average loss is 0.0033960140417329965\n",
      "Time taken for epoch: 48.881598234176636s\n",
      "\n",
      "Epoch #83: Batch 250/250 -- Loss = 0.0010418288875371218; Time taken: 0.18876409530639648s\n",
      "Epoch #83: Average loss is 0.0025324930406641216\n",
      "Time taken for epoch: 49.43279457092285s\n",
      "\n",
      "Epoch #84: Batch 250/250 -- Loss = 0.001349190715700388; Time taken: 0.19627904891967773ss\n",
      "Epoch #84: Average loss is 0.0022115591496694835\n",
      "Time taken for epoch: 49.17700386047363s\n",
      "\n",
      "Epoch #85: Batch 250/250 -- Loss = 0.0018310610903427005; Time taken: 0.19187211990356445ss\n",
      "Epoch #85: Average loss is 0.002058528390713036\n",
      "Epoch #85: Train WER is 0.025112256776983203\n",
      "Epoch #85: Validation WER is 0.08843308675184935\n",
      "Time taken for epoch: 69.30465579032898s\n",
      "\n",
      "Epoch #86: Batch 250/250 -- Loss = 0.007839127443730831; Time taken: 0.19292950630187988ss\n",
      "Epoch #86: Average loss is 0.002747229793574661\n",
      "Time taken for epoch: 49.33815002441406s\n",
      "\n",
      "Epoch #87: Batch 250/250 -- Loss = 0.0011771619319915771; Time taken: 0.1942908763885498ss\n",
      "Epoch #87: Average loss is 0.002607333970721811\n",
      "Time taken for epoch: 48.849687814712524s\n",
      "\n",
      "Epoch #88: Batch 250/250 -- Loss = 0.0023350699339061975; Time taken: 0.19442272186279297ss\n",
      "Epoch #88: Average loss is 0.0013275302288820968\n",
      "Time taken for epoch: 49.536882162094116s\n",
      "\n",
      "Epoch #89: Batch 250/250 -- Loss = 0.00931511726230383; Time taken: 0.19399356842041016ssss\n",
      "Epoch #89: Average loss is 0.0021333243830595166\n",
      "Time taken for epoch: 48.76044940948486s\n",
      "\n",
      "Epoch #90: Batch 250/250 -- Loss = 0.0024947631172835827; Time taken: 0.18897700309753418s\n",
      "Epoch #90: Average loss is 0.004269272405654192\n",
      "Epoch #90: Train WER is 0.03134874438716115\n",
      "Epoch #90: Validation WER is 0.09129119031607263\n",
      "Time taken for epoch: 68.97885394096375s\n",
      "\n",
      "Epoch #91: Batch 250/250 -- Loss = 0.0010569822043180466; Time taken: 0.18999195098876953s\n",
      "Epoch #91: Average loss is 0.002078414871939458\n",
      "Time taken for epoch: 48.13224482536316s\n",
      "\n",
      "Epoch #92: Batch 250/250 -- Loss = 0.0015474908286705613; Time taken: 0.19202256202697754ss\n",
      "Epoch #92: Average loss is 0.0013227834625868127\n",
      "Time taken for epoch: 48.26878809928894s\n",
      "\n",
      "Epoch #93: Batch 250/250 -- Loss = 0.000883569591678679; Time taken: 0.19321346282958984sss\n",
      "Epoch #93: Average loss is 0.0009708242972847074\n",
      "Time taken for epoch: 48.20105528831482s\n",
      "\n",
      "Epoch #94: Batch 250/250 -- Loss = 0.0011435652850195765; Time taken: 0.1980419158935547sss\n",
      "Epoch #94: Average loss is 0.001481912935618311\n",
      "Time taken for epoch: 48.22285795211792s\n",
      "\n",
      "Epoch #95: Batch 250/250 -- Loss = 0.0013801238965243101; Time taken: 0.1900331974029541ss\n",
      "Epoch #95: Average loss is 0.002465571288135834\n",
      "Epoch #95: Train WER is 0.014052885414934308\n",
      "Epoch #95: Validation WER is 0.07347007397444519\n",
      "Time taken for epoch: 68.71023631095886s\n",
      "\n",
      "Epoch #96: Batch 250/250 -- Loss = 0.00035635990207083523; Time taken: 0.19026446342468262s\n",
      "Epoch #96: Average loss is 0.002237950690439902\n",
      "Time taken for epoch: 48.25932431221008s\n",
      "\n",
      "Epoch #97: Batch 250/250 -- Loss = 0.001408266369253397; Time taken: 0.19477581977844238sss\n",
      "Epoch #97: Average loss is 0.0014544491135748104\n",
      "Time taken for epoch: 48.008814096450806s\n",
      "\n",
      "Epoch #98: Batch 250/250 -- Loss = 0.00039061057032085955; Time taken: 0.19510555267333984s\n",
      "Epoch #98: Average loss is 0.0008281458988785744\n",
      "Time taken for epoch: 49.85723543167114s\n",
      "\n",
      "Epoch #99: Batch 250/250 -- Loss = 0.000901544641237706; Time taken: 0.1968696117401123s08s\n",
      "Epoch #99: Average loss is 0.0007389196947333403\n",
      "Time taken for epoch: 49.47333288192749s\n",
      "\n",
      "Epoch #100: Batch 250/250 -- Loss = 0.00021777166693937033; Time taken: 0.19286298751831055s\n",
      "Epoch #100: Average loss is 0.0006101367172086611\n",
      "Epoch #100: Train WER is 0.0019956760352569432\n",
      "Epoch #100: Validation WER is 0.059347679892400806\n",
      "Time taken for epoch: 70.25470066070557s\n",
      "\n",
      "Epoch #101: Batch 250/250 -- Loss = 0.0015885091852396727; Time taken: 0.20228314399719238ss\n",
      "Epoch #101: Average loss is 0.0007215118281892501\n",
      "Time taken for epoch: 50.884976863861084s\n",
      "\n",
      "Epoch #102: Batch 250/250 -- Loss = 0.0032719855662435293; Time taken: 0.20498156547546387s\n",
      "Epoch #102: Average loss is 0.006483125377912074\n",
      "Time taken for epoch: 51.696391105651855s\n",
      "\n",
      "Epoch #103: Batch 250/250 -- Loss = 0.0010805204510688782; Time taken: 0.27248334884643555s\n",
      "Epoch #103: Average loss is 0.0022116058899555356\n",
      "Time taken for epoch: 51.61386585235596s\n",
      "\n",
      "Epoch #104: Batch 250/250 -- Loss = 0.0003187138354405761; Time taken: 0.19996070861816406ss\n",
      "Epoch #104: Average loss is 0.0010580466528772377\n",
      "Time taken for epoch: 51.3443341255188s\n",
      "\n",
      "Epoch #105: Batch 250/250 -- Loss = 0.0009751433390192688; Time taken: 0.2054765224456787sss\n",
      "Epoch #105: Average loss is 0.0007361636299174279\n",
      "Epoch #105: Train WER is 0.004032928654581739\n",
      "Epoch #105: Validation WER is 0.062373907195696035\n",
      "Time taken for epoch: 77.53223633766174s\n",
      "\n",
      "Epoch #106: Batch 250/250 -- Loss = 0.005356456618756056; Time taken: 0.21493911743164062sss\n",
      "Epoch #106: Average loss is 0.0017019649771973491\n",
      "Time taken for epoch: 52.40258836746216s\n",
      "\n",
      "Epoch #107: Batch 250/250 -- Loss = 0.0007763899629935622; Time taken: 0.19184470176696777ss\n",
      "Epoch #107: Average loss is 0.0025277368905954065\n",
      "Time taken for epoch: 49.64672613143921s\n",
      "\n",
      "Epoch #108: Batch 250/250 -- Loss = 0.00032188845216296613; Time taken: 0.19298434257507324s\n",
      "Epoch #108: Average loss is 0.0011113109000725672\n",
      "Time taken for epoch: 51.307469606399536s\n",
      "\n",
      "Epoch #109: Batch 250/250 -- Loss = 0.00029233741224743426; Time taken: 0.2357194423675537ss\n",
      "Epoch #109: Average loss is 0.00038911391535657457\n",
      "Time taken for epoch: 50.32218956947327s\n",
      "\n",
      "Epoch #110: Batch 250/250 -- Loss = 0.0001071278311428614; Time taken: 0.20496344566345215ss\n",
      "Epoch #110: Average loss is 0.0001933952172694262\n",
      "Epoch #110: Train WER is 0.0\n",
      "Epoch #110: Validation WER is 0.05531271015467384\n",
      "Time taken for epoch: 72.84689164161682s\n",
      "\n",
      "Epoch #111: Batch 250/250 -- Loss = 9.368122846353799e-05; Time taken: 0.19280600547790527ss\n",
      "Epoch #111: Average loss is 0.00012313945280038752\n",
      "Time taken for epoch: 51.13657784461975s\n",
      "\n",
      "Epoch #112: Batch 250/250 -- Loss = 0.0001307211205130443; Time taken: 0.20850610733032227ss\n",
      "Epoch #112: Average loss is 9.611632818996441e-05\n",
      "Time taken for epoch: 50.00367093086243s\n",
      "\n",
      "Epoch #113: Batch 250/250 -- Loss = 0.00011236762657063082; Time taken: 0.1924149990081787ss\n",
      "Epoch #113: Average loss is 8.052389720978681e-05\n",
      "Time taken for epoch: 49.73310661315918s\n",
      "\n",
      "Epoch #114: Batch 250/250 -- Loss = 9.784847497940063e-05; Time taken: 0.1907646656036377sss\n",
      "Epoch #114: Average loss is 6.906072102719918e-05\n",
      "Time taken for epoch: 48.28150796890259s\n",
      "\n",
      "Epoch #115: Batch 250/250 -- Loss = 4.801120303454809e-05; Time taken: 0.19156169891357422ss\n",
      "Epoch #115: Average loss is 6.009245038876543e-05\n",
      "Epoch #115: Train WER is 0.0\n",
      "Epoch #115: Validation WER is 0.05648957632817754\n",
      "Time taken for epoch: 68.10548067092896s\n",
      "\n",
      "Epoch #116: Batch 250/250 -- Loss = 4.338574581197463e-05; Time taken: 0.1940467357635498sss\n",
      "Epoch #116: Average loss is 5.2676155457447745e-05\n",
      "Time taken for epoch: 48.22466850280762s\n",
      "\n",
      "Epoch #117: Batch 250/250 -- Loss = 4.7989866288844496e-05; Time taken: 0.19409847259521484s\n",
      "Epoch #117: Average loss is 4.722639718966093e-05\n",
      "Time taken for epoch: 48.01246976852417s\n",
      "\n",
      "Epoch #118: Batch 250/250 -- Loss = 0.006935231853276491; Time taken: 0.1905531883239746s8ss\n",
      "Epoch #118: Average loss is 0.00017584714639087907\n",
      "Time taken for epoch: 47.963587284088135s\n",
      "\n",
      "Epoch #119: Batch 250/250 -- Loss = 0.006002346053719521; Time taken: 0.19022321701049805ss\n",
      "Epoch #119: Average loss is 0.01270940669812262\n",
      "Time taken for epoch: 47.9847891330719s\n",
      "\n",
      "Epoch #120: Batch 250/250 -- Loss = 0.001227081986144185; Time taken: 0.19164371490478516sss\n",
      "Epoch #120: Average loss is 0.002038117656484246\n",
      "Epoch #120: Train WER is 0.006860136371195743\n",
      "Epoch #120: Validation WER is 0.06455951580363148\n",
      "Time taken for epoch: 67.63881278038025s\n",
      "\n",
      "Epoch #121: Batch 250/250 -- Loss = 0.00235692597925663; Time taken: 0.19007086753845215s3s\n",
      "Epoch #121: Average loss is 0.0016240005813306197\n",
      "Time taken for epoch: 48.00620102882385s\n",
      "\n",
      "Epoch #122: Batch 250/250 -- Loss = 0.0010868622921407223; Time taken: 0.19347691535949707ss\n",
      "Epoch #122: Average loss is 0.0009232983375550248\n",
      "Time taken for epoch: 51.05290246009827s\n",
      "\n",
      "Epoch #123: Batch 250/250 -- Loss = 0.0006358384853228927; Time taken: 0.20242047309875488ss\n",
      "Epoch #123: Average loss is 0.0007618925094720907\n",
      "Time taken for epoch: 52.00991916656494s\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #124: Batch 250/250 -- Loss = 0.0005848482251167297; Time taken: 0.20831918716430664ss\n",
      "Epoch #124: Average loss is 0.0004768685287272092\n",
      "Time taken for epoch: 51.19286775588989s\n",
      "\n",
      "Epoch #125: Batch 250/250 -- Loss = 0.0001711052900645882; Time taken: 0.19844317436218262ss\n",
      "Epoch #125: Average loss is 0.0005030612124537583\n",
      "Epoch #125: Train WER is 0.0012057209379677367\n",
      "Epoch #125: Validation WER is 0.053967720242098186\n",
      "Time taken for epoch: 71.8257737159729s\n",
      "\n",
      "Epoch #126: Batch 250/250 -- Loss = 0.0008477445226162672; Time taken: 0.20595979690551758ss\n",
      "Epoch #126: Average loss is 0.0010597734009497799\n",
      "Time taken for epoch: 49.753239154815674s\n",
      "\n",
      "Epoch #127: Batch 250/250 -- Loss = 0.0017286117654293776; Time taken: 0.1973578929901123ss\n",
      "Epoch #127: Average loss is 0.0028897357288515195\n",
      "Time taken for epoch: 50.0340850353241s\n",
      "\n",
      "Epoch #128: Batch 250/250 -- Loss = 0.0024970388039946556; Time taken: 0.19695663452148438s\n",
      "Epoch #128: Average loss is 0.002274535429896787\n",
      "Time taken for epoch: 49.91318130493164s\n",
      "\n",
      "Epoch #129: Batch 250/250 -- Loss = 0.0004154118651058525; Time taken: 0.192643404006958s1ss\n",
      "Epoch #129: Average loss is 0.0023135348623618485\n",
      "Time taken for epoch: 50.36304211616516s\n",
      "\n",
      "Epoch #130: Batch 250/250 -- Loss = 0.0003947906952816993; Time taken: 0.20877408981323242ss\n",
      "Epoch #130: Average loss is 0.0007317716497927904\n",
      "Epoch #130: Train WER is 0.002328288707799767\n",
      "Epoch #130: Validation WER is 0.05699394754539341\n",
      "Time taken for epoch: 73.26182222366333s\n",
      "\n",
      "Epoch #131: Batch 250/250 -- Loss = 0.000296033569611609; Time taken: 0.2095639705657959s3ss\n",
      "Epoch #131: Average loss is 0.0004175692746939603\n",
      "Time taken for epoch: 52.13128161430359s\n",
      "\n",
      "Epoch #132: Batch 250/250 -- Loss = 0.00015730106679257005; Time taken: 0.19775843620300293s\n",
      "Epoch #132: Average loss is 0.00018637954420410097\n",
      "Time taken for epoch: 50.606727600097656s\n",
      "\n",
      "Epoch #133: Batch 250/250 -- Loss = 0.00012096424325136468; Time taken: 0.20766639709472656s\n",
      "Epoch #133: Average loss is 0.00010225538494705689\n",
      "Time taken for epoch: 50.27629780769348s\n",
      "\n",
      "Epoch #134: Batch 250/250 -- Loss = 8.321180939674377e-05; Time taken: 0.202239990234375ssss\n",
      "Epoch #134: Average loss is 7.311398931778968e-05\n",
      "Time taken for epoch: 50.31849122047424s\n",
      "\n",
      "Epoch #135: Batch 250/250 -- Loss = 5.007027357351035e-05; Time taken: 0.2019057273864746sss\n",
      "Epoch #135: Average loss is 6.0213035569177006e-05\n",
      "Epoch #135: Train WER is 0.0\n",
      "Epoch #135: Validation WER is 0.053967720242098186\n",
      "Time taken for epoch: 71.43870687484741s\n",
      "\n",
      "Epoch #136: Batch 250/250 -- Loss = 2.7918002160731703e-05; Time taken: 0.20325279235839844s\n",
      "Epoch #136: Average loss is 5.178690577304224e-05\n",
      "Time taken for epoch: 50.58849906921387s\n",
      "\n",
      "Epoch #137: Batch 250/250 -- Loss = 3.8738955481676385e-05; Time taken: 0.1968982219696045ss\n",
      "Epoch #137: Average loss is 4.507927264785394e-05\n",
      "Time taken for epoch: 50.453256607055664s\n",
      "\n",
      "Epoch #138: Batch 250/250 -- Loss = 2.30463392654201e-05; Time taken: 0.19124579429626465sss\n",
      "Epoch #138: Average loss is 3.954797840560787e-05\n",
      "Time taken for epoch: 49.656848430633545s\n",
      "\n",
      "Epoch #139: Batch 250/250 -- Loss = 4.644285581889562e-05; Time taken: 0.19761180877685547ss\n",
      "Epoch #139: Average loss is 3.4923928003991026e-05\n",
      "Time taken for epoch: 49.65987777709961s\n",
      "\n",
      "Epoch #140: Batch 250/250 -- Loss = 2.703612517507281e-05; Time taken: 0.19788575172424316ss\n",
      "Epoch #140: Average loss is 3.0867308320011945e-05\n",
      "Epoch #140: Train WER is 0.0\n",
      "Epoch #140: Validation WER is 0.05379959650302623\n",
      "Time taken for epoch: 69.43689012527466s\n",
      "\n",
      "Epoch #141: Batch 250/250 -- Loss = 2.381950616836548e-05; Time taken: 0.19430136680603027ss\n",
      "Epoch #141: Average loss is 2.748304202395957e-05\n",
      "Time taken for epoch: 48.91912865638733s\n",
      "\n",
      "Epoch #142: Batch 250/250 -- Loss = 2.11372971534729e-05; Time taken: 0.19426178932189941sss\n",
      "Epoch #142: Average loss is 2.4524782813386993e-05\n",
      "Time taken for epoch: 49.77398681640625s\n",
      "\n",
      "Epoch #143: Batch 250/250 -- Loss = 2.8811733500333503e-05; Time taken: 0.19274616241455078s\n",
      "Epoch #143: Average loss is 2.1682587554096244e-05\n",
      "Time taken for epoch: 48.98373985290527s\n",
      "\n",
      "Epoch #144: Batch 250/250 -- Loss = 1.2662600056501105e-05; Time taken: 0.1943986415863037ss\n",
      "Epoch #144: Average loss is 1.9158800219884143e-05\n",
      "Time taken for epoch: 48.972980260849s\n",
      "\n",
      "Epoch #145: Batch 250/250 -- Loss = 8.864159099175595e-06; Time taken: 0.19258546829223633ss\n",
      "Epoch #145: Average loss is 1.7001941803755472e-05\n",
      "Epoch #145: Train WER is 0.0\n",
      "Epoch #145: Validation WER is 0.05413584398117014\n",
      "Time taken for epoch: 68.99409747123718s\n",
      "\n",
      "Epoch #146: Batch 250/250 -- Loss = 1.36244025270571e-05; Time taken: 0.1950092315673828s13s\n",
      "Epoch #146: Average loss is 1.5338604420321645e-05\n",
      "Time taken for epoch: 49.06208920478821s\n",
      "\n",
      "Epoch #147: Batch 250/250 -- Loss = 0.018117008730769157; Time taken: 0.19219088554382324sss\n",
      "Epoch #147: Average loss is 0.009424019980810045\n",
      "Time taken for epoch: 48.83843803405762s\n",
      "\n",
      "Epoch #148: Batch 250/250 -- Loss = 0.0035458693746477365; Time taken: 0.1931922435760498ss\n",
      "Epoch #148: Average loss is 0.008985172782093287\n",
      "Time taken for epoch: 49.612876415252686s\n",
      "\n",
      "Epoch #149: Batch 250/250 -- Loss = 0.0008336940663866699; Time taken: 0.1933422088623047sss\n",
      "Epoch #149: Average loss is 0.0021144298377912493\n",
      "Time taken for epoch: 48.95024824142456s\n",
      "\n",
      "Epoch #150: Batch 250/250 -- Loss = 0.0003257918870076537; Time taken: 0.19374632835388184ss\n",
      "Epoch #150: Average loss is 0.0006624543501529842\n",
      "Epoch #150: Train WER is 0.0004573424247463828\n",
      "Epoch #150: Validation WER is 0.05346334902488231\n",
      "Time taken for epoch: 69.2985007762909s\n",
      "\n",
      "Epoch #151: Batch 250/250 -- Loss = 0.00017005781410261989; Time taken: 0.1976780891418457ss\n",
      "Epoch #151: Average loss is 0.0002518644797673915\n",
      "Time taken for epoch: 49.61686682701111s\n",
      "\n",
      "Epoch #152: Batch 250/250 -- Loss = 0.00017722391930874437; Time taken: 0.201399564743042s6s\n",
      "Epoch #152: Average loss is 0.00014598774634941948\n",
      "Time taken for epoch: 49.182819843292236s\n",
      "\n",
      "Epoch #153: Batch 250/250 -- Loss = 5.622546814265661e-05; Time taken: 0.19387149810791016ss\n",
      "Epoch #153: Average loss is 0.00010720399749698117\n",
      "Time taken for epoch: 50.213934898376465s\n",
      "\n",
      "Epoch #154: Batch 250/250 -- Loss = 4.0843744500307366e-05; Time taken: 0.19305419921875s52s\n",
      "Epoch #154: Average loss is 8.416952539118938e-05\n",
      "Time taken for epoch: 48.99533033370972s\n",
      "\n",
      "Epoch #155: Batch 250/250 -- Loss = 7.749619544483721e-05; Time taken: 0.1956651210784912sss\n",
      "Epoch #155: Average loss is 6.893609597318573e-05\n",
      "Epoch #155: Train WER is 0.0\n",
      "Epoch #155: Validation WER is 0.052286482851378616\n",
      "Time taken for epoch: 68.99087882041931s\n",
      "\n",
      "Epoch #156: Batch 250/250 -- Loss = 8.106841414701194e-05; Time taken: 0.19533967971801758ss\n",
      "Epoch #156: Average loss is 5.792355342418887e-05\n",
      "Time taken for epoch: 48.928656816482544s\n",
      "\n",
      "Epoch #157: Batch 250/250 -- Loss = 6.885623588459566e-05; Time taken: 0.1936044692993164s9s\n",
      "Epoch #157: Average loss is 4.9412651562306564e-05\n",
      "Time taken for epoch: 49.74401068687439s\n",
      "\n",
      "Epoch #158: Batch 250/250 -- Loss = 5.8318066294305027e-05; Time taken: 0.20214366912841797s\n",
      "Epoch #158: Average loss is 4.2302486559492535e-05\n",
      "Time taken for epoch: 53.043535470962524s\n",
      "\n",
      "Epoch #159: Batch 250/250 -- Loss = 4.4561584218172356e-05; Time taken: 0.20748138427734375s\n",
      "Epoch #159: Average loss is 3.652207700361032e-05\n",
      "Time taken for epoch: 52.82765007019043s\n",
      "\n",
      "Epoch #160: Batch 250/250 -- Loss = 2.5483694116701372e-05; Time taken: 0.20383715629577637s\n",
      "Epoch #160: Average loss is 3.1768649805599125e-05\n",
      "Epoch #160: Train WER is 0.0\n",
      "Epoch #160: Validation WER is 0.05279085406859448\n",
      "Time taken for epoch: 73.54357933998108s\n",
      "\n",
      "Epoch #161: Batch 250/250 -- Loss = 2.2473321223515086e-05; Time taken: 0.25640177726745605s\n",
      "Epoch #161: Average loss is 2.777051317752921e-05\n",
      "Time taken for epoch: 50.44249749183655s\n",
      "\n",
      "Epoch #162: Batch 250/250 -- Loss = 2.9102984626661055e-05; Time taken: 0.19454002380371094s\n",
      "Epoch #162: Average loss is 2.4594378057372522e-05\n",
      "Time taken for epoch: 50.68286848068237s\n",
      "\n",
      "Epoch #163: Batch 250/250 -- Loss = 0.005426162853837013; Time taken: 0.19548583030700684sss\n",
      "Epoch #163: Average loss is 0.00027124615767752403\n",
      "Time taken for epoch: 49.22058081626892s\n",
      "\n",
      "Epoch #164: Batch 250/250 -- Loss = 0.006588684394955635; Time taken: 0.19855928421020508ss\n",
      "Epoch #164: Average loss is 0.01286669842991978\n",
      "Time taken for epoch: 49.26664185523987s\n",
      "\n",
      "Epoch #165: Batch 250/250 -- Loss = 0.001498980913311243; Time taken: 0.19411873817443848sss\n",
      "Epoch #165: Average loss is 0.0019870484919520095\n",
      "Epoch #165: Train WER is 0.009853650424081158\n",
      "Epoch #165: Validation WER is 0.062373907195696035\n",
      "Time taken for epoch: 69.36549949645996s\n",
      "\n",
      "Epoch #166: Batch 250/250 -- Loss = 0.00027854638756252825; Time taken: 0.19496583938598633s\n",
      "Epoch #166: Average loss is 0.0006955442458274774\n",
      "Time taken for epoch: 49.27246832847595s\n",
      "\n",
      "Epoch #167: Batch 250/250 -- Loss = 0.0002898954844567925; Time taken: 0.19619345664978027ss\n",
      "Epoch #167: Average loss is 0.00026377901597879826\n",
      "Time taken for epoch: 49.255584716796875s\n",
      "\n",
      "Epoch #168: Batch 250/250 -- Loss = 0.00017261234461329877; Time taken: 0.19769024848937988s\n",
      "Epoch #168: Average loss is 0.000322038698286633\n",
      "Time taken for epoch: 49.18190360069275s\n",
      "\n",
      "Epoch #169: Batch 250/250 -- Loss = 0.00010767274216050282; Time taken: 0.2006371021270752ss\n",
      "Epoch #169: Average loss is 0.00015781137646990828\n",
      "Time taken for epoch: 49.1107976436615s\n",
      "\n",
      "Epoch #170: Batch 250/250 -- Loss = 6.363168358802795e-05; Time taken: 0.19489622116088867ss\n",
      "Epoch #170: Average loss is 8.472606343275402e-05\n",
      "Epoch #170: Train WER is 0.0\n",
      "Epoch #170: Validation WER is 0.05094149293880296\n",
      "Time taken for epoch: 69.64436435699463s\n",
      "\n",
      "Epoch #171: Batch 250/250 -- Loss = 6.252984167076647e-05; Time taken: 0.1965165138244629sss\n",
      "Epoch #171: Average loss is 6.224112545169191e-05\n",
      "Time taken for epoch: 48.9468719959259s\n",
      "\n",
      "Epoch #172: Batch 250/250 -- Loss = 5.0966034905286506e-05; Time taken: 0.2023911476135254ss\n",
      "Epoch #172: Average loss is 5.069087986339582e-05\n",
      "Time taken for epoch: 49.24890470504761s\n",
      "\n",
      "Epoch #173: Batch 250/250 -- Loss = 3.1699171813670546e-05; Time taken: 0.19935226440429688s\n",
      "Epoch #173: Average loss is 4.286825789313298e-05\n",
      "Time taken for epoch: 49.13229966163635s\n",
      "\n",
      "Epoch #174: Batch 250/250 -- Loss = 3.667175769805908e-05; Time taken: 0.1973435878753662s5s\n",
      "Epoch #174: Average loss is 3.678031269373605e-05\n",
      "Time taken for epoch: 49.19038248062134s\n",
      "\n",
      "Epoch #175: Batch 250/250 -- Loss = 4.4773587433155626e-05; Time taken: 0.19546222686767578s\n",
      "Epoch #175: Average loss is 3.1790344553883186e-05\n",
      "Epoch #175: Train WER is 0.0\n",
      "Epoch #175: Validation WER is 0.05110961667787491\n",
      "Time taken for epoch: 69.68638134002686s\n",
      "\n",
      "Epoch #176: Batch 250/250 -- Loss = 2.9926612114650197e-05; Time taken: 0.19648480415344238s\n",
      "Epoch #176: Average loss is 2.771489929727977e-05\n",
      "Time taken for epoch: 49.31667494773865s\n",
      "\n",
      "Epoch #177: Batch 250/250 -- Loss = 2.5842677132459357e-05; Time taken: 0.19287729263305664s\n",
      "Epoch #177: Average loss is 2.423808518142323e-05\n",
      "Time taken for epoch: 49.220072746276855s\n",
      "\n",
      "Epoch #178: Batch 250/250 -- Loss = 2.290918018843513e-05; Time taken: 0.19958829879760742ss\n",
      "Epoch #178: Average loss is 2.12132375127112e-05\n",
      "Time taken for epoch: 48.99744462966919s\n",
      "\n",
      "Epoch #179: Batch 250/250 -- Loss = 1.660091038502287e-05; Time taken: 0.19743084907531738ss\n",
      "Epoch #179: Average loss is 1.8673125367058672e-05\n",
      "Time taken for epoch: 49.29610347747803s\n",
      "\n",
      "Epoch #180: Batch 250/250 -- Loss = 2.5932762582669966e-05; Time taken: 0.19318938255310059s\n",
      "Epoch #180: Average loss is 1.6457506175356683e-05\n",
      "Epoch #180: Train WER is 0.0\n",
      "Epoch #180: Validation WER is 0.05144586415601883\n",
      "Time taken for epoch: 69.38306641578674s\n",
      "\n",
      "Epoch #181: Batch 250/250 -- Loss = 1.0031190868176054e-05; Time taken: 0.19608402252197266s\n",
      "Epoch #181: Average loss is 1.4587771494916523e-05\n",
      "Time taken for epoch: 49.005977630615234s\n",
      "\n",
      "Epoch #182: Batch 250/250 -- Loss = 2.288682844664436e-05; Time taken: 0.1982884407043457s4s\n",
      "Epoch #182: Average loss is 1.3301604207299534e-05\n",
      "Time taken for epoch: 48.8686466217041s\n",
      "\n",
      "Epoch #183: Batch 250/250 -- Loss = 0.0077980514615774155; Time taken: 0.19213628768920898s\n",
      "Epoch #183: Average loss is 0.011106060172771322\n",
      "Time taken for epoch: 48.90650415420532s\n",
      "\n",
      "Epoch #184: Batch 250/250 -- Loss = 0.0006209515267983079; Time taken: 0.19537997245788574s\n",
      "Epoch #184: Average loss is 0.0024447144280420616\n",
      "Time taken for epoch: 48.90044283866882s\n",
      "\n",
      "Epoch #185: Batch 250/250 -- Loss = 0.0003377613902557641; Time taken: 0.1968069076538086sss\n",
      "Epoch #185: Average loss is 0.0008678810317069292\n",
      "Epoch #185: Train WER is 0.0013304506901712955\n",
      "Epoch #185: Validation WER is 0.05363147276395427\n",
      "Time taken for epoch: 69.12834000587463s\n",
      "\n",
      "Epoch #186: Batch 250/250 -- Loss = 0.00013029643741901964; Time taken: 0.19729399681091309s\n",
      "Epoch #186: Average loss is 0.0002789476453035604\n",
      "Time taken for epoch: 48.959349393844604s\n",
      "\n",
      "Epoch #187: Batch 250/250 -- Loss = 0.00013475898595061153; Time taken: 0.1930689811706543ss\n",
      "Epoch #187: Average loss is 0.00013097525760531425\n",
      "Time taken for epoch: 48.867347717285156s\n",
      "\n",
      "Epoch #188: Batch 250/250 -- Loss = 7.979537622304633e-05; Time taken: 0.19285845756530762ss\n",
      "Epoch #188: Average loss is 9.095173742389306e-05\n",
      "Time taken for epoch: 48.716352701187134s\n",
      "\n",
      "Epoch #189: Batch 250/250 -- Loss = 8.339332998730242e-05; Time taken: 0.1936933994293213s4s\n",
      "Epoch #189: Average loss is 7.026812106050784e-05\n",
      "Time taken for epoch: 48.828577280044556s\n",
      "\n",
      "Epoch #190: Batch 250/250 -- Loss = 7.186457514762878e-05; Time taken: 0.19255423545837402ss\n",
      "Epoch #190: Average loss is 5.871357498836005e-05\n",
      "Epoch #190: Train WER is 0.00012472975220355895\n",
      "Epoch #190: Validation WER is 0.04976462676529926\n",
      "Time taken for epoch: 69.27575373649597s\n",
      "\n",
      "Epoch #191: Batch 250/250 -- Loss = 0.0036798701621592045; Time taken: 0.19709062576293945ss\n",
      "Epoch #191: Average loss is 0.0013509045885002706\n",
      "Time taken for epoch: 48.85100603103638s\n",
      "\n",
      "Epoch #192: Batch 250/250 -- Loss = 0.002543909940868616; Time taken: 0.19202971458435059sss\n",
      "Epoch #192: Average loss is 0.002400738282361999\n",
      "Time taken for epoch: 48.84647846221924s\n",
      "\n",
      "Epoch #193: Batch 250/250 -- Loss = 0.0006530582904815674; Time taken: 0.19313979148864746ss\n",
      "Epoch #193: Average loss is 0.0013950064379023388\n",
      "Time taken for epoch: 48.840866804122925s\n",
      "\n",
      "Epoch #194: Batch 250/250 -- Loss = 0.0008923914283514023; Time taken: 0.1933138370513916s4s\n",
      "Epoch #194: Average loss is 0.000883206287631765\n",
      "Time taken for epoch: 48.821669816970825s\n",
      "\n",
      "Epoch #195: Batch 250/250 -- Loss = 0.0008692399132996798; Time taken: 0.1999824047088623s2s\n",
      "Epoch #195: Average loss is 0.0009383915439830162\n",
      "Epoch #195: Train WER is 0.002868784300681856\n",
      "Epoch #195: Validation WER is 0.05110961667787491\n",
      "Time taken for epoch: 69.14493942260742s\n",
      "\n",
      "Epoch #196: Batch 250/250 -- Loss = 0.00023018331557977945; Time taken: 0.19223833084106445s\n",
      "Epoch #196: Average loss is 0.0004249398946558358\n",
      "Time taken for epoch: 49.01814389228821s\n",
      "\n",
      "Epoch #197: Batch 250/250 -- Loss = 0.0005294958245940506; Time taken: 0.19404029846191406ss\n",
      "Epoch #197: Average loss is 0.0002608335008844733\n",
      "Time taken for epoch: 48.99120545387268s\n",
      "\n",
      "Epoch #198: Batch 250/250 -- Loss = 9.740042150951922e-05; Time taken: 0.19453811645507812ss\n",
      "Epoch #198: Average loss is 0.00020096952810126823\n",
      "Time taken for epoch: 48.97685718536377s\n",
      "\n",
      "Epoch #199: Batch 250/250 -- Loss = 5.670061000273563e-05; Time taken: 0.19883084297180176ss\n",
      "Epoch #199: Average loss is 6.682237394852563e-05\n",
      "Time taken for epoch: 48.88680601119995s\n",
      "\n",
      "Epoch #200: Batch 250/250 -- Loss = 3.16460027534049e-05; Time taken: 0.1955418586730957ssss\n",
      "Epoch #200: Average loss is 4.3747059346060265e-05\n",
      "Epoch #200: Train WER is 0.0\n",
      "Epoch #200: Validation WER is 0.04606590450571621\n",
      "Time taken for epoch: 69.39330244064331s\n",
      "\n",
      "Training completed in 10739.910420417786s\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "our, our_stats = task_our.train(epochs=200, train_loader=train_loader, valid_loader=valid_loader, \n",
    "                                out_dir='dump/Seq2SeqSame/Our/', freq=5, vocab=babi.vocab, \n",
    "                                wer_dict=babi.wer_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix: \n",
      " [[304  35  55  17  35  15]\n",
      " [ 52 278  29  28  29  25]\n",
      " [ 46  27 405  37  53  39]\n",
      " [ 59  49  31 311  42  35]\n",
      " [ 47  34  44  32 303  37]\n",
      " [ 38  24  17  36  16 336]]\n",
      "\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           7       0.56      0.66      0.60       461\n",
      "          10       0.62      0.63      0.63       441\n",
      "          16       0.70      0.67      0.68       607\n",
      "          17       0.67      0.59      0.63       527\n",
      "          20       0.63      0.61      0.62       497\n",
      "          21       0.69      0.72      0.70       467\n",
      "\n",
      "   micro avg       0.65      0.65      0.65      3000\n",
      "   macro avg       0.65      0.65      0.64      3000\n",
      "weighted avg       0.65      0.65      0.65      3000\n",
      "\n",
      "0.35433333333333333\n"
     ]
    }
   ],
   "source": [
    "our_wer, _ = task_our.evaluate(test_loader, babi.vocab, babi.wer_dict, verbose=True)\n",
    "print(our_wer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " \r",
      " \r",
      " \r",
      " \r",
      " \r",
      " \r",
      " \r",
      " \r",
      " \r",
      " \r",
      " \r",
      " \r",
      " \r",
      " \r",
      " \r",
      " \r",
      " \r",
      " \r",
      " \r",
      " \r",
      " \r",
      " \r",
      " \r",
      " \r",
      " \r",
      " \r",
      " \r",
      " \r",
      " \r",
      " \r",
      " \r",
      " \r",
      " \r",
      " \r",
      " Mary moved to the hallway . Sandra went to the garden . Where is Sandra ? Mary went back to the kitchen . Sandra journeyed to the kitchen . Where is Sandra ? Daniel went back to the garden . John went to the garden . Where is John ?\n",
      "                 garden       kitchen       garden\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\r",
      " \r",
      " \r",
      " \r",
      " \r",
      " \r",
      " \r",
      " \r",
      " \r",
      " \r",
      " \r",
      " \r",
      " \r",
      " \r",
      " \r",
      " \r",
      " \r",
      " \r",
      " \r",
      " Mary moved to the hallway . Sandra went to the garden . Where is Sandra ? Mary went back to the kitchen . Sandra journeyed to the kitchen . Where is Sandra ? Daniel went back to the garden . John went to the garden . Where is John ? Mary travelled to the office . Sandra went to the bathroom . Where is Daniel ?\n",
      "            garden       kitchen       garden      garden\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\r",
      " \r",
      " Mary moved to the hallway . Sandra went to the garden . Where is Sandra ? Mary went back to the kitchen . Sandra journeyed to the kitchen . Where is Sandra ? Daniel went back to the garden . John went to the garden . Where is John ? Mary travelled to the office . Sandra went to the bathroom . Where is Daniel ? Mary moved to the garden . Daniel went back to the office . Where is Mary ?\n",
      "      garden       kitchen       garden      garden       garden\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\r",
      " \r",
      " \r",
      " \r",
      " \r",
      " \r",
      " \r",
      " \r",
      " \r",
      " \r",
      " \r",
      " \r",
      " \r",
      " \r",
      " \r",
      " \r",
      " \r",
      " \r",
      " \r",
      " \r",
      " \r",
      " \r",
      " \r",
      " \r",
      " \r",
      " \r",
      " \r",
      " \r",
      " \r",
      " \r",
      " \r",
      " \r",
      " \r",
      " \r",
      " \r",
      " \r",
      " \r",
      " \r",
      " \r",
      " \r",
      " \r",
      " \r",
      " \r",
      " \r",
      " \r",
      " \r",
      " \r",
      " \r",
      " \r",
      " \r",
      " \r",
      " \r",
      " \r",
      " \r",
      " \r",
      " \r",
      " \r",
      " \r",
      " \r",
      " \r",
      " \r",
      " \r",
      " \r",
      " \r",
      " \r",
      " \r",
      " \r",
      " \r",
      " \r",
      " Sandra moved to the kitchen . John travelled to the kitchen . Where is John ?\n",
      "                            kitchen\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\r",
      " \r",
      " \r",
      " \r",
      " \r",
      " \r",
      " \r",
      " \r",
      " \r",
      " \r",
      " \r",
      " \r",
      " \r",
      " \r",
      " \r",
      " \r",
      " \r",
      " \r",
      " \r",
      " \r",
      " \r",
      " \r",
      " \r",
      " \r",
      " \r",
      " \r",
      " \r",
      " \r",
      " \r",
      " \r",
      " \r",
      " \r",
      " \r",
      " \r",
      " \r",
      " \r",
      " \r",
      " \r",
      " \r",
      " \r",
      " \r",
      " \r",
      " \r",
      " \r",
      " \r",
      " \r",
      " \r",
      " \r",
      " \r",
      " \r",
      " \r",
      " \r",
      " \r",
      " Sandra moved to the kitchen . John travelled to the kitchen . Where is John ? Sandra moved to the hallway . Daniel journeyed to the hallway . Where is Sandra ?\n",
      "                       kitchen      hallway\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\r",
      " \r",
      " \r",
      " \r",
      " \r",
      " \r",
      " \r",
      " \r",
      " \r",
      " \r",
      " \r",
      " \r",
      " \r",
      " \r",
      " \r",
      " \r",
      " \r",
      " \r",
      " \r",
      " \r",
      " \r",
      " \r",
      " \r",
      " \r",
      " \r",
      " \r",
      " \r",
      " \r",
      " \r",
      " \r",
      " \r",
      " \r",
      " \r",
      " \r",
      " \r",
      " \r",
      " \r",
      " Sandra moved to the kitchen . John travelled to the kitchen . Where is John ? Sandra moved to the hallway . Daniel journeyed to the hallway . Where is Sandra ? Sandra travelled to the office . John moved to the bedroom . Where is Sandra ?\n",
      "                  kitchen      hallway      office\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\r",
      " \r",
      " \r",
      " \r",
      " \r",
      " \r",
      " \r",
      " \r",
      " \r",
      " \r",
      " \r",
      " \r",
      " \r",
      " \r",
      " \r",
      " \r",
      " \r",
      " \r",
      " \r",
      " \r",
      " Sandra moved to the kitchen . John travelled to the kitchen . Where is John ? Sandra moved to the hallway . Daniel journeyed to the hallway . Where is Sandra ? Sandra travelled to the office . John moved to the bedroom . Where is Sandra ? Sandra went back to the garden . Sandra travelled to the bathroom . Where is Sandra ?\n",
      "            kitchen      hallway      office       garden\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\r",
      " \r",
      " \r",
      " \r",
      " Sandra moved to the kitchen . John travelled to the kitchen . Where is John ? Sandra moved to the hallway . Daniel journeyed to the hallway . Where is Sandra ? Sandra travelled to the office . John moved to the bedroom . Where is Sandra ? Sandra went back to the garden . Sandra travelled to the bathroom . Where is Sandra ? Sandra moved to the office . Daniel journeyed to the garden . Where is John ?\n",
      "       kitchen      hallway      office       garden      garden\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for text, label in test_loader:\n",
    "    pass\n",
    "h = torch.zeros(2 * task_our.model.layers, label.shape[0], task_our.model.hidden_dim).to(device)\n",
    "c = torch.zeros(2 * task_our.model.layers, label.shape[0], task_our.model.hidden_dim).to(device)\n",
    "o = task_our.model(text.transpose(0, 1).to(device), h, c)\n",
    "for i in range(text.shape[0]):\n",
    "    s1 = ' '.join(babi.vocab[torch.argmax(text, 2)[i].numpy()])\n",
    "    s1 = s1.replace('_', '\\r')\n",
    "    s2 = ' '.join(babi.vocab[torch.argmax(o.transpose(1,0), 2)[i].cpu().numpy()])\n",
    "    s2 = s2.replace('_ _ _', '')\n",
    "    s2 = s2.replace('_ _', '')\n",
    "    s2 = s2.replace('_', '')\n",
    "    print(s1)\n",
    "    print(s2)\n",
    "    print(\"-\" * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['_' '_' '_' '_' '_' '_' '_' '_' '_' '_' '_' '_' '_' '_' '_' '_' '_' '_'\n",
      " '_' '_' '_' '_' '_' '_' '_' '_' '_' '_' '_' '_' '_' '_' '_' '_' '_'\n",
      " 'Mary' 'moved' 'to' 'the' 'hallway' '.' 'Sandra' 'went' 'to' 'the'\n",
      " 'garden' '.' 'Where' 'is' 'Sandra' '?' 'Mary' 'went' 'back' 'to' 'the'\n",
      " 'kitchen' '.' 'Sandra' 'journeyed' 'to' 'the' 'kitchen' '.' 'Where' 'is'\n",
      " 'Sandra' '?' 'Daniel' 'went' 'back' 'to' 'the' 'garden' '.' 'John' 'went'\n",
      " 'to' 'the' 'garden' '.' 'Where' 'is' 'John' '?']\n",
      "['_' '_' '_' '_' '_' '_' '_' '_' '_' '_' '_' '_' '_' '_' '_' '_' '_' '_'\n",
      " '_' '_' '_' '_' '_' '_' '_' '_' '_' '_' '_' '_' '_' '_' '_' '_' '_' '_'\n",
      " '_' '_' '_' '_' '_' '_' '_' '_' '_' '_' '_' '_' '_' '_' 'garden' '_' '_'\n",
      " '_' '_' '_' '_' '_' '_' '_' '_' '_' '_' '_' '_' '_' '_' 'kitchen' '_' '_'\n",
      " '_' '_' '_' '_' '_' '_' '_' '_' '_' '_' '_' '_' '_' '_' 'garden']\n"
     ]
    }
   ],
   "source": [
    " #.shape, text.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PyTorch implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our implementation\n",
      "==================\n",
      "# of parameters: 161302\n",
      "lstm.weight_ih_l0        : torch.Size([512, 22])\n",
      "lstm.weight_hh_l0        : torch.Size([512, 128])\n",
      "lstm.bias_ih_l0          : torch.Size([512])\n",
      "lstm.bias_hh_l0          : torch.Size([512])\n",
      "lstm.weight_ih_l0_reverse: torch.Size([512, 22])\n",
      "lstm.weight_hh_l0_reverse: torch.Size([512, 128])\n",
      "lstm.bias_ih_l0_reverse  : torch.Size([512])\n",
      "lstm.bias_hh_l0_reverse  : torch.Size([512])\n",
      "fc.weight                : torch.Size([22, 256])\n",
      "fc.bias                  : torch.Size([22])\n"
     ]
    }
   ],
   "source": [
    "from seq_seq_same import PyTorchBaseline\n",
    "\n",
    "pytorch = PyTorchBaseline(input_dim=input_dim, hidden_dim=hidden_dim, output_dim=output_dim, \n",
    "                        layers=layers, bidirectional=bidirectional).to(device)\n",
    "\n",
    "print(\"Our implementation\\n{}\".format(\"=\" * len(\"Our implementation\")))\n",
    "print(\"# of parameters: {}\".format(pytorch.count_parameters()))\n",
    "for name, param in pytorch.named_parameters():\n",
    "    print(\"{:<25}: {}\".format(name, param.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from seq_seq_same import Seq2SeqSame\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer_pytorch = torch.optim.Adam(pytorch.parameters(), lr=learning_rate)\n",
    "\n",
    "task_pytorch = Seq2SeqSame(pytorch, optimizer_pytorch, loss_fn, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beginning training model with 161302 parameters\n",
      "Files will be saved in: dump/Seq2SeqSame/PyTorch/\n",
      "\n",
      "Epoch #1: Batch 250/250 -- Loss = 0.09766252338886261; Time taken: 0.01817774772644043ss\n",
      "Epoch #1: Average loss is 0.3309956705272198\n",
      "Epoch #1: Train WER is 1.0\n",
      "Epoch #1: Validation WER is 1.0\n",
      "Time taken for epoch: 7.812786340713501s\n",
      "\n",
      "Epoch #2: Batch 250/250 -- Loss = 0.06445416808128357; Time taken: 0.017499685287475586ss\n",
      "Epoch #2: Average loss is 0.07100786229968072\n",
      "Time taken for epoch: 5.115179061889648s\n",
      "\n",
      "Epoch #3: Batch 250/250 -- Loss = 0.05718819051980972; Time taken: 0.02117466926574707s8s\n",
      "Epoch #3: Average loss is 0.061803809136152264\n",
      "Time taken for epoch: 5.38176417350769s\n",
      "\n",
      "Epoch #4: Batch 250/250 -- Loss = 0.05517381802201271; Time taken: 0.01703357696533203s2s\n",
      "Epoch #4: Average loss is 0.05652186757326126\n",
      "Time taken for epoch: 5.35343599319458s\n",
      "\n",
      "Epoch #5: Batch 250/250 -- Loss = 0.041883114725351334; Time taken: 0.021523475646972656s\n",
      "Epoch #5: Average loss is 0.051234923228621485\n",
      "Epoch #5: Train WER is 0.48756860136371194\n",
      "Epoch #5: Validation WER is 0.48655010087424344\n",
      "Time taken for epoch: 7.979350805282593s\n",
      "\n",
      "Epoch #6: Batch 250/250 -- Loss = 0.040546614676713943; Time taken: 0.027051925659179688s\n",
      "Epoch #6: Average loss is 0.047134723104536536\n",
      "Time taken for epoch: 5.16032075881958s\n",
      "\n",
      "Epoch #7: Batch 250/250 -- Loss = 0.05369243770837784; Time taken: 0.01847672462463379sss\n",
      "Epoch #7: Average loss is 0.044751529008150104\n",
      "Time taken for epoch: 5.220989942550659s\n",
      "\n",
      "Epoch #8: Batch 250/250 -- Loss = 0.040507618337869644; Time taken: 0.01700758934020996ss\n",
      "Epoch #8: Average loss is 0.042026311106979845\n",
      "Time taken for epoch: 5.106754779815674s\n",
      "\n",
      "Epoch #9: Batch 250/250 -- Loss = 0.03669309616088867; Time taken: 0.017977476119995117ss\n",
      "Epoch #9: Average loss is 0.039281597316265106\n",
      "Time taken for epoch: 5.240970849990845s\n",
      "\n",
      "Epoch #10: Batch 250/250 -- Loss = 0.03682746738195419; Time taken: 0.016551494598388672ss\n",
      "Epoch #10: Average loss is 0.03749685399979353\n",
      "Epoch #10: Train WER is 0.4416680525528023\n",
      "Epoch #10: Validation WER is 0.4546065904505716\n",
      "Time taken for epoch: 7.978294849395752s\n",
      "\n",
      "Epoch #11: Batch 250/250 -- Loss = 0.04281563684344292; Time taken: 0.016800880432128906ss\n",
      "Epoch #11: Average loss is 0.03676593726873398\n",
      "Time taken for epoch: 5.340903282165527s\n",
      "\n",
      "Epoch #12: Batch 250/250 -- Loss = 0.031123735010623932; Time taken: 0.02308821678161621ss\n",
      "Epoch #12: Average loss is 0.03611405229568482\n",
      "Time taken for epoch: 5.056676864624023s\n",
      "\n",
      "Epoch #13: Batch 250/250 -- Loss = 0.028564482927322388; Time taken: 0.025736093521118164s\n",
      "Epoch #13: Average loss is 0.03517577651888132\n",
      "Time taken for epoch: 5.033196449279785s\n",
      "\n",
      "Epoch #14: Batch 250/250 -- Loss = 0.03536283224821091; Time taken: 0.018703460693359375ss\n",
      "Epoch #14: Average loss is 0.03464910092204809\n",
      "Time taken for epoch: 5.125532150268555s\n",
      "\n",
      "Epoch #15: Batch 250/250 -- Loss = 0.028355050832033157; Time taken: 0.01577281951904297ss\n",
      "Epoch #15: Average loss is 0.033843442276120184\n",
      "Epoch #15: Train WER is 0.4271994012971894\n",
      "Epoch #15: Validation WER is 0.44720914593140554\n",
      "Time taken for epoch: 7.677520275115967s\n",
      "\n",
      "Epoch #16: Batch 250/250 -- Loss = 0.04400521144270897; Time taken: 0.02103590965270996sss\n",
      "Epoch #16: Average loss is 0.03342747548222542\n",
      "Time taken for epoch: 5.0548577308654785s\n",
      "\n",
      "Epoch #17: Batch 250/250 -- Loss = 0.035031527280807495; Time taken: 0.017908334732055664s\n",
      "Epoch #17: Average loss is 0.03274182055145502\n",
      "Time taken for epoch: 5.036455869674683s\n",
      "\n",
      "Epoch #18: Batch 250/250 -- Loss = 0.02523847669363022; Time taken: 0.01632070541381836sss\n",
      "Epoch #18: Average loss is 0.032297036223113536\n",
      "Time taken for epoch: 5.000476598739624s\n",
      "\n",
      "Epoch #19: Batch 250/250 -- Loss = 0.026830244809389114; Time taken: 0.023165225982666016s\n",
      "Epoch #19: Average loss is 0.03203717959672213\n",
      "Time taken for epoch: 5.00891900062561s\n",
      "\n",
      "Epoch #20: Batch 250/250 -- Loss = 0.03435930237174034; Time taken: 0.015655994415283203ss\n",
      "Epoch #20: Average loss is 0.03143363679945469\n",
      "Epoch #20: Train WER is 0.41497588558124066\n",
      "Epoch #20: Validation WER is 0.44115669132481505\n",
      "Time taken for epoch: 7.714197874069214s\n",
      "\n",
      "Epoch #21: Batch 250/250 -- Loss = 0.03163671866059303; Time taken: 0.015745162963867188ss\n",
      "Epoch #21: Average loss is 0.031153315201401712\n",
      "Time taken for epoch: 4.8843841552734375s\n",
      "\n",
      "Epoch #22: Batch 250/250 -- Loss = 0.033881112933158875; Time taken: 0.016305923461914062s\n",
      "Epoch #22: Average loss is 0.030883265405893326\n",
      "Time taken for epoch: 4.834594011306763s\n",
      "\n",
      "Epoch #23: Batch 250/250 -- Loss = 0.02630731277167797; Time taken: 0.014871597290039062ss\n",
      "Epoch #23: Average loss is 0.030618568263947963\n",
      "Time taken for epoch: 4.8163416385650635s\n",
      "\n",
      "Epoch #24: Batch 250/250 -- Loss = 0.02924834005534649; Time taken: 0.0245668888092041s6ss\n",
      "Epoch #24: Average loss is 0.03012985710054636\n",
      "Time taken for epoch: 4.768964767456055s\n",
      "\n",
      "Epoch #25: Batch 250/250 -- Loss = 0.03179594501852989; Time taken: 0.014668464660644531ss\n",
      "Epoch #25: Average loss is 0.029934516668319703\n",
      "Epoch #25: Train WER is 0.39896890071511726\n",
      "Epoch #25: Validation WER is 0.42552118359112306\n",
      "Time taken for epoch: 7.513542413711548s\n",
      "\n",
      "Epoch #26: Batch 250/250 -- Loss = 0.029235124588012695; Time taken: 0.016144275665283203s\n",
      "Epoch #26: Average loss is 0.02946425163000822\n",
      "Time taken for epoch: 4.7118353843688965s\n",
      "\n",
      "Epoch #27: Batch 250/250 -- Loss = 0.027496622875332832; Time taken: 0.014677286148071289s\n",
      "Epoch #27: Average loss is 0.029013187624514103\n",
      "Time taken for epoch: 4.69512939453125s\n",
      "\n",
      "Epoch #28: Batch 250/250 -- Loss = 0.022453440353274345; Time taken: 0.015241384506225586s\n",
      "Epoch #28: Average loss is 0.028772642567753793\n",
      "Time taken for epoch: 4.785258054733276s\n",
      "\n",
      "Epoch #29: Batch 250/250 -- Loss = 0.028597449883818626; Time taken: 0.016218185424804688s\n",
      "Epoch #29: Average loss is 0.02829234164953232\n",
      "Time taken for epoch: 5.066491603851318s\n",
      "\n",
      "Epoch #30: Batch 250/250 -- Loss = 0.033525194972753525; Time taken: 0.01714634895324707ss\n",
      "Epoch #30: Average loss is 0.027774094700813292\n",
      "Epoch #30: Train WER is 0.3593879926825212\n",
      "Epoch #30: Validation WER is 0.40063887020847344\n",
      "Time taken for epoch: 8.117911100387573s\n",
      "\n",
      "Epoch #31: Batch 250/250 -- Loss = 0.027772944420576096; Time taken: 0.018890857696533203s\n",
      "Epoch #31: Average loss is 0.027622494041919708\n",
      "Time taken for epoch: 4.902501344680786s\n",
      "\n",
      "Epoch #32: Batch 250/250 -- Loss = 0.03201417624950409; Time taken: 0.01788163185119629s2s\n",
      "Epoch #32: Average loss is 0.02698000782728195\n",
      "Time taken for epoch: 4.814249515533447s\n",
      "\n",
      "Epoch #33: Batch 250/250 -- Loss = 0.0334276482462883; Time taken: 0.017009496688842773s4s\n",
      "Epoch #33: Average loss is 0.02626714674383402\n",
      "Time taken for epoch: 5.048528432846069s\n",
      "\n",
      "Epoch #34: Batch 250/250 -- Loss = 0.023068953305482864; Time taken: 0.01922917366027832ss\n",
      "Epoch #34: Average loss is 0.02580314873158932\n",
      "Time taken for epoch: 4.93598747253418s\n",
      "\n",
      "Epoch #35: Batch 250/250 -- Loss = 0.029862798750400543; Time taken: 0.019371747970581055s\n",
      "Epoch #35: Average loss is 0.02534276545792818\n",
      "Epoch #35: Train WER is 0.3110344254116082\n",
      "Epoch #35: Validation WER is 0.36735036987222597\n",
      "Time taken for epoch: 7.6835548877716064s\n",
      "\n",
      "Epoch #36: Batch 250/250 -- Loss = 0.01908446103334427; Time taken: 0.017308950424194336ss\n",
      "Epoch #36: Average loss is 0.0243541387245059\n",
      "Time taken for epoch: 4.813742399215698s\n",
      "\n",
      "Epoch #37: Batch 250/250 -- Loss = 0.021750539541244507; Time taken: 0.01854848861694336ss\n",
      "Epoch #37: Average loss is 0.023621423441916704\n",
      "Time taken for epoch: 4.707737922668457s\n",
      "\n",
      "Epoch #38: Batch 250/250 -- Loss = 0.02157421037554741; Time taken: 0.02570962905883789sss\n",
      "Epoch #38: Average loss is 0.022975371453911066\n",
      "Time taken for epoch: 4.731321096420288s\n",
      "\n",
      "Epoch #39: Batch 250/250 -- Loss = 0.023724544793367386; Time taken: 0.01710820198059082ss\n",
      "Epoch #39: Average loss is 0.022569413580000402\n",
      "Time taken for epoch: 4.6365344524383545s\n",
      "\n",
      "Epoch #40: Batch 250/250 -- Loss = 0.022028062492609024; Time taken: 0.01689457893371582ss\n",
      "Epoch #40: Average loss is 0.021288848239928482\n",
      "Epoch #40: Train WER is 0.26276401130883087\n",
      "Epoch #40: Validation WER is 0.3343981170141224\n",
      "Time taken for epoch: 7.472751140594482s\n",
      "\n",
      "Epoch #41: Batch 250/250 -- Loss = 0.015375928021967411; Time taken: 0.020060062408447266s\n",
      "Epoch #41: Average loss is 0.020651797607541083\n",
      "Time taken for epoch: 4.740387201309204s\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #42: Batch 250/250 -- Loss = 0.022698311135172844; Time taken: 0.021372556686401367s\n",
      "Epoch #42: Average loss is 0.020287653382867574\n",
      "Time taken for epoch: 4.657675504684448s\n",
      "\n",
      "Epoch #43: Batch 250/250 -- Loss = 0.020856307819485664; Time taken: 0.020241498947143555s\n",
      "Epoch #43: Average loss is 0.019131135825067758\n",
      "Time taken for epoch: 4.691173791885376s\n",
      "\n",
      "Epoch #44: Batch 250/250 -- Loss = 0.01909993588924408; Time taken: 0.018783092498779297ss\n",
      "Epoch #44: Average loss is 0.018400690663605928\n",
      "Time taken for epoch: 4.684077024459839s\n",
      "\n",
      "Epoch #45: Batch 250/250 -- Loss = 0.01586349681019783; Time taken: 0.01599884033203125sss\n",
      "Epoch #45: Average loss is 0.01729416811466217\n",
      "Epoch #45: Train WER is 0.17769832030600366\n",
      "Epoch #45: Validation WER is 0.27051109616677876\n",
      "Time taken for epoch: 7.411954402923584s\n",
      "\n",
      "Epoch #46: Batch 250/250 -- Loss = 0.015193642117083073; Time taken: 0.016649484634399414s\n",
      "Epoch #46: Average loss is 0.01727966082468629\n",
      "Time taken for epoch: 4.722104549407959s\n",
      "\n",
      "Epoch #47: Batch 250/250 -- Loss = 0.012173430062830448; Time taken: 0.019287109375s9688ss\n",
      "Epoch #47: Average loss is 0.015811684623360633\n",
      "Time taken for epoch: 4.6524693965911865s\n",
      "\n",
      "Epoch #48: Batch 250/250 -- Loss = 0.01480970997363329; Time taken: 0.01488494873046875sss\n",
      "Epoch #48: Average loss is 0.015206221759319306\n",
      "Time taken for epoch: 4.679470539093018s\n",
      "\n",
      "Epoch #49: Batch 250/250 -- Loss = 0.017578529193997383; Time taken: 0.015145301818847656s\n",
      "Epoch #49: Average loss is 0.01423914048448205\n",
      "Time taken for epoch: 4.6837732791900635s\n",
      "\n",
      "Epoch #50: Batch 250/250 -- Loss = 0.012985066510736942; Time taken: 0.016904592514038086s\n",
      "Epoch #50: Average loss is 0.013400722123682499\n",
      "Epoch #50: Train WER is 0.12564443705305173\n",
      "Epoch #50: Validation WER is 0.2183927370544721\n",
      "Time taken for epoch: 7.376039266586304s\n",
      "\n",
      "Epoch #51: Batch 250/250 -- Loss = 0.010190441273152828; Time taken: 0.017049789428710938s\n",
      "Epoch #51: Average loss is 0.012749116091057658\n",
      "Time taken for epoch: 4.712043046951294s\n",
      "\n",
      "Epoch #52: Batch 250/250 -- Loss = 0.012272551655769348; Time taken: 0.017758846282958984s\n",
      "Epoch #52: Average loss is 0.012598913967609406\n",
      "Time taken for epoch: 4.659679651260376s\n",
      "\n",
      "Epoch #53: Batch 250/250 -- Loss = 0.015244930982589722; Time taken: 0.020357608795166016ss\n",
      "Epoch #53: Average loss is 0.011495582299306988\n",
      "Time taken for epoch: 4.725974798202515s\n",
      "\n",
      "Epoch #54: Batch 250/250 -- Loss = 0.010850637219846249; Time taken: 0.01872873306274414sss\n",
      "Epoch #54: Average loss is 0.010882012952119113\n",
      "Time taken for epoch: 4.660046100616455s\n",
      "\n",
      "Epoch #55: Batch 250/250 -- Loss = 0.008758129552006721; Time taken: 0.01825737953186035ss\n",
      "Epoch #55: Average loss is 0.010597360720857978\n",
      "Epoch #55: Train WER is 0.09013803425910527\n",
      "Epoch #55: Validation WER is 0.175857431069267\n",
      "Time taken for epoch: 7.465376138687134s\n",
      "\n",
      "Epoch #56: Batch 250/250 -- Loss = 0.0090806744992733; Time taken: 0.018149852752685547s2ss\n",
      "Epoch #56: Average loss is 0.009893391635268927\n",
      "Time taken for epoch: 4.689274072647095s\n",
      "\n",
      "Epoch #57: Batch 250/250 -- Loss = 0.012261325493454933; Time taken: 0.018367767333984375ss\n",
      "Epoch #57: Average loss is 0.008836485761217773\n",
      "Time taken for epoch: 4.64194130897522s\n",
      "\n",
      "Epoch #58: Batch 250/250 -- Loss = 0.011535688303411007; Time taken: 0.017043113708496094ss\n",
      "Epoch #58: Average loss is 0.008688943644985557\n",
      "Time taken for epoch: 4.657687187194824s\n",
      "\n",
      "Epoch #59: Batch 250/250 -- Loss = 0.012976238504052162; Time taken: 0.020827770233154297ss\n",
      "Epoch #59: Average loss is 0.007993274208158254\n",
      "Time taken for epoch: 4.650928497314453s\n",
      "\n",
      "Epoch #60: Batch 250/250 -- Loss = 0.006694127339869738; Time taken: 0.017446517944335938ss\n",
      "Epoch #60: Average loss is 0.007715252737514675\n",
      "Epoch #60: Train WER is 0.05720937967736571\n",
      "Epoch #60: Validation WER is 0.14038332212508406\n",
      "Time taken for epoch: 7.507076025009155s\n",
      "\n",
      "Epoch #61: Batch 250/250 -- Loss = 0.004525978583842516; Time taken: 0.015652894973754883ss\n",
      "Epoch #61: Average loss is 0.006712228494696319\n",
      "Time taken for epoch: 4.714385271072388s\n",
      "\n",
      "Epoch #62: Batch 250/250 -- Loss = 0.005563575308769941; Time taken: 0.014889955520629883ss\n",
      "Epoch #62: Average loss is 0.007244033352471888\n",
      "Time taken for epoch: 4.652435302734375s\n",
      "\n",
      "Epoch #63: Batch 250/250 -- Loss = 0.004554552026093006; Time taken: 0.017579078674316406ss\n",
      "Epoch #63: Average loss is 0.006033852450549602\n",
      "Time taken for epoch: 4.689203262329102s\n",
      "\n",
      "Epoch #64: Batch 250/250 -- Loss = 0.00683262525126338; Time taken: 0.016385793685913086sss\n",
      "Epoch #64: Average loss is 0.006085927041247487\n",
      "Time taken for epoch: 4.712417840957642s\n",
      "\n",
      "Epoch #65: Batch 250/250 -- Loss = 0.006942284293472767; Time taken: 0.023973941802978516ss\n",
      "Epoch #65: Average loss is 0.006000087189488113\n",
      "Epoch #65: Train WER is 0.05741726259770497\n",
      "Epoch #65: Validation WER is 0.13466711499663753\n",
      "Time taken for epoch: 7.371326208114624s\n",
      "\n",
      "Epoch #66: Batch 250/250 -- Loss = 0.004141983110457659; Time taken: 0.019127607345581055ss\n",
      "Epoch #66: Average loss is 0.0053576406924985345\n",
      "Time taken for epoch: 4.67158842086792s\n",
      "\n",
      "Epoch #67: Batch 250/250 -- Loss = 0.008930536918342113; Time taken: 0.019494295120239258ss\n",
      "Epoch #67: Average loss is 0.005449493526481092\n",
      "Time taken for epoch: 4.696456670761108s\n",
      "\n",
      "Epoch #68: Batch 250/250 -- Loss = 0.005828943569213152; Time taken: 0.01598381996154785sss\n",
      "Epoch #68: Average loss is 0.004927846491336822\n",
      "Time taken for epoch: 4.69646954536438s\n",
      "\n",
      "Epoch #69: Batch 250/250 -- Loss = 0.008966943249106407; Time taken: 0.021701574325561523ss\n",
      "Epoch #69: Average loss is 0.004140954388771206\n",
      "Time taken for epoch: 4.658061265945435s\n",
      "\n",
      "Epoch #70: Batch 250/250 -- Loss = 0.00608831224963069; Time taken: 0.015710830688476562s2s\n",
      "Epoch #70: Average loss is 0.005365183140616864\n",
      "Epoch #70: Train WER is 0.04536005321802761\n",
      "Epoch #70: Validation WER is 0.12340282447881641\n",
      "Time taken for epoch: 7.394362211227417s\n",
      "\n",
      "Epoch #71: Batch 250/250 -- Loss = 0.008902194909751415; Time taken: 0.014893770217895508ss\n",
      "Epoch #71: Average loss is 0.005006094845943153\n",
      "Time taken for epoch: 4.699279308319092s\n",
      "\n",
      "Epoch #72: Batch 250/250 -- Loss = 0.0032331536058336496; Time taken: 0.017793893814086914s\n",
      "Epoch #72: Average loss is 0.004414944875519722\n",
      "Time taken for epoch: 4.690526247024536s\n",
      "\n",
      "Epoch #73: Batch 250/250 -- Loss = 0.0019968198612332344; Time taken: 0.01758265495300293ss\n",
      "Epoch #73: Average loss is 0.003428350139874965\n",
      "Time taken for epoch: 4.735547780990601s\n",
      "\n",
      "Epoch #74: Batch 250/250 -- Loss = 0.001294420682825148; Time taken: 0.015525579452514648ss\n",
      "Epoch #74: Average loss is 0.0031103320319671186\n",
      "Time taken for epoch: 4.70339035987854s\n",
      "\n",
      "Epoch #75: Batch 250/250 -- Loss = 0.0016990542644634843; Time taken: 0.017159461975097656s\n",
      "Epoch #75: Average loss is 0.0031627502110786734\n",
      "Epoch #75: Train WER is 0.02814734741393647\n",
      "Epoch #75: Validation WER is 0.09246805648957633\n",
      "Time taken for epoch: 7.390232563018799s\n",
      "\n",
      "Epoch #76: Batch 250/250 -- Loss = 0.003629728453233838; Time taken: 0.017183303833007812ss\n",
      "Epoch #76: Average loss is 0.003188840014627203\n",
      "Time taken for epoch: 4.727383613586426s\n",
      "\n",
      "Epoch #77: Batch 250/250 -- Loss = 0.0014086465816944838; Time taken: 0.017400026321411133s\n",
      "Epoch #77: Average loss is 0.0035445280703715982\n",
      "Time taken for epoch: 4.632593393325806s\n",
      "\n",
      "Epoch #78: Batch 250/250 -- Loss = 0.0014613165985792875; Time taken: 0.016652822494506836s\n",
      "Epoch #78: Average loss is 0.0030400256409775467\n",
      "Time taken for epoch: 4.678934097290039s\n",
      "\n",
      "Epoch #79: Batch 250/250 -- Loss = 0.0013186358846724033; Time taken: 0.018298625946044922s\n",
      "Epoch #79: Average loss is 0.002373499696725048\n",
      "Time taken for epoch: 4.71814489364624s\n",
      "\n",
      "Epoch #80: Batch 250/250 -- Loss = 0.004142661113291979; Time taken: 0.022234678268432617ss\n",
      "Epoch #80: Average loss is 0.0027498878005426377\n",
      "Epoch #80: Train WER is 0.06855978712788957\n",
      "Epoch #80: Validation WER is 0.1274377942165434\n",
      "Time taken for epoch: 7.377894878387451s\n",
      "\n",
      "Epoch #81: Batch 250/250 -- Loss = 0.0021642360370606184; Time taken: 0.014499902725219727s\n",
      "Epoch #81: Average loss is 0.006042375419288874\n",
      "Time taken for epoch: 4.624217748641968s\n",
      "\n",
      "Epoch #82: Batch 250/250 -- Loss = 0.0017027925932779908; Time taken: 0.017105579376220703s\n",
      "Epoch #82: Average loss is 0.0020075755175203084\n",
      "Time taken for epoch: 4.690701246261597s\n",
      "\n",
      "Epoch #83: Batch 250/250 -- Loss = 0.0017211236990988255; Time taken: 0.021233797073364258s\n",
      "Epoch #83: Average loss is 0.0019548947382718325\n",
      "Time taken for epoch: 4.69848370552063s\n",
      "\n",
      "Epoch #84: Batch 250/250 -- Loss = 0.0011298117460682988; Time taken: 0.01624321937561035ss\n",
      "Epoch #84: Average loss is 0.0020662260770332066\n",
      "Time taken for epoch: 4.683763742446899s\n",
      "\n",
      "Epoch #85: Batch 250/250 -- Loss = 0.0024986404459923506; Time taken: 0.018304109573364258s\n",
      "Epoch #85: Average loss is 0.002135888879885897\n",
      "Epoch #85: Train WER is 0.009437884583402627\n",
      "Epoch #85: Validation WER is 0.07414256893073302\n",
      "Time taken for epoch: 7.409198045730591s\n",
      "\n",
      "Epoch #86: Batch 250/250 -- Loss = 0.005329927429556847; Time taken: 0.01661992073059082sss\n",
      "Epoch #86: Average loss is 0.002974234466557391\n",
      "Time taken for epoch: 4.70789909362793s\n",
      "\n",
      "Epoch #87: Batch 250/250 -- Loss = 0.0016220047837123275; Time taken: 0.015645265579223633s\n",
      "Epoch #87: Average loss is 0.0025107031872030347\n",
      "Time taken for epoch: 4.705812454223633s\n",
      "\n",
      "Epoch #88: Batch 250/250 -- Loss = 0.0035365403164178133; Time taken: 0.016718626022338867s\n",
      "Epoch #88: Average loss is 0.0049672251297160986\n",
      "Time taken for epoch: 4.681488513946533s\n",
      "\n",
      "Epoch #89: Batch 250/250 -- Loss = 0.0017985833110287786; Time taken: 0.01708674430847168ss\n",
      "Epoch #89: Average loss is 0.0023323783241212368\n",
      "Time taken for epoch: 4.699921131134033s\n",
      "\n",
      "Epoch #90: Batch 250/250 -- Loss = 0.000431916763773188; Time taken: 0.016219139099121094sss\n",
      "Epoch #90: Average loss is 0.0009747826455859468\n",
      "Epoch #90: Train WER is 0.0017877931149176784\n",
      "Epoch #90: Validation WER is 0.055648957632817755\n",
      "Time taken for epoch: 7.404552221298218s\n",
      "\n",
      "Epoch #91: Batch 250/250 -- Loss = 0.0006196034955792129; Time taken: 0.020711898803710938ss\n",
      "Epoch #91: Average loss is 0.000676228464290034\n",
      "Time taken for epoch: 4.690547466278076s\n",
      "\n",
      "Epoch #92: Batch 250/250 -- Loss = 0.0009752843761816621; Time taken: 0.01646137237548828ss\n",
      "Epoch #92: Average loss is 0.0015875333060976118\n",
      "Time taken for epoch: 4.693690776824951s\n",
      "\n",
      "Epoch #93: Batch 250/250 -- Loss = 0.0017077423399314284; Time taken: 0.01635432243347168sss\n",
      "Epoch #93: Average loss is 0.002370105091831647\n",
      "Time taken for epoch: 4.678092002868652s\n",
      "\n",
      "Epoch #94: Batch 250/250 -- Loss = 0.001991349970921874; Time taken: 0.022898197174072266ss\n",
      "Epoch #94: Average loss is 0.002569644113420509\n",
      "Time taken for epoch: 4.696457147598267s\n",
      "\n",
      "Epoch #95: Batch 250/250 -- Loss = 0.0017189845675602555; Time taken: 0.017485380172729492ss\n",
      "Epoch #95: Average loss is 0.0014571751637849958\n",
      "Epoch #95: Train WER is 0.00864792948611342\n",
      "Epoch #95: Validation WER is 0.06943510423671823\n",
      "Time taken for epoch: 7.394678831100464s\n",
      "\n",
      "Epoch #96: Batch 250/250 -- Loss = 0.0026802178472280502; Time taken: 0.017224788665771484ss\n",
      "Epoch #96: Average loss is 0.0015757222939282655\n",
      "Time taken for epoch: 4.7028398513793945s\n",
      "\n",
      "Epoch #97: Batch 250/250 -- Loss = 0.0037188560236245394; Time taken: 0.016373634338378906ss\n",
      "Epoch #97: Average loss is 0.002349118712125346\n",
      "Time taken for epoch: 4.737096071243286s\n",
      "\n",
      "Epoch #98: Batch 250/250 -- Loss = 0.000623654224909842; Time taken: 0.016901016235351562sss\n",
      "Epoch #98: Average loss is 0.0011198704735143111\n",
      "Time taken for epoch: 4.659845352172852s\n",
      "\n",
      "Epoch #99: Batch 250/250 -- Loss = 0.001531840767711401; Time taken: 0.01604175567626953s7s\n",
      "Epoch #99: Average loss is 0.002041168914292939\n",
      "Time taken for epoch: 4.682896852493286s\n",
      "\n",
      "Epoch #100: Batch 250/250 -- Loss = 0.0008896656800061464; Time taken: 0.019722938537597656ss\n",
      "Epoch #100: Average loss is 0.0016628439208725468\n",
      "Epoch #100: Train WER is 0.010768335273573923\n",
      "Epoch #100: Validation WER is 0.07498318762609281\n",
      "Time taken for epoch: 7.392727613449097s\n",
      "\n",
      "Epoch #101: Batch 250/250 -- Loss = 0.0031385228503495455; Time taken: 0.02055954933166504ss\n",
      "Epoch #101: Average loss is 0.0019152786909835413\n",
      "Time taken for epoch: 4.682741641998291s\n",
      "\n",
      "Epoch #102: Batch 250/250 -- Loss = 0.005057089496403933; Time taken: 0.01660013198852539s2s\n",
      "Epoch #102: Average loss is 0.002625643505190965\n",
      "Time taken for epoch: 4.691392183303833s\n",
      "\n",
      "Epoch #103: Batch 250/250 -- Loss = 0.002659640507772565; Time taken: 0.016717195510864258ss\n",
      "Epoch #103: Average loss is 0.0021988973955158145\n",
      "Time taken for epoch: 4.684382438659668s\n",
      "\n",
      "Epoch #104: Batch 250/250 -- Loss = 0.0021187940146774054; Time taken: 0.015750646591186523ss\n",
      "Epoch #104: Average loss is 0.0013968892838456667\n",
      "Time taken for epoch: 4.677200078964233s\n",
      "\n",
      "Epoch #105: Batch 250/250 -- Loss = 0.00037793611409142613; Time taken: 0.018246173858642578s\n",
      "Epoch #105: Average loss is 0.0005066268462105654\n",
      "Epoch #105: Train WER is 0.0014136038583070015\n",
      "Epoch #105: Validation WER is 0.056657700067249496\n",
      "Time taken for epoch: 7.410996198654175s\n",
      "\n",
      "Epoch #106: Batch 250/250 -- Loss = 0.0012425165623426437; Time taken: 0.017487049102783203ss\n",
      "Epoch #106: Average loss is 0.0005536958038574085\n",
      "Time taken for epoch: 4.7426042556762695s\n",
      "\n",
      "Epoch #107: Batch 250/250 -- Loss = 0.00023934143246151507; Time taken: 0.018377065658569336s\n",
      "Epoch #107: Average loss is 0.000360971587972017\n",
      "Time taken for epoch: 4.684092283248901s\n",
      "\n",
      "Epoch #108: Batch 250/250 -- Loss = 0.00013075937749817967; Time taken: 0.01954817771911621ss\n",
      "Epoch #108: Average loss is 0.00016272057106834836\n",
      "Time taken for epoch: 4.649786949157715s\n",
      "\n",
      "Epoch #109: Batch 250/250 -- Loss = 0.0001326989004155621; Time taken: 0.017766237258911133ss\n",
      "Epoch #109: Average loss is 0.00010658179651363753\n",
      "Time taken for epoch: 4.6811206340789795s\n",
      "\n",
      "Epoch #110: Batch 250/250 -- Loss = 8.278780296677724e-05; Time taken: 0.016882658004760742ss\n",
      "Epoch #110: Average loss is 9.919902047840879e-05\n",
      "Epoch #110: Train WER is 4.1576584067852984e-05\n",
      "Epoch #110: Validation WER is 0.0554808338937458\n",
      "Time taken for epoch: 7.556420803070068s\n",
      "\n",
      "Epoch #111: Batch 250/250 -- Loss = 8.341127977473661e-05; Time taken: 0.01761317253112793sss\n",
      "Epoch #111: Average loss is 7.308477234619204e-05\n",
      "Time taken for epoch: 4.725731134414673s\n",
      "\n",
      "Epoch #112: Batch 250/250 -- Loss = 6.607479735976085e-05; Time taken: 0.017813920974731445ss\n",
      "Epoch #112: Average loss is 5.928711537853815e-05\n",
      "Time taken for epoch: 4.735212087631226s\n",
      "\n",
      "Epoch #113: Batch 250/250 -- Loss = 2.9028817152720876e-05; Time taken: 0.01717662811279297ss\n",
      "Epoch #113: Average loss is 5.049465118645457e-05\n",
      "Time taken for epoch: 4.664263725280762s\n",
      "\n",
      "Epoch #114: Batch 250/250 -- Loss = 2.8527256290544756e-05; Time taken: 0.01759481430053711ss\n",
      "Epoch #114: Average loss is 4.378435751277721e-05\n",
      "Time taken for epoch: 4.701355695724487s\n",
      "\n",
      "Epoch #115: Batch 250/250 -- Loss = 3.104589268332347e-05; Time taken: 0.01478433609008789sss\n",
      "Epoch #115: Average loss is 3.851396188838408e-05\n",
      "Epoch #115: Train WER is 0.0\n",
      "Epoch #115: Validation WER is 0.055648957632817755\n",
      "Time taken for epoch: 7.435014486312866s\n",
      "\n",
      "Epoch #116: Batch 250/250 -- Loss = 3.55771990143694e-05; Time taken: 0.017879486083984375sss\n",
      "Epoch #116: Average loss is 3.387109469622374e-05\n",
      "Time taken for epoch: 4.69854211807251s\n",
      "\n",
      "Epoch #117: Batch 250/250 -- Loss = 2.76765367743792e-05; Time taken: 0.014154911041259766sss\n",
      "Epoch #117: Average loss is 2.990428088378394e-05\n",
      "Time taken for epoch: 4.641274690628052s\n",
      "\n",
      "Epoch #118: Batch 250/250 -- Loss = 2.148713610949926e-05; Time taken: 0.017804861068725586ss\n",
      "Epoch #118: Average loss is 2.6367491595010505e-05\n",
      "Time taken for epoch: 4.67802619934082s\n",
      "\n",
      "Epoch #119: Batch 250/250 -- Loss = 1.84110613190569e-05; Time taken: 0.019452810287475586s6s\n",
      "Epoch #119: Average loss is 2.336711162206484e-05\n",
      "Time taken for epoch: 4.695130348205566s\n",
      "\n",
      "Epoch #120: Batch 250/250 -- Loss = 2.1212479623500258e-05; Time taken: 0.02119159698486328ss\n",
      "Epoch #120: Average loss is 2.0578504980221625e-05\n",
      "Epoch #120: Train WER is 0.0\n",
      "Epoch #120: Validation WER is 0.05648957632817754\n",
      "Time taken for epoch: 7.588760614395142s\n",
      "\n",
      "Epoch #121: Batch 250/250 -- Loss = 1.8619000911712646e-05; Time taken: 0.01706528663635254ss\n",
      "Epoch #121: Average loss is 1.817506078441511e-05\n",
      "Time taken for epoch: 4.770781517028809s\n",
      "\n",
      "Epoch #122: Batch 250/250 -- Loss = 1.5826050002942793e-05; Time taken: 0.017405986785888672s\n",
      "Epoch #122: Average loss is 1.6057419512435443e-05\n",
      "Time taken for epoch: 4.73136568069458s\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #123: Batch 250/250 -- Loss = 1.1179934517713264e-05; Time taken: 0.017221450805664062s\n",
      "Epoch #123: Average loss is 1.4125271911325398e-05\n",
      "Time taken for epoch: 4.684989929199219s\n",
      "\n",
      "Epoch #124: Batch 250/250 -- Loss = 1.1494214049889706e-05; Time taken: 0.020652294158935547s\n",
      "Epoch #124: Average loss is 1.2492074200054048e-05\n",
      "Time taken for epoch: 4.671291351318359s\n",
      "\n",
      "Epoch #125: Batch 250/250 -- Loss = 1.1783431546064094e-05; Time taken: 0.017317533493041992s\n",
      "Epoch #125: Average loss is 1.104395704351191e-05\n",
      "Epoch #125: Train WER is 0.0\n",
      "Epoch #125: Validation WER is 0.057330195023537325\n",
      "Time taken for epoch: 7.377926349639893s\n",
      "\n",
      "Epoch #126: Batch 250/250 -- Loss = 0.019311176612973213; Time taken: 0.019614219665527344ss\n",
      "Epoch #126: Average loss is 0.02927981736019683\n",
      "Time taken for epoch: 4.668739318847656s\n",
      "\n",
      "Epoch #127: Batch 250/250 -- Loss = 0.015942083671689034; Time taken: 0.016927242279052734ss\n",
      "Epoch #127: Average loss is 0.01685916627384722\n",
      "Time taken for epoch: 4.643506050109863s\n",
      "\n",
      "Epoch #128: Batch 250/250 -- Loss = 0.011363926343619823; Time taken: 0.01714777946472168sss\n",
      "Epoch #128: Average loss is 0.008531210645101964\n",
      "Time taken for epoch: 4.669201850891113s\n",
      "\n",
      "Epoch #129: Batch 250/250 -- Loss = 0.003008140018209815; Time taken: 0.01536870002746582sss\n",
      "Epoch #129: Average loss is 0.004409983287099749\n",
      "Time taken for epoch: 4.705418825149536s\n",
      "\n",
      "Epoch #130: Batch 250/250 -- Loss = 0.0011031440226361156; Time taken: 0.024074077606201172s\n",
      "Epoch #130: Average loss is 0.002267455211491324\n",
      "Epoch #130: Train WER is 0.009105271910859804\n",
      "Epoch #130: Validation WER is 0.06926698049764626\n",
      "Time taken for epoch: 7.388461589813232s\n",
      "\n",
      "Epoch #131: Batch 250/250 -- Loss = 0.0004048535483889282; Time taken: 0.020826339721679688ss\n",
      "Epoch #131: Average loss is 0.0012182119151111692\n",
      "Time taken for epoch: 4.7096991539001465s\n",
      "\n",
      "Epoch #132: Batch 250/250 -- Loss = 0.0010620064567774534; Time taken: 0.017496585845947266ss\n",
      "Epoch #132: Average loss is 0.0010141500273603014\n",
      "Time taken for epoch: 4.667950630187988s\n",
      "\n",
      "Epoch #133: Batch 250/250 -- Loss = 0.0016618747031316161; Time taken: 0.01773524284362793ss\n",
      "Epoch #133: Average loss is 0.0015047766746138223\n",
      "Time taken for epoch: 4.688266754150391s\n",
      "\n",
      "Epoch #134: Batch 250/250 -- Loss = 0.0073417071253061295; Time taken: 0.01902294158935547sss\n",
      "Epoch #134: Average loss is 0.001936147495638579\n",
      "Time taken for epoch: 4.629815101623535s\n",
      "\n",
      "Epoch #135: Batch 250/250 -- Loss = 0.0007226475863717496; Time taken: 0.01778864860534668sss\n",
      "Epoch #135: Average loss is 0.002341042200685479\n",
      "Epoch #135: Train WER is 0.005072343256278064\n",
      "Epoch #135: Validation WER is 0.060692669804976465\n",
      "Time taken for epoch: 7.461061954498291s\n",
      "\n",
      "Epoch #136: Batch 250/250 -- Loss = 0.0006613250588998199; Time taken: 0.01774883270263672sss\n",
      "Epoch #136: Average loss is 0.0007692957463441417\n",
      "Time taken for epoch: 4.747140407562256s\n",
      "\n",
      "Epoch #137: Batch 250/250 -- Loss = 0.00033313644235022366; Time taken: 0.01669788360595703ss\n",
      "Epoch #137: Average loss is 0.0003904687770991586\n",
      "Time taken for epoch: 4.66412353515625s\n",
      "\n",
      "Epoch #138: Batch 250/250 -- Loss = 0.0001605886354809627; Time taken: 0.019475936889648438ss\n",
      "Epoch #138: Average loss is 0.00018580278556328266\n",
      "Time taken for epoch: 4.716570854187012s\n",
      "\n",
      "Epoch #139: Batch 250/250 -- Loss = 0.002152716973796487; Time taken: 0.02061605453491211ssss\n",
      "Epoch #139: Average loss is 0.0020209880641050403\n",
      "Time taken for epoch: 4.70570182800293s\n",
      "\n",
      "Epoch #140: Batch 250/250 -- Loss = 0.0012765020364895463; Time taken: 0.02103137969970703sss\n",
      "Epoch #140: Average loss is 0.002928208972327411\n",
      "Epoch #140: Train WER is 0.011100947946116747\n",
      "Epoch #140: Validation WER is 0.0687626092804304\n",
      "Time taken for epoch: 7.3494484424591064s\n",
      "\n",
      "Epoch #141: Batch 250/250 -- Loss = 0.0006199831259436905; Time taken: 0.017033100128173828ss\n",
      "Epoch #141: Average loss is 0.0008462022733292542\n",
      "Time taken for epoch: 4.719223499298096s\n",
      "\n",
      "Epoch #142: Batch 250/250 -- Loss = 0.00024393895000685006; Time taken: 0.01436614990234375ss\n",
      "Epoch #142: Average loss is 0.0005357376566389575\n",
      "Time taken for epoch: 4.671511650085449s\n",
      "\n",
      "Epoch #143: Batch 250/250 -- Loss = 0.00013173744082450867; Time taken: 0.017528772354125977s\n",
      "Epoch #143: Average loss is 0.0003391069898207206\n",
      "Time taken for epoch: 4.701730251312256s\n",
      "\n",
      "Epoch #144: Batch 250/250 -- Loss = 0.00026228788192383945; Time taken: 0.017778635025024414s\n",
      "Epoch #144: Average loss is 0.0002424998552305624\n",
      "Time taken for epoch: 4.68785834312439s\n",
      "\n",
      "Epoch #145: Batch 250/250 -- Loss = 0.00021597133309114724; Time taken: 0.02006673812866211ss\n",
      "Epoch #145: Average loss is 0.0003553837569634197\n",
      "Epoch #145: Train WER is 0.0004989190088142358\n",
      "Epoch #145: Validation WER is 0.052958977807666445\n",
      "Time taken for epoch: 7.438324213027954s\n",
      "\n",
      "Epoch #146: Batch 250/250 -- Loss = 6.20138889644295e-05; Time taken: 0.01574563980102539s5ss\n",
      "Epoch #146: Average loss is 0.0001934914580633631\n",
      "Time taken for epoch: 4.6930091381073s\n",
      "\n",
      "Epoch #147: Batch 250/250 -- Loss = 0.004278946202248335; Time taken: 0.016409635543823242ss\n",
      "Epoch #147: Average loss is 0.004398226490360685\n",
      "Time taken for epoch: 4.697342395782471s\n",
      "\n",
      "Epoch #148: Batch 250/250 -- Loss = 0.0011193316895514727; Time taken: 0.016804933547973633ss\n",
      "Epoch #148: Average loss is 0.002194873910979368\n",
      "Time taken for epoch: 4.804481267929077s\n",
      "\n",
      "Epoch #149: Batch 250/250 -- Loss = 0.0006272511673159897; Time taken: 0.014883041381835938ss\n",
      "Epoch #149: Average loss is 0.0019312255126424133\n",
      "Time taken for epoch: 4.596937894821167s\n",
      "\n",
      "Epoch #150: Batch 250/250 -- Loss = 0.00016380203305743635; Time taken: 0.015857219696044922s\n",
      "Epoch #150: Average loss is 0.00043916441354667767\n",
      "Epoch #150: Train WER is 0.0002494595044071179\n",
      "Epoch #150: Validation WER is 0.05211835911230666\n",
      "Time taken for epoch: 7.405117750167847s\n",
      "\n",
      "Training completed in 801.7726521492004s\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pytorch, pytorch_stats = task_pytorch.train(epochs=150, train_loader=train_loader, valid_loader=valid_loader, \n",
    "                                            out_dir='dump/Seq2SeqSame/PyTorch/', freq=5, vocab=babi.vocab, \n",
    "                                            wer_dict=babi.wer_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix: \n",
      " [[317  21  31  21  54  17]\n",
      " [ 21 292  26  37  19  46]\n",
      " [ 48  35 419  30  33  42]\n",
      " [ 61  41  40 320  35  30]\n",
      " [ 41  28  42  37 311  38]\n",
      " [ 44  17  38  51  27 290]]\n",
      "\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           7       0.60      0.69      0.64       461\n",
      "          10       0.67      0.66      0.67       441\n",
      "          16       0.70      0.69      0.70       607\n",
      "          17       0.65      0.61      0.63       527\n",
      "          20       0.65      0.63      0.64       497\n",
      "          21       0.63      0.62      0.62       467\n",
      "\n",
      "   micro avg       0.65      0.65      0.65      3000\n",
      "   macro avg       0.65      0.65      0.65      3000\n",
      "weighted avg       0.65      0.65      0.65      3000\n",
      "\n",
      "0.35033333333333333\n"
     ]
    }
   ],
   "source": [
    "pytorch_wer, _ = task_pytorch.evaluate(test_loader, babi.vocab, babi.wer_dict, verbose=True)\n",
    "print(pytorch_wer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TRANSFORMER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
