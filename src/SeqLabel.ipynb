{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"SeqLabel.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":["ZS-zwgyIL_Gq"],"toc_visible":true},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.7"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"qR7QKPdWL_GU","colab_type":"text"},"source":["# Benchmarking LSTMs\n","\n","This notebook contains experiments on 3 different sequence tasks:\n","* __Sequence Labelling__\n","    * A many-to-one, _Sentiment Analysis_ task on the IMDb dataset available with _torchtext_.\n","* __Sequence to Sequence - Same__\n","    * A many-to-many-same, _Predict missing word_ task on the Facebook bAbi dataset.\n","* __Sequence to Sequence - Different__\n","    * A many-to-one-different, _NTM toy_ task.\n","    \n","For each of the tasks, we will run our implementation of vanilla LSTM. <br>"]},{"cell_type":"markdown","metadata":{"id":"FDO3QS-dL_GV","colab_type":"text"},"source":["### Loading dependencies"]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2019-07-10T23:18:33.946357Z","start_time":"2019-07-10T23:18:32.653217Z"},"id":"CnagSCLwL_GW","colab_type":"code","colab":{}},"source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torchtext.datasets import IMDB\n","from torchtext import data\n","from torchtext.vocab import GloVe\n","\n","import os\n","import json\n","import time\n","import random\n","import copy\n","import numpy as np\n","from matplotlib import pyplot as plt\n","from sklearn.metrics import confusion_matrix, f1_score, classification_report\n","\n","from IPython.display import Image\n","\n","from seq_label import SeqLabel\n","\n","\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","# device = torch.device('cpu')\n","\n","SEED = 1\n","random.seed(SEED)\n","torch.manual_seed(SEED)\n","torch.backends.cudnn.deterministic = True\n","torch.backends.cudnn.benchmark = False"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"uVvnTF5CL_Ga","colab_type":"text"},"source":["# Task 1: Sequence Labelling\n","\n","All code pertaining to this task will have a pre-/post-fix **SeqLabel**."]},{"cell_type":"markdown","metadata":{"id":"lx5yCF9_L_Gb","colab_type":"text"},"source":["### Common Parameters"]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2019-07-10T23:18:34.867719Z","start_time":"2019-07-10T23:18:34.864536Z"},"id":"Ro6cpqmfL_Gc","colab_type":"code","colab":{}},"source":["batch_size = 16\n","# Percentage of training data\n","split_ratio = 0.8\n","learning_rate = 0.001\n","epochs = 200\n","# vocabulary size to embed input (GloVe output dim)\n","embed_dim = 300"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Ao9hPoXuL_Gf","colab_type":"text"},"source":["### Loading and preparing IMDb data"]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2019-07-10T23:18:39.350227Z","start_time":"2019-07-10T23:18:36.294738Z"},"id":"Bfq-_Vn_L_Gh","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":71},"outputId":"dc80064a-3a03-4a97-a719-089b050c9f3a","executionInfo":{"status":"ok","timestamp":1563434551831,"user_tz":-120,"elapsed":101934,"user":{"displayName":"Ashwin Raaghav","photoUrl":"https://lh5.googleusercontent.com/-uO-vZ_lY6nI/AAAAAAAAAAI/AAAAAAAAGoc/e5zeb5jD1vE/s64/photo.jpg","userId":"02512740178384625797"}}},"source":["from imdb import IMDB_dataset\n","\n","imdb = IMDB_dataset(split_ratio, SEED)\n","imdb.load(verbose = True)\n","imdb.build_vocab(embed_dim)\n","train_loader, valid_loader, test_loader = imdb.create_data_loader(batch_size, \n","                                                                  device)\n","vocab_len = len(imdb.TEXT.vocab)"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Training data size:    20000\n","Validation data size:  5000\n","Test data size:        25000\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"ZS-zwgyIL_Gq","colab_type":"text"},"source":["# LSTM"]},{"cell_type":"markdown","metadata":{"id":"5J9JIEiEL_Gt","colab_type":"text"},"source":["#### LSTM Parameters"]},{"cell_type":"code","metadata":{"id":"bEyy-XbWL_Gu","colab_type":"code","colab":{}},"source":["# Number of hidden nodes\n","hidden_dim = 256\n","# Number of output nodes\n","output_dim = 1\n","# Number of LSTMs cells to be stacked\n","layers = 1\n","# Boolean value for bidirectioanl or not\n","bidirectional = False\n","# Boolean value to use LayerNorm or not\n","layernorm = False"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"wwyIk6aEwmBw","colab_type":"text"},"source":["### Our implementation"]},{"cell_type":"code","metadata":{"id":"4djeHhqPL_Gx","colab_type":"code","colab":{}},"source":["# Our implementation\n","\n","from seq_label import LSTMSeqLabel\n","\n","# Initializing model\n","model = LSTMSeqLabel(vocab_len, embed_dim, hidden_dim, output_dim, \n","                      imdb.pretrained_weights, layers, bidirectional,\n","                      layernorm)\n","model.to(device)\n","\n","print('Model parameters: ', model.count_parameters())\n","\n","# Initializing optimizer and loss\n","optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n","loss_criterion = nn.BCEWithLogitsLoss()\n","\n","# Initializing task\n","task = SeqLabel(model, optimizer, loss_criterion, device)\n","\n","# Training\n","freq = 5    # epoch interval to calculate F1 score and save models\n","out_dir = \"results/seq_label/\"\n","# out_dir = \"/content/drive/My Drive/colab/seq_label/\"\n","model, stats = task.train(epochs, train_loader, valid_loader, freq, out_dir)\n","\n","print(\"=\" * 50)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"qQx20X6WL_G6","colab_type":"code","colab":{}},"source":["# Testing\n","f1_test = task.evaluate(test_loader, verbose=True)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"50ZCNQzcL_G9","colab_type":"text"},"source":["### PyTorch implementation"]},{"cell_type":"code","metadata":{"id":"rievXl2kL_G-","colab_type":"code","outputId":"37207bd7-7011-4120-dcd2-100b32ec1bdf","executionInfo":{"status":"error","timestamp":1562829252477,"user_tz":-120,"elapsed":484554,"user":{"displayName":"Ashwin Raaghav","photoUrl":"https://lh5.googleusercontent.com/-uO-vZ_lY6nI/AAAAAAAAAAI/AAAAAAAAGoc/e5zeb5jD1vE/s64/photo.jpg","userId":"02512740178384625797"}},"colab":{"base_uri":"https://localhost:8080/","height":880}},"source":["# PyTorch implementation\n","\n","from seq_label import PyTorchBaseline\n","\n","# Initializing model\n","model = PyTorchBaseline(vocab_len, embed_dim, hidden_dim, output_dim, \n","                       imdb.pretrained_weights, layers, bidirectional)\n","model.to(device)\n","\n","print('Model parameters: ', model.count_parameters())\n","\n","# Initializing optimizer and loss\n","optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n","loss_criterion = nn.BCEWithLogitsLoss()\n","\n","# Initializing task\n","task = SeqLabel(model, optimizer, loss_criterion, device)\n","\n","# Training\n","freq = 5    # epoch interval to calculate F1 score and save models\n","out_dir = \"results/seq_label/pytorch/\"\n","# out_dir = \"/content/drive/My Drive/colab/seq_label/\"\n","model, stats = task.train(epochs, train_loader, valid_loader, freq, out_dir)\n","\n","print(\"=\" * 50)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Model parameters:  571649\n","Beginning training model with 571649 parameters\n","\n","Epoch #1: Batch 2500/2500 -- Loss = 0.6400628089904785; Time taken: 0.016690731048583984s\n","Epoch #1: Average loss is 0.688916947054863\n","Epoch #1: Train F1-score is 0.11512942715634053\n","Epoch #1: Validation F1-score is 0.5475675675675676\n","Time taken for epoch: 117.011958360672s\n","\n","Epoch #2: Batch 2500/2500 -- Loss = 0.3095054626464844; Time taken: 0.016431331634521484s\n","Epoch #2: Average loss is 0.6341397064268589\n","Time taken for epoch: 77.60263323783875s\n","\n","Epoch #3: Batch 2500/2500 -- Loss = 0.12923932075500488; Time taken: 0.02263617515563965s\n","Epoch #3: Average loss is 0.359573724719882\n","Time taken for epoch: 76.62852096557617s\n","\n","Epoch #4: Batch 2500/2500 -- Loss = 0.09730026125907898; Time taken: 0.02712535858154297s\n","Epoch #4: Average loss is 0.30158056974858044\n","Time taken for epoch: 77.24223208427429s\n","\n","Epoch #5: Batch 2500/2500 -- Loss = 0.39330965280532837; Time taken: 0.013465404510498047s\n","Epoch #5: Average loss is 0.27174832921028136\n","Epoch #5: Train F1-score is 0.9126972494992427\n","Epoch #5: Validation F1-score is 0.8834782608695653\n","Time taken for epoch: 119.35506844520569s\n","\n"],"name":"stdout"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-10-23fb55ebe5a9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0mout_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"results/seq_label/pytorch/\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;31m# out_dir = \"/content/drive/My Drive/colab/seq_label/\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstats\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfreq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"=\"\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-6-1370c6fdab8d>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, epochs, train_loader, valid_loader, freq, out_dir)\u001b[0m\n\u001b[1;32m    122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m                 \u001b[0;31m# forward pass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 124\u001b[0;31m                 \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    125\u001b[0m                 \u001b[0;31m# backward pass for the batch (+ weight updates)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-6-1370c6fdab8d>\u001b[0m in \u001b[0;36mlstm_forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     73\u001b[0m                                      self.model.hidden_dim).to(self.device)\n\u001b[1;32m     74\u001b[0m         \u001b[0;31m# forward pass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/seq_label.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, h, c)\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m         \u001b[0membed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 112\u001b[0;31m         \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    113\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    557\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward_packed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    558\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 559\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    560\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    561\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward_tensor\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    537\u001b[0m         \u001b[0munsorted_indices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    538\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 539\u001b[0;31m         \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_batch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msorted_indices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    540\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    541\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute_hidden\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munsorted_indices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward_impl\u001b[0;34m(self, input, hx, batch_sizes, max_batch_size, sorted_indices)\u001b[0m\n\u001b[1;32m    520\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbatch_sizes\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    521\u001b[0m             result = _VF.lstm(input, hx, self._get_flat_weights(), self.bias, self.num_layers,\n\u001b[0;32m--> 522\u001b[0;31m                               self.dropout, self.training, self.bidirectional, self.batch_first)\n\u001b[0m\u001b[1;32m    523\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    524\u001b[0m             result = _VF.lstm(input, batch_sizes, hx, self._get_flat_weights(), self.bias,\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","metadata":{"id":"IyqLuiP1wg4U","colab_type":"code","colab":{}},"source":["# Testing\n","f1_test = task.evaluate(test_loader, verbose=True)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"AoZdxErgPgBh","colab_type":"text"},"source":["# Transformer"]},{"cell_type":"markdown","metadata":{"id":"hNxaidYkQOz8","colab_type":"text"},"source":["### our implementation"]},{"cell_type":"code","metadata":{"id":"rf1izpUftLMy","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"outputId":"e1098017-2d76-49ed-9f1a-dd2b6cd32f36","executionInfo":{"status":"ok","timestamp":1563434555891,"user_tz":-120,"elapsed":52673,"user":{"displayName":"Ashwin Raaghav","photoUrl":"https://lh5.googleusercontent.com/-uO-vZ_lY6nI/AAAAAAAAAAI/AAAAAAAAGoc/e5zeb5jD1vE/s64/photo.jpg","userId":"02512740178384625797"}}},"source":["from seq_label import TransformerSeqLabel\n","from transformer import NoamOpt\n","\n","# 117k\n","model = TransformerSeqLabel(in_dim=vocab_len, out_dim=1, N=1, heads=4, embed_dim=embed_dim, model_dim=128, ff_dim=256, \n","                            key_dim=32, value_dim=32, batch_first=False,\n","                            pretrained_vec=imdb.pretrained_weights)\n","\n","model = model.to(device)\n","\n","print('Model parameters: ', model.count_parameters())"],"execution_count":4,"outputs":[{"output_type":"stream","text":["Model parameters:  171137\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"FlI0d22SQBIT","colab_type":"code","outputId":"89b50cfc-9be2-468c-9db4-7a14cf84c5f8","executionInfo":{"status":"error","timestamp":1563440775647,"user_tz":-120,"elapsed":6110156,"user":{"displayName":"Ashwin Raaghav","photoUrl":"https://lh5.googleusercontent.com/-uO-vZ_lY6nI/AAAAAAAAAAI/AAAAAAAAGoc/e5zeb5jD1vE/s64/photo.jpg","userId":"02512740178384625797"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["# Initializing optimizer and loss\n","# optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n","optimizer = NoamOpt(model.model_dim, 1, 2000,\n","        torch.optim.Adam(model.parameters(), lr=0, betas=(0.9, 0.98), eps=1e-9))\n","loss_criterion = nn.BCEWithLogitsLoss()\n","\n","# Initializing task\n","task = SeqLabel(model, optimizer, loss_criterion, device)\n","\n","# Training\n","freq = 5    # epoch interval to calculate F1 score and save models\n","out_dir = \"results/seqLabel/transformer/\"\n","model, stats = task.train(150, train_loader, valid_loader, freq, out_dir)\n","\n","print(\"=\" * 50)\n","\n","# Testing\n","f1_test = task.evaluate(test_loader, verbose=True)"],"execution_count":6,"outputs":[{"output_type":"stream","text":["Beginning training model with 171137 parameters\n","\n","\n","Epoch #1: Average loss is 0.47241753222346305\n","Epoch #1: Train F1 is 0.8475949367088608\n","Epoch #1: Validation F1 is 0.8491663435440092\n","Time taken for epoch: 77.926922082901s\n","\n","\n","Epoch #2: Average loss is 0.3745592767238617\n","Time taken for epoch: 52.81982731819153s\n","\n","\n","Epoch #3: Average loss is 0.33830806418061254\n","Time taken for epoch: 53.295148611068726s\n","\n","\n","Epoch #4: Average loss is 0.3065046506434679\n","Time taken for epoch: 54.342206716537476s\n","\n","\n","Epoch #5: Average loss is 0.28564162150919437\n","Epoch #5: Train F1 is 0.8827127940090708\n","Epoch #5: Validation F1 is 0.8563334682314853\n","Time taken for epoch: 76.9979019165039s\n","\n","\n","Epoch #6: Average loss is 0.2663201034232974\n","Time taken for epoch: 53.23896503448486s\n","\n","\n","Epoch #7: Average loss is 0.2516104934856296\n","Time taken for epoch: 53.220128774642944s\n","\n","\n","Epoch #8: Average loss is 0.23765434447824954\n","Time taken for epoch: 53.5066499710083s\n","\n","\n","Epoch #9: Average loss is 0.2253943543717265\n","Time taken for epoch: 53.697389364242554s\n","\n","\n","Epoch #10: Average loss is 0.21223808723837137\n","Epoch #10: Train F1 is 0.9248309178743962\n","Epoch #10: Validation F1 is 0.8624308338103416\n","Time taken for epoch: 78.20217776298523s\n","\n","\n","Epoch #11: Average loss is 0.2026348753619939\n","Time taken for epoch: 53.51780581474304s\n","\n","\n","Epoch #12: Average loss is 0.19316560855209827\n","Time taken for epoch: 53.84292244911194s\n","\n","\n","Epoch #13: Average loss is 0.18057769728451967\n","Time taken for epoch: 53.35486817359924s\n","\n","\n","Epoch #14: Average loss is 0.17224119079373776\n","Time taken for epoch: 53.08657383918762s\n","\n","\n","Epoch #15: Average loss is 0.1644634550716728\n","Epoch #15: Train F1 is 0.9492692173392527\n","Epoch #15: Validation F1 is 0.8593809705769966\n","Time taken for epoch: 77.80920314788818s\n","\n","\n","Epoch #16: Average loss is 0.15517100207321347\n","Time taken for epoch: 52.96273398399353s\n","\n","\n","Epoch #17: Average loss is 0.14759667546432464\n","Time taken for epoch: 53.43499755859375s\n","\n","\n","Epoch #18: Average loss is 0.14175945250913502\n","Time taken for epoch: 53.529664516448975s\n","\n","\n","Epoch #19: Average loss is 0.13465692444453015\n","Time taken for epoch: 53.87435603141785s\n","\n","\n","Epoch #20: Average loss is 0.1251843829434365\n","Epoch #20: Train F1 is 0.9628475189784323\n","Epoch #20: Validation F1 is 0.8539805825242718\n","Time taken for epoch: 78.37023663520813s\n","\n","\n","Epoch #21: Average loss is 0.12144348427839577\n","Time taken for epoch: 53.59635305404663s\n","\n","\n","Epoch #22: Average loss is 0.11453345116954297\n","Time taken for epoch: 53.48126983642578s\n","\n","\n","Epoch #23: Average loss is 0.11006583965928293\n","Time taken for epoch: 53.4348042011261s\n","\n","\n","Epoch #24: Average loss is 0.10321216355711221\n","Time taken for epoch: 53.22753691673279s\n","\n","\n","Epoch #25: Average loss is 0.10023101809103974\n","Epoch #25: Train F1 is 0.9678343134748146\n","Epoch #25: Validation F1 is 0.8487938811531672\n","Time taken for epoch: 77.80720853805542s\n","\n","\n","Epoch #26: Average loss is 0.09584170881547034\n","Time taken for epoch: 53.22996139526367s\n","\n","\n","Epoch #27: Average loss is 0.08976618209048175\n","Time taken for epoch: 53.85586214065552s\n","\n","\n","Epoch #28: Average loss is 0.08869505762568441\n","Time taken for epoch: 53.77509570121765s\n","\n","\n","Epoch #29: Average loss is 0.08289735036673955\n","Time taken for epoch: 53.9385883808136s\n","\n","\n","Epoch #30: Average loss is 0.07969902785305166\n","Epoch #30: Train F1 is 0.9752262275626762\n","Epoch #30: Validation F1 is 0.845356941043511\n","Time taken for epoch: 78.34468531608582s\n","\n","\n","Epoch #31: Average loss is 0.07686749536275166\n","Time taken for epoch: 53.13358688354492s\n","\n","\n","Epoch #32: Average loss is 0.07215175480289326\n","Time taken for epoch: 53.461689949035645s\n","\n","\n","Epoch #33: Average loss is 0.06848485794950974\n","Time taken for epoch: 53.01230502128601s\n","\n","\n","Epoch #34: Average loss is 0.06427017764490228\n","Time taken for epoch: 54.12820363044739s\n","\n","\n","Epoch #35: Average loss is 0.06730119478049747\n","Epoch #35: Train F1 is 0.9835087009307972\n","Epoch #35: Validation F1 is 0.8413039234823345\n","Time taken for epoch: 78.63146352767944s\n","\n","\n","Epoch #36: Average loss is 0.06307019457129208\n","Time taken for epoch: 53.74545359611511s\n","\n","\n","Epoch #37: Average loss is 0.05830542923137837\n","Time taken for epoch: 53.43738007545471s\n","\n","\n","Epoch #38: Average loss is 0.05625422761499649\n","Time taken for epoch: 53.48845171928406s\n","\n","\n","Epoch #39: Average loss is 0.05416716306022135\n","Time taken for epoch: 53.686830282211304s\n","\n","\n","Epoch #40: Average loss is 0.0525916277763301\n","Epoch #40: Train F1 is 0.9867288015398642\n","Epoch #40: Validation F1 is 0.8420845624385448\n","Time taken for epoch: 77.79955959320068s\n","\n","\n","Epoch #41: Average loss is 0.05027334231743298\n","Time taken for epoch: 53.754863262176514s\n","\n","\n","Epoch #42: Average loss is 0.050031489347557724\n","Time taken for epoch: 53.3876588344574s\n","\n","\n","Epoch #43: Average loss is 0.04729436789079063\n","Time taken for epoch: 53.68272566795349s\n","\n","\n","Epoch #44: Average loss is 0.04615793097472078\n","Time taken for epoch: 53.901771783828735s\n","\n","\n","Epoch #45: Average loss is 0.048215527858865063\n","Epoch #45: Train F1 is 0.9887788111605338\n","Epoch #45: Validation F1 is 0.839073749756762\n","Time taken for epoch: 78.8892707824707s\n","\n","\n","Epoch #46: Average loss is 0.04345684833796313\n","Time taken for epoch: 53.93797421455383s\n","\n","\n","Epoch #47: Average loss is 0.043716971843819195\n","Time taken for epoch: 53.887739419937134s\n","\n","\n","Epoch #48: Average loss is 0.04326204344922153\n","Time taken for epoch: 53.666282415390015s\n","\n","\n","Epoch #49: Average loss is 0.04324872559402979\n","Time taken for epoch: 52.6533100605011s\n","\n","\n","Epoch #50: Average loss is 0.03905272045495849\n","Epoch #50: Train F1 is 0.9919391178090422\n","Epoch #50: Validation F1 is 0.8400077384407042\n","Time taken for epoch: 78.08925318717957s\n","\n","\n","Epoch #51: Average loss is 0.037219730899751446\n","Time taken for epoch: 53.44890856742859s\n","\n","\n","Epoch #52: Average loss is 0.03851135415475869\n","Time taken for epoch: 53.02232217788696s\n","\n","\n","Epoch #53: Average loss is 0.03423869938819953\n","Time taken for epoch: 53.51886510848999s\n","\n","\n","Epoch #54: Average loss is 0.0361096470547368\n","Time taken for epoch: 53.29300856590271s\n","\n","\n","Epoch #55: Average loss is 0.0337189746228547\n","Epoch #55: Train F1 is 0.9920111843419214\n","Epoch #55: Validation F1 is 0.8446245898475196\n","Time taken for epoch: 77.94025659561157s\n","\n","\n","Epoch #56: Average loss is 0.030959491075379184\n","Time taken for epoch: 53.55541467666626s\n","\n","\n","Epoch #57: Average loss is 0.0318775273955255\n","Time taken for epoch: 53.947038412094116s\n","\n","\n","Epoch #58: Average loss is 0.03202908892933954\n","Time taken for epoch: 54.3542537689209s\n","\n","\n","Epoch #59: Average loss is 0.03332401472965512\n","Time taken for epoch: 53.65385055541992s\n","\n","\n","Epoch #60: Average loss is 0.029439915597282016\n","Epoch #60: Train F1 is 0.9951390628915059\n","Epoch #60: Validation F1 is 0.8442035997677569\n","Time taken for epoch: 77.91020965576172s\n","\n","\n","Epoch #61: Average loss is 0.030015173310493266\n","Time taken for epoch: 53.51331400871277s\n","\n","\n","Epoch #62: Average loss is 0.025324068046084322\n","Time taken for epoch: 52.95014524459839s\n","\n","\n","Epoch #63: Average loss is 0.026744905825144064\n","Time taken for epoch: 53.66464185714722s\n","\n","\n","Epoch #64: Average loss is 0.026774059861803527\n","Time taken for epoch: 53.27071285247803s\n","\n","\n","Epoch #65: Average loss is 0.02778775704891964\n","Epoch #65: Train F1 is 0.9941256213285135\n","Epoch #65: Validation F1 is 0.8379888268156424\n","Time taken for epoch: 78.87084984779358s\n","\n","\n","Epoch #66: Average loss is 0.02681627576375767\n","Time taken for epoch: 53.507022857666016s\n","\n","\n","Epoch #67: Average loss is 0.024829963344906808\n","Time taken for epoch: 53.39446187019348s\n","\n","\n","Epoch #68: Average loss is 0.027571007164255094\n","Time taken for epoch: 53.24758744239807s\n","\n","\n","Epoch #69: Average loss is 0.023840688124687516\n","Time taken for epoch: 53.897857904434204s\n","\n","\n","Epoch #70: Average loss is 0.022716381487210037\n","Epoch #70: Train F1 is 0.9946093002166356\n","Epoch #70: Validation F1 is 0.8331652208997378\n","Time taken for epoch: 77.87886166572571s\n","\n","\n","Epoch #71: Average loss is 0.024684290824575465\n","Time taken for epoch: 53.19524669647217s\n","\n","\n","Epoch #72: Average loss is 0.02407000538629793\n","Time taken for epoch: 53.530850648880005s\n","\n","\n","Epoch #73: Average loss is 0.02280432589677693\n","Time taken for epoch: 52.873124837875366s\n","\n","\n","Epoch #74: Average loss is 0.0214425083180192\n","Time taken for epoch: 53.05263137817383s\n","\n","\n","Epoch #75: Average loss is 0.023783161594030176\n","Epoch #75: Train F1 is 0.996490524415923\n","Epoch #75: Validation F1 is 0.8423538673489471\n","Time taken for epoch: 77.47446012496948s\n","\n","\n","Epoch #76: Average loss is 0.02454211420099042\n","Time taken for epoch: 53.53467321395874s\n","\n","\n","Epoch #77: Average loss is 0.020897712372682155\n","Time taken for epoch: 53.38923168182373s\n","\n","\n","Epoch #78: Average loss is 0.021906448132679408\n","Time taken for epoch: 53.359572887420654s\n","\n","\n","Epoch #79: Average loss is 0.01795469863581427\n","Time taken for epoch: 53.736069202423096s\n","\n","\n","Epoch #80: Average loss is 0.018736780708778815\n","Epoch #80: Train F1 is 0.9899635036496351\n","Epoch #80: Validation F1 is 0.8317680685994284\n","Time taken for epoch: 77.93386840820312s\n","\n","\n","Epoch #81: Average loss is 0.017558980727016383\n","Time taken for epoch: 53.422619342803955s\n","\n","\n","Epoch #82: Average loss is 0.01936850234781404\n","Time taken for epoch: 53.62936615943909s\n","\n","\n","Epoch #83: Average loss is 0.019723091076009627\n","Time taken for epoch: 53.37379693984985s\n","\n","\n","Epoch #84: Average loss is 0.018861604052805625\n","Time taken for epoch: 53.31812572479248s\n","\n","\n","Epoch #85: Average loss is 0.02016829707172294\n","Epoch #85: Train F1 is 0.9972913322632424\n","Epoch #85: Validation F1 is 0.8427207172091211\n","Time taken for epoch: 78.50445580482483s\n","\n","\n","Epoch #86: Average loss is 0.015504455672827265\n","Time taken for epoch: 53.65591812133789s\n","\n","\n","Epoch #87: Average loss is 0.01702265702364984\n","Time taken for epoch: 53.65106558799744s\n","\n","\n","Epoch #88: Average loss is 0.017655362144698903\n","Time taken for epoch: 53.067405223846436s\n","\n","\n","Epoch #89: Average loss is 0.015091864409171558\n","Time taken for epoch: 53.7298526763916s\n","\n","\n","Epoch #90: Average loss is 0.018596672156259094\n","Epoch #90: Train F1 is 0.9972363197829255\n","Epoch #90: Validation F1 is 0.8353719671144977\n","Time taken for epoch: 78.48750448226929s\n","\n","\n","Epoch #91: Average loss is 0.017713387665210054\n","Time taken for epoch: 52.97917652130127s\n","\n","\n","Epoch #92: Average loss is 0.019314626858002466\n","Time taken for epoch: 53.75435709953308s\n","\n","\n","Epoch #93: Average loss is 0.01566017668387169\n","Time taken for epoch: 53.023966550827026s\n","\n","\n","Epoch #94: Average loss is 0.015717768929928617\n","Time taken for epoch: 53.89216709136963s\n","\n","\n","Epoch #95: Average loss is 0.015323831473082222\n","Epoch #95: Train F1 is 0.9964795815731241\n","Epoch #95: Validation F1 is 0.8441791044776119\n","Time taken for epoch: 78.07174563407898s\n","\n","\n","Epoch #96: Average loss is 0.013844023127027242\n","Time taken for epoch: 53.435303926467896s\n","\n","\n","Epoch #97: Average loss is 0.01596610727088672\n","Time taken for epoch: 53.44560790061951s\n","\n","\n","Epoch #98: Average loss is 0.011879299225980116\n","Time taken for epoch: 53.70201849937439s\n","\n","\n","Epoch #99: Average loss is 0.01365283995855799\n","Time taken for epoch: 53.94553852081299s\n","\n","\n","Epoch #100: Average loss is 0.010925755082120684\n","Epoch #100: Train F1 is 0.9976935419173687\n","Epoch #100: Validation F1 is 0.8413284132841329\n","Time taken for epoch: 78.58385729789734s\n","\n","\n","Epoch #101: Average loss is 0.012638908034689153\n","Time taken for epoch: 53.93715167045593s\n","\n","\n","Epoch #102: Average loss is 0.017879611904682534\n","Time taken for epoch: 53.318268060684204s\n","\n","\n","Epoch #103: Average loss is 0.012319120722887144\n","Time taken for epoch: 53.163816690444946s\n","\n","\n","Epoch #104: Average loss is 0.014251299140827735\n","Time taken for epoch: 53.136723279953s\n","\n"],"name":"stdout"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-6-046d2d4825f0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mfreq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m5\u001b[0m    \u001b[0;31m# epoch interval to calculate F1 score and save models\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mout_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"results/seqLabel/transformer/\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstats\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m150\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfreq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"=\"\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/seq_label.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, epochs, train_loader, valid_loader, freq, out_dir, create_dir, train_eval)\u001b[0m\n\u001b[1;32m    353\u001b[0m                 \u001b[0;31m#       \"Time taken: {}s\".format(i, j, len(train_loader),\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    354\u001b[0m                 \u001b[0;31m#                                loss.item(), time.time() - start), end='\\r')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 355\u001b[0;31m                 \u001b[0mloss_tracker\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    356\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    357\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstats\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_tracker\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","metadata":{"id":"sDhaARXAstP6","colab_type":"code","colab":{}},"source":["# !zip -r results-seq_label.zip results/seqLabel/\n","\n","# from google.colab import files\n","# files.download('results-seq_label.zip')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"iI4rYt0yutrl","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":269},"outputId":"b030a7a4-ac54-4cd8-becc-2b76d9067d8b","executionInfo":{"status":"ok","timestamp":1563440981214,"user_tz":-120,"elapsed":8349,"user":{"displayName":"Ashwin Raaghav","photoUrl":"https://lh5.googleusercontent.com/-uO-vZ_lY6nI/AAAAAAAAAAI/AAAAAAAAGoc/e5zeb5jD1vE/s64/photo.jpg","userId":"02512740178384625797"}}},"source":["# Testing\n","f1_test = task.evaluate(test_loader, verbose=True)\n","print('F1 score: ', f1_test)"],"execution_count":14,"outputs":[{"output_type":"stream","text":["Confusion Matrix: \n"," [[10179  2321]\n"," [ 1361 11139]]\n","Classification Report: \n","               precision    recall  f1-score   support\n","\n","         0.0       0.88      0.81      0.85     12500\n","         1.0       0.83      0.89      0.86     12500\n","\n","    accuracy                           0.85     25000\n","   macro avg       0.85      0.85      0.85     25000\n","weighted avg       0.85      0.85      0.85     25000\n","\n","F1 score:  (0.8581664098613251, 0.4305374167611678)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"_TcVftdswleR","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}