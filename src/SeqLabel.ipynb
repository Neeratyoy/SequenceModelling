{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SeqLabel.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [
        "ZS-zwgyIL_Gq",
        "wwyIk6aEwmBw"
      ],
      "toc_visible": true
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.7"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-07-10T23:18:33.946357Z",
          "start_time": "2019-07-10T23:18:32.653217Z"
        },
        "id": "CnagSCLwL_GW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchtext.datasets import IMDB\n",
        "from torchtext import data\n",
        "from torchtext.vocab import GloVe\n",
        "\n",
        "import os\n",
        "import json\n",
        "import time\n",
        "import random\n",
        "import copy\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix, f1_score, classification_report\n",
        "\n",
        "from IPython.display import Image\n",
        "\n",
        "from seq_label import SeqLabel\n",
        "\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "# device = torch.device('cpu')\n",
        "\n",
        "SEED = 1\n",
        "random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lx5yCF9_L_Gb",
        "colab_type": "text"
      },
      "source": [
        "### Common Parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-07-10T23:18:34.867719Z",
          "start_time": "2019-07-10T23:18:34.864536Z"
        },
        "id": "Ro6cpqmfL_Gc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 16\n",
        "# Percentage of training data\n",
        "split_ratio = 0.8\n",
        "learning_rate = 0.001\n",
        "epochs = 200\n",
        "# vocabulary size to embed input (GloVe output dim)\n",
        "embed_dim = 300"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ao9hPoXuL_Gf",
        "colab_type": "text"
      },
      "source": [
        "## IMDb data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-07-10T23:18:39.350227Z",
          "start_time": "2019-07-10T23:18:36.294738Z"
        },
        "id": "Bfq-_Vn_L_Gh",
        "colab_type": "code",
        "outputId": "359a455e-5f42-40f6-dde2-828842b6f27c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "from imdb import IMDB_dataset\n",
        "\n",
        "imdb = IMDB_dataset(split_ratio, SEED)\n",
        "imdb.load(verbose = True)\n",
        "imdb.build_vocab(embed_dim)\n",
        "train_loader, valid_loader, test_loader = imdb.create_data_loader(batch_size, \n",
        "                                                                  device)\n",
        "vocab_len = len(imdb.TEXT.vocab)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training data size:    20000\n",
            "Validation data size:  5000\n",
            "Test data size:        25000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZS-zwgyIL_Gq",
        "colab_type": "text"
      },
      "source": [
        "# LSTM"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5J9JIEiEL_Gt",
        "colab_type": "text"
      },
      "source": [
        "#### LSTM Parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bEyy-XbWL_Gu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Number of hidden nodes\n",
        "hidden_dim = 64\n",
        "# Number of output nodes\n",
        "output_dim = 1\n",
        "# Number of LSTMs cells to be stacked\n",
        "layers = 1\n",
        "# Boolean value for bidirectioanl or not\n",
        "bidirectional = True\n",
        "# Boolean value to use LayerNorm or not\n",
        "layernorm = True"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wwyIk6aEwmBw",
        "colab_type": "text"
      },
      "source": [
        "### Our implementation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4djeHhqPL_Gx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1be98582-2400-41d5-af32-837d86f0c2c0"
      },
      "source": [
        "## Our implementation\n",
        "\n",
        "from seq_label import LSTMSeqLabel\n",
        "\n",
        "# Initializing model\n",
        "model = LSTMSeqLabel(vocab_len, embed_dim, hidden_dim, output_dim, \n",
        "                      imdb.pretrained_weights, layers, bidirectional,\n",
        "                      layernorm)\n",
        "model.to(device)\n",
        "\n",
        "print('Model parameters: ', model.count_parameters())\n",
        "\n",
        "# Initializing optimizer and loss\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "loss_criterion = nn.BCEWithLogitsLoss()\n",
        "\n",
        "# Initializing task\n",
        "task = SeqLabel(model, optimizer, loss_criterion, device)\n",
        "\n",
        "# Training\n",
        "freq = 5    # epoch interval to calculate F1 score and save models\n",
        "out_dir = \"results/seq_label/lstm\"\n",
        "# out_dir = \"/content/drive/My Drive/colab/seq_label/\""
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model parameters:  93505\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DB9wR08PE8A7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model, stats = task.train(epochs, train_loader, valid_loader, freq, out_dir)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "50ZCNQzcL_G9",
        "colab_type": "text"
      },
      "source": [
        "### PyTorch implementation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rievXl2kL_G-",
        "colab_type": "code",
        "outputId": "31eb1294-7217-49b1-c662-4468e701983e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "## PyTorch implementation\n",
        "\n",
        "from seq_label import PyTorchBaseline\n",
        "\n",
        "# Initializing model\n",
        "model = PyTorchBaseline(vocab_len, embed_dim, hidden_dim, output_dim, \n",
        "                       imdb.pretrained_weights, layers, bidirectional)\n",
        "model.to(device)\n",
        "\n",
        "print('Model parameters: ', model.count_parameters())\n",
        "\n",
        "# Initializing optimizer and loss\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "loss_criterion = nn.BCEWithLogitsLoss()\n",
        "\n",
        "# Initializing task\n",
        "task = SeqLabel(model, optimizer, loss_criterion, device)\n",
        "\n",
        "# Training\n",
        "freq = 5    # epoch interval to calculate F1 score and save models\n",
        "out_dir = \"results/seq_label/pytorch/\"\n",
        "# out_dir = \"/content/drive/My Drive/colab/seq_label/\""
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model parameters:  93761\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c6naCXIiGqxi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model, stats = task.train(epochs, train_loader, valid_loader, freq, out_dir)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XouCfDXEGrdP",
        "colab_type": "text"
      },
      "source": [
        "### Evaluate"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IyqLuiP1wg4U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Testing\n",
        "f1_test = task.evaluate(test_loader, verbose=True)\n",
        "print('F1 score: ', f1_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AoZdxErgPgBh",
        "colab_type": "text"
      },
      "source": [
        "# Transformer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hNxaidYkQOz8",
        "colab_type": "text"
      },
      "source": [
        "### our implementation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rf1izpUftLMy",
        "colab_type": "code",
        "outputId": "89d627b9-2b4b-4195-97c1-d40c1ab00bf0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from seq_label import TransformerSeqLabel\n",
        "from transformer import NoamOpt\n",
        "\n",
        "# 117k\n",
        "model = TransformerSeqLabel(in_dim=vocab_len, out_dim=1, N=1, heads=4, embed_dim=embed_dim, model_dim=128, ff_dim=256, \n",
        "                            key_dim=32, value_dim=32, batch_first=False,\n",
        "                            pretrained_vec=imdb.pretrained_weights)\n",
        "\n",
        "model = model.to(device)\n",
        "\n",
        "print('Model parameters: ', model.count_parameters())\n",
        "\n",
        "# Initializing optimizer and loss\n",
        "# optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "optimizer = NoamOpt(model.model_dim, 1, 2000,\n",
        "        torch.optim.Adam(model.parameters(), lr=0, betas=(0.9, 0.98), eps=1e-9))\n",
        "loss_criterion = nn.BCEWithLogitsLoss()\n",
        "\n",
        "# Initializing task\n",
        "task = SeqLabel(model, optimizer, loss_criterion, device)\n",
        "\n",
        "# Training\n",
        "freq = 5    # epoch interval to calculate F1 score and save models\n",
        "out_dir = \"results/seqLabel/transformer/\""
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model parameters:  171137\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WQ7n-OchEe27",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model, stats = task.train(50, train_loader, valid_loader, freq, out_dir)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E8fbBsLVHG67",
        "colab_type": "text"
      },
      "source": [
        "### Evaluate"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iI4rYt0yutrl",
        "colab_type": "code",
        "outputId": "b030a7a4-ac54-4cd8-becc-2b76d9067d8b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        }
      },
      "source": [
        "# Testing\n",
        "f1_test = task.evaluate(test_loader, verbose=True)\n",
        "print('F1 score: ', f1_test)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Confusion Matrix: \n",
            " [[10179  2321]\n",
            " [ 1361 11139]]\n",
            "Classification Report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.88      0.81      0.85     12500\n",
            "         1.0       0.83      0.89      0.86     12500\n",
            "\n",
            "    accuracy                           0.85     25000\n",
            "   macro avg       0.85      0.85      0.85     25000\n",
            "weighted avg       0.85      0.85      0.85     25000\n",
            "\n",
            "F1 score:  (0.8581664098613251, 0.4305374167611678)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sDhaARXAstP6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# !zip -r results-seq_label.zip results/seqLabel/\n",
        "\n",
        "# from google.colab import files\n",
        "# files.download('results-seq_label.zip')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_TcVftdswleR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}