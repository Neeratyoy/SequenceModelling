{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-10T23:18:33.946357Z",
     "start_time": "2019-07-10T23:18:32.653217Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "CnagSCLwL_GW"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchtext.datasets import IMDB\n",
    "from torchtext import data\n",
    "from torchtext.vocab import GloVe\n",
    "\n",
    "import os\n",
    "import json\n",
    "import time\n",
    "import random\n",
    "import copy\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, f1_score, classification_report\n",
    "\n",
    "from IPython.display import Image\n",
    "\n",
    "from seq_label import SeqLabel\n",
    "\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# device = torch.device('cpu')\n",
    "\n",
    "SEED = 1\n",
    "random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lx5yCF9_L_Gb"
   },
   "source": [
    "### Common Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-10T23:18:34.867719Z",
     "start_time": "2019-07-10T23:18:34.864536Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "Ro6cpqmfL_Gc"
   },
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "# Percentage of training data\n",
    "split_ratio = 0.8\n",
    "learning_rate = 0.001\n",
    "epochs = 200\n",
    "# vocabulary size to embed input (GloVe output dim)\n",
    "embed_dim = 300"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ao9hPoXuL_Gf"
   },
   "source": [
    "## IMDb data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-10T23:18:39.350227Z",
     "start_time": "2019-07-10T23:18:36.294738Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 101934,
     "status": "ok",
     "timestamp": 1563434551831,
     "user": {
      "displayName": "Ashwin Raaghav",
      "photoUrl": "https://lh5.googleusercontent.com/-uO-vZ_lY6nI/AAAAAAAAAAI/AAAAAAAAGoc/e5zeb5jD1vE/s64/photo.jpg",
      "userId": "02512740178384625797"
     },
     "user_tz": -120
    },
    "id": "Bfq-_Vn_L_Gh",
    "outputId": "dc80064a-3a03-4a97-a719-089b050c9f3a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data size:    20000\n",
      "Validation data size:  5000\n",
      "Test data size:        25000\n"
     ]
    }
   ],
   "source": [
    "from imdb import IMDB_dataset\n",
    "\n",
    "imdb = IMDB_dataset(split_ratio, SEED)\n",
    "imdb.load(verbose = True)\n",
    "imdb.build_vocab(embed_dim)\n",
    "train_loader, valid_loader, test_loader = imdb.create_data_loader(batch_size, \n",
    "                                                                  device)\n",
    "vocab_len = len(imdb.TEXT.vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZS-zwgyIL_Gq"
   },
   "source": [
    "# LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5J9JIEiEL_Gt"
   },
   "source": [
    "#### LSTM Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bEyy-XbWL_Gu"
   },
   "outputs": [],
   "source": [
    "# Number of hidden nodes\n",
    "hidden_dim = 256\n",
    "# Number of output nodes\n",
    "output_dim = 1\n",
    "# Number of LSTMs cells to be stacked\n",
    "layers = 1\n",
    "# Boolean value for bidirectioanl or not\n",
    "bidirectional = False\n",
    "# Boolean value to use LayerNorm or not\n",
    "layernorm = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wwyIk6aEwmBw"
   },
   "source": [
    "### Our implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4djeHhqPL_Gx"
   },
   "outputs": [],
   "source": [
    "# Our implementation\n",
    "\n",
    "from seq_label import LSTMSeqLabel\n",
    "\n",
    "# Initializing model\n",
    "model = LSTMSeqLabel(vocab_len, embed_dim, hidden_dim, output_dim, \n",
    "                      imdb.pretrained_weights, layers, bidirectional,\n",
    "                      layernorm)\n",
    "model.to(device)\n",
    "\n",
    "print('Model parameters: ', model.count_parameters())\n",
    "\n",
    "# Initializing optimizer and loss\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "loss_criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "# Initializing task\n",
    "task = SeqLabel(model, optimizer, loss_criterion, device)\n",
    "\n",
    "# Training\n",
    "freq = 5    # epoch interval to calculate F1 score and save models\n",
    "out_dir = \"results/seq_label/\"\n",
    "# out_dir = \"/content/drive/My Drive/colab/seq_label/\"\n",
    "model, stats = task.train(epochs, train_loader, valid_loader, freq, out_dir)\n",
    "\n",
    "print(\"=\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qQx20X6WL_G6"
   },
   "outputs": [],
   "source": [
    "# Testing\n",
    "f1_test = task.evaluate(test_loader, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "heading_collapsed": true,
    "id": "50ZCNQzcL_G9"
   },
   "source": [
    "### PyTorch implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 880
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 484554,
     "status": "error",
     "timestamp": 1562829252477,
     "user": {
      "displayName": "Ashwin Raaghav",
      "photoUrl": "https://lh5.googleusercontent.com/-uO-vZ_lY6nI/AAAAAAAAAAI/AAAAAAAAGoc/e5zeb5jD1vE/s64/photo.jpg",
      "userId": "02512740178384625797"
     },
     "user_tz": -120
    },
    "hidden": true,
    "id": "rievXl2kL_G-",
    "outputId": "37207bd7-7011-4120-dcd2-100b32ec1bdf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model parameters:  571649\n",
      "Beginning training model with 571649 parameters\n",
      "\n",
      "Epoch #1: Batch 2500/2500 -- Loss = 0.6400628089904785; Time taken: 0.016690731048583984s\n",
      "Epoch #1: Average loss is 0.688916947054863\n",
      "Epoch #1: Train F1-score is 0.11512942715634053\n",
      "Epoch #1: Validation F1-score is 0.5475675675675676\n",
      "Time taken for epoch: 117.011958360672s\n",
      "\n",
      "Epoch #2: Batch 2500/2500 -- Loss = 0.3095054626464844; Time taken: 0.016431331634521484s\n",
      "Epoch #2: Average loss is 0.6341397064268589\n",
      "Time taken for epoch: 77.60263323783875s\n",
      "\n",
      "Epoch #3: Batch 2500/2500 -- Loss = 0.12923932075500488; Time taken: 0.02263617515563965s\n",
      "Epoch #3: Average loss is 0.359573724719882\n",
      "Time taken for epoch: 76.62852096557617s\n",
      "\n",
      "Epoch #4: Batch 2500/2500 -- Loss = 0.09730026125907898; Time taken: 0.02712535858154297s\n",
      "Epoch #4: Average loss is 0.30158056974858044\n",
      "Time taken for epoch: 77.24223208427429s\n",
      "\n",
      "Epoch #5: Batch 2500/2500 -- Loss = 0.39330965280532837; Time taken: 0.013465404510498047s\n",
      "Epoch #5: Average loss is 0.27174832921028136\n",
      "Epoch #5: Train F1-score is 0.9126972494992427\n",
      "Epoch #5: Validation F1-score is 0.8834782608695653\n",
      "Time taken for epoch: 119.35506844520569s\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-23fb55ebe5a9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0mout_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"results/seq_label/pytorch/\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;31m# out_dir = \"/content/drive/My Drive/colab/seq_label/\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstats\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfreq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"=\"\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-1370c6fdab8d>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, epochs, train_loader, valid_loader, freq, out_dir)\u001b[0m\n\u001b[1;32m    122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m                 \u001b[0;31m# forward pass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 124\u001b[0;31m                 \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    125\u001b[0m                 \u001b[0;31m# backward pass for the batch (+ weight updates)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-1370c6fdab8d>\u001b[0m in \u001b[0;36mlstm_forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     73\u001b[0m                                      self.model.hidden_dim).to(self.device)\n\u001b[1;32m     74\u001b[0m         \u001b[0;31m# forward pass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/content/seq_label.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, h, c)\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m         \u001b[0membed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 112\u001b[0;31m         \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    113\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    557\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward_packed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    558\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 559\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    560\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    561\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward_tensor\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    537\u001b[0m         \u001b[0munsorted_indices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    538\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 539\u001b[0;31m         \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_batch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msorted_indices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    540\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    541\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute_hidden\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munsorted_indices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward_impl\u001b[0;34m(self, input, hx, batch_sizes, max_batch_size, sorted_indices)\u001b[0m\n\u001b[1;32m    520\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbatch_sizes\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    521\u001b[0m             result = _VF.lstm(input, hx, self._get_flat_weights(), self.bias, self.num_layers,\n\u001b[0;32m--> 522\u001b[0;31m                               self.dropout, self.training, self.bidirectional, self.batch_first)\n\u001b[0m\u001b[1;32m    523\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    524\u001b[0m             result = _VF.lstm(input, batch_sizes, hx, self._get_flat_weights(), self.bias,\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# PyTorch implementation\n",
    "\n",
    "from seq_label import PyTorchBaseline\n",
    "\n",
    "# Initializing model\n",
    "model = PyTorchBaseline(vocab_len, embed_dim, hidden_dim, output_dim, \n",
    "                       imdb.pretrained_weights, layers, bidirectional)\n",
    "model.to(device)\n",
    "\n",
    "print('Model parameters: ', model.count_parameters())\n",
    "\n",
    "# Initializing optimizer and loss\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "loss_criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "# Initializing task\n",
    "task = SeqLabel(model, optimizer, loss_criterion, device)\n",
    "\n",
    "# Training\n",
    "freq = 5    # epoch interval to calculate F1 score and save models\n",
    "out_dir = \"results/seq_label/pytorch/\"\n",
    "# out_dir = \"/content/drive/My Drive/colab/seq_label/\"\n",
    "model, stats = task.train(epochs, train_loader, valid_loader, freq, out_dir)\n",
    "\n",
    "print(\"=\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "hidden": true,
    "id": "IyqLuiP1wg4U"
   },
   "outputs": [],
   "source": [
    "# Testing\n",
    "f1_test = task.evaluate(test_loader, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AoZdxErgPgBh"
   },
   "source": [
    "# Transformer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hNxaidYkQOz8"
   },
   "source": [
    "### our implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 52673,
     "status": "ok",
     "timestamp": 1563434555891,
     "user": {
      "displayName": "Ashwin Raaghav",
      "photoUrl": "https://lh5.googleusercontent.com/-uO-vZ_lY6nI/AAAAAAAAAAI/AAAAAAAAGoc/e5zeb5jD1vE/s64/photo.jpg",
      "userId": "02512740178384625797"
     },
     "user_tz": -120
    },
    "id": "rf1izpUftLMy",
    "outputId": "e1098017-2d76-49ed-9f1a-dd2b6cd32f36"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model parameters:  171137\n"
     ]
    }
   ],
   "source": [
    "from seq_label import TransformerSeqLabel\n",
    "from transformer import NoamOpt\n",
    "\n",
    "# 117k\n",
    "model = TransformerSeqLabel(in_dim=vocab_len, out_dim=1, N=1, heads=4, embed_dim=embed_dim, model_dim=128, ff_dim=256, \n",
    "                            key_dim=32, value_dim=32, batch_first=False,\n",
    "                            pretrained_vec=imdb.pretrained_weights)\n",
    "\n",
    "model = model.to(device)\n",
    "\n",
    "print('Model parameters: ', model.count_parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 6110156,
     "status": "error",
     "timestamp": 1563440775647,
     "user": {
      "displayName": "Ashwin Raaghav",
      "photoUrl": "https://lh5.googleusercontent.com/-uO-vZ_lY6nI/AAAAAAAAAAI/AAAAAAAAGoc/e5zeb5jD1vE/s64/photo.jpg",
      "userId": "02512740178384625797"
     },
     "user_tz": -120
    },
    "id": "FlI0d22SQBIT",
    "outputId": "89b50cfc-9be2-468c-9db4-7a14cf84c5f8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beginning training model with 171137 parameters\n",
      "\n",
      "\n",
      "Epoch #1: Average loss is 0.47241753222346305\n",
      "Epoch #1: Train F1 is 0.8475949367088608\n",
      "Epoch #1: Validation F1 is 0.8491663435440092\n",
      "Time taken for epoch: 77.926922082901s\n",
      "\n",
      "\n",
      "Epoch #2: Average loss is 0.3745592767238617\n",
      "Time taken for epoch: 52.81982731819153s\n",
      "\n",
      "\n",
      "Epoch #3: Average loss is 0.33830806418061254\n",
      "Time taken for epoch: 53.295148611068726s\n",
      "\n",
      "\n",
      "Epoch #4: Average loss is 0.3065046506434679\n",
      "Time taken for epoch: 54.342206716537476s\n",
      "\n",
      "\n",
      "Epoch #5: Average loss is 0.28564162150919437\n",
      "Epoch #5: Train F1 is 0.8827127940090708\n",
      "Epoch #5: Validation F1 is 0.8563334682314853\n",
      "Time taken for epoch: 76.9979019165039s\n",
      "\n",
      "\n",
      "Epoch #6: Average loss is 0.2663201034232974\n",
      "Time taken for epoch: 53.23896503448486s\n",
      "\n",
      "\n",
      "Epoch #7: Average loss is 0.2516104934856296\n",
      "Time taken for epoch: 53.220128774642944s\n",
      "\n",
      "\n",
      "Epoch #8: Average loss is 0.23765434447824954\n",
      "Time taken for epoch: 53.5066499710083s\n",
      "\n",
      "\n",
      "Epoch #9: Average loss is 0.2253943543717265\n",
      "Time taken for epoch: 53.697389364242554s\n",
      "\n",
      "\n",
      "Epoch #10: Average loss is 0.21223808723837137\n",
      "Epoch #10: Train F1 is 0.9248309178743962\n",
      "Epoch #10: Validation F1 is 0.8624308338103416\n",
      "Time taken for epoch: 78.20217776298523s\n",
      "\n",
      "\n",
      "Epoch #11: Average loss is 0.2026348753619939\n",
      "Time taken for epoch: 53.51780581474304s\n",
      "\n",
      "\n",
      "Epoch #12: Average loss is 0.19316560855209827\n",
      "Time taken for epoch: 53.84292244911194s\n",
      "\n",
      "\n",
      "Epoch #13: Average loss is 0.18057769728451967\n",
      "Time taken for epoch: 53.35486817359924s\n",
      "\n",
      "\n",
      "Epoch #14: Average loss is 0.17224119079373776\n",
      "Time taken for epoch: 53.08657383918762s\n",
      "\n",
      "\n",
      "Epoch #15: Average loss is 0.1644634550716728\n",
      "Epoch #15: Train F1 is 0.9492692173392527\n",
      "Epoch #15: Validation F1 is 0.8593809705769966\n",
      "Time taken for epoch: 77.80920314788818s\n",
      "\n",
      "\n",
      "Epoch #16: Average loss is 0.15517100207321347\n",
      "Time taken for epoch: 52.96273398399353s\n",
      "\n",
      "\n",
      "Epoch #17: Average loss is 0.14759667546432464\n",
      "Time taken for epoch: 53.43499755859375s\n",
      "\n",
      "\n",
      "Epoch #18: Average loss is 0.14175945250913502\n",
      "Time taken for epoch: 53.529664516448975s\n",
      "\n",
      "\n",
      "Epoch #19: Average loss is 0.13465692444453015\n",
      "Time taken for epoch: 53.87435603141785s\n",
      "\n",
      "\n",
      "Epoch #20: Average loss is 0.1251843829434365\n",
      "Epoch #20: Train F1 is 0.9628475189784323\n",
      "Epoch #20: Validation F1 is 0.8539805825242718\n",
      "Time taken for epoch: 78.37023663520813s\n",
      "\n",
      "\n",
      "Epoch #21: Average loss is 0.12144348427839577\n",
      "Time taken for epoch: 53.59635305404663s\n",
      "\n",
      "\n",
      "Epoch #22: Average loss is 0.11453345116954297\n",
      "Time taken for epoch: 53.48126983642578s\n",
      "\n",
      "\n",
      "Epoch #23: Average loss is 0.11006583965928293\n",
      "Time taken for epoch: 53.4348042011261s\n",
      "\n",
      "\n",
      "Epoch #24: Average loss is 0.10321216355711221\n",
      "Time taken for epoch: 53.22753691673279s\n",
      "\n",
      "\n",
      "Epoch #25: Average loss is 0.10023101809103974\n",
      "Epoch #25: Train F1 is 0.9678343134748146\n",
      "Epoch #25: Validation F1 is 0.8487938811531672\n",
      "Time taken for epoch: 77.80720853805542s\n",
      "\n",
      "\n",
      "Epoch #26: Average loss is 0.09584170881547034\n",
      "Time taken for epoch: 53.22996139526367s\n",
      "\n",
      "\n",
      "Epoch #27: Average loss is 0.08976618209048175\n",
      "Time taken for epoch: 53.85586214065552s\n",
      "\n",
      "\n",
      "Epoch #28: Average loss is 0.08869505762568441\n",
      "Time taken for epoch: 53.77509570121765s\n",
      "\n",
      "\n",
      "Epoch #29: Average loss is 0.08289735036673955\n",
      "Time taken for epoch: 53.9385883808136s\n",
      "\n",
      "\n",
      "Epoch #30: Average loss is 0.07969902785305166\n",
      "Epoch #30: Train F1 is 0.9752262275626762\n",
      "Epoch #30: Validation F1 is 0.845356941043511\n",
      "Time taken for epoch: 78.34468531608582s\n",
      "\n",
      "\n",
      "Epoch #31: Average loss is 0.07686749536275166\n",
      "Time taken for epoch: 53.13358688354492s\n",
      "\n",
      "\n",
      "Epoch #32: Average loss is 0.07215175480289326\n",
      "Time taken for epoch: 53.461689949035645s\n",
      "\n",
      "\n",
      "Epoch #33: Average loss is 0.06848485794950974\n",
      "Time taken for epoch: 53.01230502128601s\n",
      "\n",
      "\n",
      "Epoch #34: Average loss is 0.06427017764490228\n",
      "Time taken for epoch: 54.12820363044739s\n",
      "\n",
      "\n",
      "Epoch #35: Average loss is 0.06730119478049747\n",
      "Epoch #35: Train F1 is 0.9835087009307972\n",
      "Epoch #35: Validation F1 is 0.8413039234823345\n",
      "Time taken for epoch: 78.63146352767944s\n",
      "\n",
      "\n",
      "Epoch #36: Average loss is 0.06307019457129208\n",
      "Time taken for epoch: 53.74545359611511s\n",
      "\n",
      "\n",
      "Epoch #37: Average loss is 0.05830542923137837\n",
      "Time taken for epoch: 53.43738007545471s\n",
      "\n",
      "\n",
      "Epoch #38: Average loss is 0.05625422761499649\n",
      "Time taken for epoch: 53.48845171928406s\n",
      "\n",
      "\n",
      "Epoch #39: Average loss is 0.05416716306022135\n",
      "Time taken for epoch: 53.686830282211304s\n",
      "\n",
      "\n",
      "Epoch #40: Average loss is 0.0525916277763301\n",
      "Epoch #40: Train F1 is 0.9867288015398642\n",
      "Epoch #40: Validation F1 is 0.8420845624385448\n",
      "Time taken for epoch: 77.79955959320068s\n",
      "\n",
      "\n",
      "Epoch #41: Average loss is 0.05027334231743298\n",
      "Time taken for epoch: 53.754863262176514s\n",
      "\n",
      "\n",
      "Epoch #42: Average loss is 0.050031489347557724\n",
      "Time taken for epoch: 53.3876588344574s\n",
      "\n",
      "\n",
      "Epoch #43: Average loss is 0.04729436789079063\n",
      "Time taken for epoch: 53.68272566795349s\n",
      "\n",
      "\n",
      "Epoch #44: Average loss is 0.04615793097472078\n",
      "Time taken for epoch: 53.901771783828735s\n",
      "\n",
      "\n",
      "Epoch #45: Average loss is 0.048215527858865063\n",
      "Epoch #45: Train F1 is 0.9887788111605338\n",
      "Epoch #45: Validation F1 is 0.839073749756762\n",
      "Time taken for epoch: 78.8892707824707s\n",
      "\n",
      "\n",
      "Epoch #46: Average loss is 0.04345684833796313\n",
      "Time taken for epoch: 53.93797421455383s\n",
      "\n",
      "\n",
      "Epoch #47: Average loss is 0.043716971843819195\n",
      "Time taken for epoch: 53.887739419937134s\n",
      "\n",
      "\n",
      "Epoch #48: Average loss is 0.04326204344922153\n",
      "Time taken for epoch: 53.666282415390015s\n",
      "\n",
      "\n",
      "Epoch #49: Average loss is 0.04324872559402979\n",
      "Time taken for epoch: 52.6533100605011s\n",
      "\n",
      "\n",
      "Epoch #50: Average loss is 0.03905272045495849\n",
      "Epoch #50: Train F1 is 0.9919391178090422\n",
      "Epoch #50: Validation F1 is 0.8400077384407042\n",
      "Time taken for epoch: 78.08925318717957s\n",
      "\n",
      "\n",
      "Epoch #51: Average loss is 0.037219730899751446\n",
      "Time taken for epoch: 53.44890856742859s\n",
      "\n",
      "\n",
      "Epoch #52: Average loss is 0.03851135415475869\n",
      "Time taken for epoch: 53.02232217788696s\n",
      "\n",
      "\n",
      "Epoch #53: Average loss is 0.03423869938819953\n",
      "Time taken for epoch: 53.51886510848999s\n",
      "\n",
      "\n",
      "Epoch #54: Average loss is 0.0361096470547368\n",
      "Time taken for epoch: 53.29300856590271s\n",
      "\n",
      "\n",
      "Epoch #55: Average loss is 0.0337189746228547\n",
      "Epoch #55: Train F1 is 0.9920111843419214\n",
      "Epoch #55: Validation F1 is 0.8446245898475196\n",
      "Time taken for epoch: 77.94025659561157s\n",
      "\n",
      "\n",
      "Epoch #56: Average loss is 0.030959491075379184\n",
      "Time taken for epoch: 53.55541467666626s\n",
      "\n",
      "\n",
      "Epoch #57: Average loss is 0.0318775273955255\n",
      "Time taken for epoch: 53.947038412094116s\n",
      "\n",
      "\n",
      "Epoch #58: Average loss is 0.03202908892933954\n",
      "Time taken for epoch: 54.3542537689209s\n",
      "\n",
      "\n",
      "Epoch #59: Average loss is 0.03332401472965512\n",
      "Time taken for epoch: 53.65385055541992s\n",
      "\n",
      "\n",
      "Epoch #60: Average loss is 0.029439915597282016\n",
      "Epoch #60: Train F1 is 0.9951390628915059\n",
      "Epoch #60: Validation F1 is 0.8442035997677569\n",
      "Time taken for epoch: 77.91020965576172s\n",
      "\n",
      "\n",
      "Epoch #61: Average loss is 0.030015173310493266\n",
      "Time taken for epoch: 53.51331400871277s\n",
      "\n",
      "\n",
      "Epoch #62: Average loss is 0.025324068046084322\n",
      "Time taken for epoch: 52.95014524459839s\n",
      "\n",
      "\n",
      "Epoch #63: Average loss is 0.026744905825144064\n",
      "Time taken for epoch: 53.66464185714722s\n",
      "\n",
      "\n",
      "Epoch #64: Average loss is 0.026774059861803527\n",
      "Time taken for epoch: 53.27071285247803s\n",
      "\n",
      "\n",
      "Epoch #65: Average loss is 0.02778775704891964\n",
      "Epoch #65: Train F1 is 0.9941256213285135\n",
      "Epoch #65: Validation F1 is 0.8379888268156424\n",
      "Time taken for epoch: 78.87084984779358s\n",
      "\n",
      "\n",
      "Epoch #66: Average loss is 0.02681627576375767\n",
      "Time taken for epoch: 53.507022857666016s\n",
      "\n",
      "\n",
      "Epoch #67: Average loss is 0.024829963344906808\n",
      "Time taken for epoch: 53.39446187019348s\n",
      "\n",
      "\n",
      "Epoch #68: Average loss is 0.027571007164255094\n",
      "Time taken for epoch: 53.24758744239807s\n",
      "\n",
      "\n",
      "Epoch #69: Average loss is 0.023840688124687516\n",
      "Time taken for epoch: 53.897857904434204s\n",
      "\n",
      "\n",
      "Epoch #70: Average loss is 0.022716381487210037\n",
      "Epoch #70: Train F1 is 0.9946093002166356\n",
      "Epoch #70: Validation F1 is 0.8331652208997378\n",
      "Time taken for epoch: 77.87886166572571s\n",
      "\n",
      "\n",
      "Epoch #71: Average loss is 0.024684290824575465\n",
      "Time taken for epoch: 53.19524669647217s\n",
      "\n",
      "\n",
      "Epoch #72: Average loss is 0.02407000538629793\n",
      "Time taken for epoch: 53.530850648880005s\n",
      "\n",
      "\n",
      "Epoch #73: Average loss is 0.02280432589677693\n",
      "Time taken for epoch: 52.873124837875366s\n",
      "\n",
      "\n",
      "Epoch #74: Average loss is 0.0214425083180192\n",
      "Time taken for epoch: 53.05263137817383s\n",
      "\n",
      "\n",
      "Epoch #75: Average loss is 0.023783161594030176\n",
      "Epoch #75: Train F1 is 0.996490524415923\n",
      "Epoch #75: Validation F1 is 0.8423538673489471\n",
      "Time taken for epoch: 77.47446012496948s\n",
      "\n",
      "\n",
      "Epoch #76: Average loss is 0.02454211420099042\n",
      "Time taken for epoch: 53.53467321395874s\n",
      "\n",
      "\n",
      "Epoch #77: Average loss is 0.020897712372682155\n",
      "Time taken for epoch: 53.38923168182373s\n",
      "\n",
      "\n",
      "Epoch #78: Average loss is 0.021906448132679408\n",
      "Time taken for epoch: 53.359572887420654s\n",
      "\n",
      "\n",
      "Epoch #79: Average loss is 0.01795469863581427\n",
      "Time taken for epoch: 53.736069202423096s\n",
      "\n",
      "\n",
      "Epoch #80: Average loss is 0.018736780708778815\n",
      "Epoch #80: Train F1 is 0.9899635036496351\n",
      "Epoch #80: Validation F1 is 0.8317680685994284\n",
      "Time taken for epoch: 77.93386840820312s\n",
      "\n",
      "\n",
      "Epoch #81: Average loss is 0.017558980727016383\n",
      "Time taken for epoch: 53.422619342803955s\n",
      "\n",
      "\n",
      "Epoch #82: Average loss is 0.01936850234781404\n",
      "Time taken for epoch: 53.62936615943909s\n",
      "\n",
      "\n",
      "Epoch #83: Average loss is 0.019723091076009627\n",
      "Time taken for epoch: 53.37379693984985s\n",
      "\n",
      "\n",
      "Epoch #84: Average loss is 0.018861604052805625\n",
      "Time taken for epoch: 53.31812572479248s\n",
      "\n",
      "\n",
      "Epoch #85: Average loss is 0.02016829707172294\n",
      "Epoch #85: Train F1 is 0.9972913322632424\n",
      "Epoch #85: Validation F1 is 0.8427207172091211\n",
      "Time taken for epoch: 78.50445580482483s\n",
      "\n",
      "\n",
      "Epoch #86: Average loss is 0.015504455672827265\n",
      "Time taken for epoch: 53.65591812133789s\n",
      "\n",
      "\n",
      "Epoch #87: Average loss is 0.01702265702364984\n",
      "Time taken for epoch: 53.65106558799744s\n",
      "\n",
      "\n",
      "Epoch #88: Average loss is 0.017655362144698903\n",
      "Time taken for epoch: 53.067405223846436s\n",
      "\n",
      "\n",
      "Epoch #89: Average loss is 0.015091864409171558\n",
      "Time taken for epoch: 53.7298526763916s\n",
      "\n",
      "\n",
      "Epoch #90: Average loss is 0.018596672156259094\n",
      "Epoch #90: Train F1 is 0.9972363197829255\n",
      "Epoch #90: Validation F1 is 0.8353719671144977\n",
      "Time taken for epoch: 78.48750448226929s\n",
      "\n",
      "\n",
      "Epoch #91: Average loss is 0.017713387665210054\n",
      "Time taken for epoch: 52.97917652130127s\n",
      "\n",
      "\n",
      "Epoch #92: Average loss is 0.019314626858002466\n",
      "Time taken for epoch: 53.75435709953308s\n",
      "\n",
      "\n",
      "Epoch #93: Average loss is 0.01566017668387169\n",
      "Time taken for epoch: 53.023966550827026s\n",
      "\n",
      "\n",
      "Epoch #94: Average loss is 0.015717768929928617\n",
      "Time taken for epoch: 53.89216709136963s\n",
      "\n",
      "\n",
      "Epoch #95: Average loss is 0.015323831473082222\n",
      "Epoch #95: Train F1 is 0.9964795815731241\n",
      "Epoch #95: Validation F1 is 0.8441791044776119\n",
      "Time taken for epoch: 78.07174563407898s\n",
      "\n",
      "\n",
      "Epoch #96: Average loss is 0.013844023127027242\n",
      "Time taken for epoch: 53.435303926467896s\n",
      "\n",
      "\n",
      "Epoch #97: Average loss is 0.01596610727088672\n",
      "Time taken for epoch: 53.44560790061951s\n",
      "\n",
      "\n",
      "Epoch #98: Average loss is 0.011879299225980116\n",
      "Time taken for epoch: 53.70201849937439s\n",
      "\n",
      "\n",
      "Epoch #99: Average loss is 0.01365283995855799\n",
      "Time taken for epoch: 53.94553852081299s\n",
      "\n",
      "\n",
      "Epoch #100: Average loss is 0.010925755082120684\n",
      "Epoch #100: Train F1 is 0.9976935419173687\n",
      "Epoch #100: Validation F1 is 0.8413284132841329\n",
      "Time taken for epoch: 78.58385729789734s\n",
      "\n",
      "\n",
      "Epoch #101: Average loss is 0.012638908034689153\n",
      "Time taken for epoch: 53.93715167045593s\n",
      "\n",
      "\n",
      "Epoch #102: Average loss is 0.017879611904682534\n",
      "Time taken for epoch: 53.318268060684204s\n",
      "\n",
      "\n",
      "Epoch #103: Average loss is 0.012319120722887144\n",
      "Time taken for epoch: 53.163816690444946s\n",
      "\n",
      "\n",
      "Epoch #104: Average loss is 0.014251299140827735\n",
      "Time taken for epoch: 53.136723279953s\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-046d2d4825f0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mfreq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m5\u001b[0m    \u001b[0;31m# epoch interval to calculate F1 score and save models\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mout_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"results/seqLabel/transformer/\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstats\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m150\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfreq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"=\"\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/content/seq_label.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, epochs, train_loader, valid_loader, freq, out_dir, create_dir, train_eval)\u001b[0m\n\u001b[1;32m    353\u001b[0m                 \u001b[0;31m#       \"Time taken: {}s\".format(i, j, len(train_loader),\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    354\u001b[0m                 \u001b[0;31m#                                loss.item(), time.time() - start), end='\\r')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 355\u001b[0;31m                 \u001b[0mloss_tracker\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    356\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    357\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstats\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_tracker\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Initializing optimizer and loss\n",
    "# optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "optimizer = NoamOpt(model.model_dim, 1, 2000,\n",
    "        torch.optim.Adam(model.parameters(), lr=0, betas=(0.9, 0.98), eps=1e-9))\n",
    "loss_criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "# Initializing task\n",
    "task = SeqLabel(model, optimizer, loss_criterion, device)\n",
    "\n",
    "# Training\n",
    "freq = 5    # epoch interval to calculate F1 score and save models\n",
    "out_dir = \"results/seqLabel/transformer/\"\n",
    "model, stats = task.train(150, train_loader, valid_loader, freq, out_dir)\n",
    "\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Testing\n",
    "f1_test = task.evaluate(test_loader, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sDhaARXAstP6"
   },
   "outputs": [],
   "source": [
    "# !zip -r results-seq_label.zip results/seqLabel/\n",
    "\n",
    "# from google.colab import files\n",
    "# files.download('results-seq_label.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 269
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 8349,
     "status": "ok",
     "timestamp": 1563440981214,
     "user": {
      "displayName": "Ashwin Raaghav",
      "photoUrl": "https://lh5.googleusercontent.com/-uO-vZ_lY6nI/AAAAAAAAAAI/AAAAAAAAGoc/e5zeb5jD1vE/s64/photo.jpg",
      "userId": "02512740178384625797"
     },
     "user_tz": -120
    },
    "id": "iI4rYt0yutrl",
    "outputId": "b030a7a4-ac54-4cd8-becc-2b76d9067d8b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix: \n",
      " [[10179  2321]\n",
      " [ 1361 11139]]\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.88      0.81      0.85     12500\n",
      "         1.0       0.83      0.89      0.86     12500\n",
      "\n",
      "    accuracy                           0.85     25000\n",
      "   macro avg       0.85      0.85      0.85     25000\n",
      "weighted avg       0.85      0.85      0.85     25000\n",
      "\n",
      "F1 score:  (0.8581664098613251, 0.4305374167611678)\n"
     ]
    }
   ],
   "source": [
    "# Testing\n",
    "f1_test = task.evaluate(test_loader, verbose=True)\n",
    "print('F1 score: ', f1_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_TcVftdswleR"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "ZS-zwgyIL_Gq"
   ],
   "name": "SeqLabel.ipynb",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
