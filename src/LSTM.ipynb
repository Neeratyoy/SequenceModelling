{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchtext.datasets import IMDB\n",
    "from torchtext import data\n",
    "from torchtext.vocab import GloVe\n",
    "\n",
    "import random\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix, f1_score, classification_report\n",
    "\n",
    "from IPython.display import Image\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "seed = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embedding dimension/dimension for LSTM cell inputs\n",
    "embed_dim = 300\n",
    "# Number of hidden nodes\n",
    "hidden_dim = 256\n",
    "# Number of output nodes\n",
    "output_dim = 1\n",
    "# Number of LSTMs cells to be stacked\n",
    "layers = 1\n",
    "# Boolean value for bidirectioanl or not\n",
    "bidirectional = False\n",
    "# Boolean value for Xavier initialization\n",
    "xavier_init = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 8\n",
    "# Percentage of training data\n",
    "split_ratio = 0.8\n",
    "learning_rate = 0.001\n",
    "epochs = 200"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading and preparing IMDB dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data size:    20000\n",
      "Validation data size:  5000\n",
      "Test data size:        25000\n"
     ]
    }
   ],
   "source": [
    "from imdb import IMDB_dataset\n",
    "imdb = IMDB_dataset(split_ratio, seed)\n",
    "imdb.load(verbose = True)\n",
    "imdb.build_vocab(embed_dim)\n",
    "train_loader, valid_loader, test_loader = imdb.create_data_loader(batch_size, device)\n",
    "vocab_len = len(imdb.TEXT.vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from lstm import LSTM\n",
    "# model = LSTM(embed_dim, hidden_dim, layers=1, bidirectional=False, xavier_init=True)\n",
    "# hidden_state = torch.zeros(1, batch_size, hidden_dim, requires_grad=True)\n",
    "# cell_state = torch.zeros(1, batch_size, hidden_dim, requires_grad=True)\n",
    "# inputs = torch.randn(20, batch_size, embed_dim)\n",
    "# print(next(model.parameters()).is_cuda, inputs.is_cuda, hidden_state.is_cuda, cell_state.is_cuda)\n",
    "# o, (h, c) = model(inputs, hidden_state, cell_state, device=\"cpu\")\n",
    "# print(h.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss = torch.norm(h)\n",
    "# loss.backward()\n",
    "# optimizer = optim.Adam(model.parameters())\n",
    "# optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #1: Batch 35/5000 -- Loss = 0.6816046833992004\r"
     ]
    }
   ],
   "source": [
    "# from sentiment_analysis import *\n",
    "\n",
    "model = LSTM_sentiment(vocab_len, embed_dim, hidden_dim, output_dim, \n",
    "                       imdb.pretrained_weights, layers, bidirectional, \n",
    "                       xavier_init)\n",
    "model.to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "loss_criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "# Train\n",
    "model, stats = train_sentiment(model, train_loader, device, epochs, optimizer, \n",
    "                               loss_criterion, valid_loader)\n",
    "print(\"=\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test\n",
    "f1_test = evaluate_sentiment(model, test_loader, device, verbose=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
